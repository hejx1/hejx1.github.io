{"meta":{"title":"Junxin's Blog","subtitle":"A good memory is not as good as a rotten keyboard.","description":"A good memory is not as good as a rotten keyboard.","author":"何俊鑫","url":"https://blog.smilexin.cn"},"pages":[{"title":"","date":"2021-04-30T02:44:33.323Z","updated":"2021-04-30T02:44:33.323Z","comments":false,"path":"categories/index.html","permalink":"https://blog.smilexin.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-04-30T02:44:33.323Z","updated":"2021-04-30T02:44:33.323Z","comments":false,"path":"tags/index.html","permalink":"https://blog.smilexin.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java后端实现视频分段渐进式播放","slug":"Java后端实现视频分段渐进式播放","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T05:49:42.143Z","comments":true,"path":"2021/08/20/Java后端实现视频分段渐进式播放.html","link":"","permalink":"https://blog.smilexin.cn/2021/08/20/Java后端实现视频分段渐进式播放.html","excerpt":"","text":"概述最近在做公司的视频业务，涉及到大的视频文件的上传和播放。针对大文件，无论是上传和下载都需要分片处理，不能像以前处理小图片一样直接将整个文件流上传到服务器，服务器也不能直接响应整个文件给客户端。 这篇文章，主要记录一下，服务端如何将一个大的视频文件做切分，分段响应给客户端，让浏览器可以渐进式的播放。 为什么需要分段播放？如果一个视频文件很大，例如一部1GB的电影，服务端直接将整个文件响应给客户端是会抛异常的，浏览器也没办法一下子接收这么大的文件，视频播放会出问题。 其次，直接响应一个完整的视频，无疑会浪费服务器的带宽，用户点击播放，很少会完整的观看完视频，可能看一下片头不感兴趣就不看了，亦或是想直接快进到高潮部分，跳过前面的情节等等，服务端应该根据用户的需求，只响应用户真正需要的视频片段就可以了。 服务器带宽是很珍贵的稀缺资源，应该尽可能的节约。 Http请求头RangeRange请求头是HTTP1.1才加入的，它为并行下载以及断点续传提供了技术支持。如下是一个HTTP请求头示例：123456Accept: */*Accept-Encoding: identity;q=1, *;q=0Accept-Language: zh-CN,zh;q=0.9Connection: keep-aliveHost: localhost:8080Range: bytes=0-1024 Range请求头的意思是告诉服务端，这次请求客户端只需要资源的第0-1024个字节的区间数据，服务端只需要响应这部分数据就可以了。 使用&lt;video&gt;标签的src属性指向服务器链接，当服务器响应的HTTP状态码为206时，浏览器会自动开启分段式播放，在每次的HTTP请求头中自动加入Range请求头，服务端只需要根据前端传过来的Range信息截取视频的指定区间来响应即可。 代码部分1234567891011121314151617181920212223242526272829303132333435363738394041@RestControllerpublic class VideoController &#123; @GetMapping(\"play\") public void play(HttpServletRequest request, HttpServletResponse response) throws IOException&#123; response.reset(); File file = new File(\"/Users/panchanghe/Downloads/北极狗.BD.1080p.国英双语中字.mkv\"); long fileLength = file.length(); // 随机读文件 RandomAccessFile randomAccessFile = new RandomAccessFile(file, \"r\"); //获取从那个字节开始读取文件 String rangeString = request.getHeader(\"Range\"); long range=0; if (rangeString != null) &#123; range = Long.valueOf(rangeString.substring(rangeString.indexOf(\"=\") + 1, rangeString.indexOf(\"-\"))); &#125; //获取响应的输出流 OutputStream outputStream = response.getOutputStream(); //设置内容类型 response.setHeader(\"Content-Type\", \"video/mp4\"); //返回码需要为206，代表只处理了部分请求，响应了部分数据 response.setStatus(HttpServletResponse.SC_PARTIAL_CONTENT); // 移动访问指针到指定位置 randomAccessFile.seek(range); // 每次请求只返回1MB的视频流 byte[] bytes = new byte[1024 * 1024]; int len = randomAccessFile.read(bytes); //设置此次相应返回的数据长度 response.setContentLength(len); //设置此次相应返回的数据范围 response.setHeader(\"Content-Range\", \"bytes \"+range+\"-\"+(fileLength-1)+\"/\"+fileLength); // 将这1MB的视频流响应给客户端 outputStream.write(bytes, 0, len); outputStream.close(); randomAccessFile.close(); System.out.println(\"返回数据区间:【\"+range+\"-\"+(range+len)+\"】\"); &#125;&#125; 播放视频在浏览器中直接键入播放地址，视频的请求过程是这样的： 后端控制台输出： 利用文件分段下载的特点，除了可以做视频的渐进式播放，还有很多其他的用处。例如：文件的断点续传、文件多线程并发下载等 参考博文：https://blog.csdn.net/qq_32099833/article/details/109703883","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://blog.smilexin.cn/tags/java/"}]},{"title":"使用Docker快速搭建Skywalking","slug":"使用Docker快速搭建Skywalking","date":"2021-07-14T16:00:00.000Z","updated":"2021-07-15T07:24:54.971Z","comments":true,"path":"2021/07/15/使用Docker快速搭建Skywalking.html","link":"","permalink":"https://blog.smilexin.cn/2021/07/15/使用Docker快速搭建Skywalking.html","excerpt":"","text":"部署 elasticsearch镜像：elasticsearch:7.13.21234docker run -d --name=es7 -m 4000m \\-p 9200:9200 -p 9300:9300 \\-e &quot;ES_JAVA_OPTS=-Xms3500m -Xmx3500m&quot; \\-e &quot;discovery.type=single-node&quot; elasticsearch:7.13.2 部署 skywalking-oap-server 存储；elasticsearch 7.x 镜像：apache/skywalking-oap-server:8.6.0-es712345678docker run --name oap --restart always -d \\-e TZ=Asia/Shanghai \\-p 12800:12800 \\-p 11800:11800 \\--link es7:es7 \\-e SW_STORAGE=elasticsearch7 \\-e SW_STORAGE_ES_CLUSTER_NODES=es7:9200 \\apache/skywalking-oap-server:8.6.0-es7 部署 skywalking-ui镜像：apache/skywalking-ui:8.6.0123456docker run -d --name skywalking-ui \\-e TZ=Asia/Shanghai \\-p 8080:8080 \\--link oap:oap \\-e SW_OAP_ADDRESS=oap:12800 \\apache/skywalking-ui:8.6.0","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Skywalking","slug":"Skywalking","permalink":"https://blog.smilexin.cn/tags/Skywalking/"}]},{"title":"ElasticSearch 命令笔记","slug":"ElasticSearch 命令笔记","date":"2021-07-04T16:00:00.000Z","updated":"2021-07-21T07:10:16.757Z","comments":true,"path":"2021/07/05/ElasticSearch 命令笔记.html","link":"","permalink":"https://blog.smilexin.cn/2021/07/05/ElasticSearch 命令笔记.html","excerpt":"","text":"启动elastichd1docker run -p 9800:9800 -d containerize/elastichd 删除索引 删除 ‘sw_’ 开头的所有索引1curl -XDELETE &apos;http://192.168.1.5:9200/sw_*&apos;","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.smilexin.cn/tags/ElasticSearch/"}]},{"title":"Skywalking 简介","slug":"Skywalking 简介","date":"2021-06-27T16:00:00.000Z","updated":"2021-06-28T01:26:46.240Z","comments":true,"path":"2021/06/28/Skywalking 简介.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/28/Skywalking 简介.html","excerpt":"","text":"Skywalking是什么？分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。 提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 Skywalking有哪些功能？ 多种监控手段。可以通过语言探针和 service mesh 获得监控是数据。 多个语言自动探针。包括 Java，.NET Core 和 Node.JS。 轻量高效。无需大数据平台，和大量的服务器资源。 模块化。UI、存储、集群管理都有多种机制可选。 支持告警。 优秀的可视化解决方案。 Skywalking 整体架构 Skywalking架构图 整个架构，分成上、下、左、右四部分： 考虑到让描述更简单，我们舍弃掉 Metric 指标相关，而着重在 Tracing 链路相关功能。 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。 右部分 Storage ：Tracing 数据存储。目前支持 ES、MySQL、Sharding Sphere、TiDB、H2 多种存储器。而我们目前采用的是 ES ，主要考虑是 SkyWalking 开发团队自己的生产环境采用 ES 为主。 左部分 SkyWalking UI ：负责提供控台，查看链路等等。 SkyWalking 单机环境 Skywalking单机环境 SkyWalking UI 介绍https://blog.csdn.net/lizz861109/article/details/107535100","categories":[],"tags":[{"name":"Skywalking","slug":"Skywalking","permalink":"https://blog.smilexin.cn/tags/Skywalking/"}]},{"title":"基于Docker搭建 EMQ X 集群","slug":"基于Docker搭建 EMQ X 集群","date":"2021-06-22T16:00:00.000Z","updated":"2021-07-05T07:26:54.315Z","comments":true,"path":"2021/06/23/基于Docker搭建 EMQ X 集群.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/23/基于Docker搭建 EMQ X 集群.html","excerpt":"","text":"EMQ X 消息服务器简介EMQ X (Erlang/Enterprise/Elastic MQTT Broker) 是基于 Erlang/OTP 平台开发的开源物联网 MQTT 消息服务器。 Erlang/OTP是出色的软实时 (Soft-Realtime)、低延时 (Low-Latency)、分布式 (Distributed)的语言平台。 MQTT 是轻量的 (Lightweight)、发布订阅模式 (PubSub) 的物联网消息协议。 EMQ X 设计目标是实现高可靠，并支持承载海量物联网终端的MQTT连接，支持在海量物联网设备间低延时消息路由: 稳定承载大规模的 MQTT 客户端连接，单服务器节点支持50万到100万连接。 分布式节点集群，快速低延时的消息路由，单集群支持1000万规模的路由。 消息服务器内扩展，支持定制多种认证方式、高效存储消息到后端数据库。 完整物联网协议支持，MQTT、MQTT-SN、CoAP、LwM2M、WebSocket 或私有协议支持。 官方网站：https://mqttx.app/zh/docs 官方文档：https://docs.emqx.cn/broker/v4.3 启动集群节点 192.168.1.100 123456789101112131415docker run -d --name emqx-node1 --restart=always --network host \\ -e EMQX_LISTENER__TCP__EXTERNAL=1883 \\ -e EMQX_NAME=emqx \\ -e EMQX_HOST=192.168.1.100 \\ -e EMQX_CLUSTER__NAME=emqxcl \\ -e EMQX_ALLOW_ANONYMOUS=false \\ -e EMQX_LOADED_PLUGINS=&quot;emqx_auth_mysql&quot; \\ -e EMQX_DASHBOARD__DEFAULT_USER__LOGIN=&quot;admin&quot; \\ -e EMQX_DASHBOARD__DEFAULT_USER__PASSWORD=&quot;admin@123&quot; \\ -e EMQX_AUTH__MYSQL__SERVER=&quot;192.168.1.5:3306&quot; \\ -e EMQX_AUTH__MYSQL__USERNAME=&quot;emqx&quot; \\ -e EMQX_AUTH__MYSQL__PASSWORD=&quot;mysql_password&quot; \\ -e EMQX_AUTH__MYSQL__DATABASE=&quot;emqx&quot; \\ -e EMQX_AUTH__MYSQL__PASSWORD_HASH=&quot;plain&quot; \\ emqx/emqx:4.3.3 192.168.1.102 123456789101112131415docker run -d --name emqx-node2 --restart=always --network host \\ -e EMQX_LISTENER__TCP__EXTERNAL=1883 \\ -e EMQX_NAME=emqx \\ -e EMQX_HOST=192.168.1.102 \\ -e EMQX_CLUSTER__NAME=emqxcl \\ -e EMQX_ALLOW_ANONYMOUS=false \\ -e EMQX_DASHBOARD__DEFAULT_USER__LOGIN=&quot;admin&quot; \\ -e EMQX_DASHBOARD__DEFAULT_USER__PASSWORD=&quot;admin@123&quot; \\ -e EMQX_LOADED_PLUGINS=&quot;emqx_auth_mysql&quot; \\ -e EMQX_AUTH__MYSQL__SERVER=&quot;192.168.1.5:3306&quot; \\ -e EMQX_AUTH__MYSQL__USERNAME=&quot;emqx&quot; \\ -e EMQX_AUTH__MYSQL__PASSWORD=&quot;mysql_password&quot; \\ -e EMQX_AUTH__MYSQL__DATABASE=&quot;emqx&quot; \\ -e EMQX_AUTH__MYSQL__PASSWORD_HASH=&quot;plain&quot; \\ emqx/emqx:4.3.3 比较需要注意的是–network选择host就不需要使用-p暴露端口了,容器的端口会默认暴露在宿主机。这样和直接部署在主机上一样，但是同时又利用了docker的限制资源的能力，算是投机取巧吧，linux貌似可以直接限制进程的资源使用。 配置集群 注意：集群节点必须在同一个网段，否则添加节点会错误。不同节点之间访问需要在防火墙开启端口 192.168.1.1021234567891011docker exec -it emqx-node2 sh/opt/emqx $ cd bin//opt/emqx/bin $ ./emqx_ctl cluster join emqx@192.168.1.100=CRITICAL REPORT==== 23-Jun-2021::08:37:01.907458 ===[EMQ X] emqx shutdown for joinJoin the cluster successfully.Cluster status: #&#123;running_nodes =&gt; [&apos;emqx@192.168.1.100&apos;,&apos;emqx@192.168.1.102&apos;], stopped_nodes =&gt; []&#125;/opt/emqx/bin $ emqx_ctl cluster statusCluster status: #&#123;running_nodes =&gt; [&apos;emqx@192.168.1.100&apos;,&apos;emqx@192.168.1.102&apos;], stopped_nodes =&gt; []&#125; emqx_ctl cluster join emqx@192.168.1.100 加入集群 emqx_ctl cluster status 查看集群状态 192.168.1.100进入 192.168.1.100 查看集群状态1234[root@master ~]# docker exec -it emqx-node1 sh/opt/emqx $ ./bin/emqx_ctl cluster statusCluster status: #&#123;running_nodes =&gt; [&apos;emqx@192.168.1.100&apos;,&apos;emqx@192.168.1.102&apos;], stopped_nodes =&gt; []&#125; 端口说明 1883: MQTT 协议端口 8883: MQTT/SSL 端口 8083: MQTT/WebSocket 端口 8080: HTTP API 端口 18083: Dashboard 管理控制台端口 使用 Dashboard 查看集群状态 url: http://192.168.1.100:18083 user:admin pwd:admin@123 负载均衡参考文档：https://docs.emqx.cn/broker/v4.3/tutorial/deploy.html#私有网络部署 Nginx 负载均衡Nginx 产品作为 EMQ X 集群 LB，并终结 SSL 连接: 创建 EMQ X 节点集群，例如: 节点 IP 地址 emqx1 192.168.0.2 emqx2 192.168.0.3 配置 /etc/nginx/nginx.conf，示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960stream &#123; upstream stream_backend &#123; zone tcp_servers 64k; hash $remote_addr; server 192.168.0.2:1883 max_fails=2 fail_timeout=30s; server 192.168.0.3:1883 max_fails=2 fail_timeout=30s; &#125; server &#123; listen 8883 ssl; status_zone tcp_server; proxy_pass stream_backend; proxy_buffer_size 4k; ssl_handshake_timeout 15s; ssl_certificate /etc/emqx/certs/cert.pem; ssl_certificate_key /etc/emqx/certs/key.pem; &#125;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; map $http_upgrade $connection_upgrade &#123; default upgrade; &apos;&apos; close; &#125; upstream stream_ws &#123; #ip_hash; server 192.168.1.100:8083; server 192.168.1.102:8083; &#125; server &#123; listen 12884; location /mqtt &#123; proxy_pass http://stream_ws; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; &#125; &#125; include /etc/nginx/conf.d/*.conf;&#125; Docker启动Nginx负载均衡nginx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172user nginx;worker_processes auto;error_log /var/log/nginx/error.log notice;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;stream &#123; upstream stream_backend &#123; zone tcp_servers 64k; hash $remote_addr; server 192.168.1.100:1883 max_fails=2 fail_timeout=30s; server 192.168.1.102:1883 max_fails=2 fail_timeout=30s; &#125; server &#123; listen 12883; proxy_pass stream_backend; proxy_buffer_size 4k; # ssl_handshake_timeout 15s; # ssl_certificate /etc/emqx/certs/cert.pem; # ssl_certificate_key /etc/emqx/certs/key.pem; &#125;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; map $http_upgrade $connection_upgrade &#123; default upgrade; &apos;&apos; close; &#125; upstream stream_ws &#123; #ip_hash; server 192.168.1.100:8083; server 192.168.1.102:8083; &#125; server &#123; listen 12884; location /mqtt &#123; proxy_pass http://stream_ws; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; &#125; &#125; include /etc/nginx/conf.d/*.conf;&#125; 启动容器1docker run --name mqtt-cluster-nginx -p 12883:12883 -p 12884:12884 -v /usr/local/docker/nginx/nginx.conf:/etc/nginx/nginx.conf -v /usr/local/docker/nginx/log:/var/log/nginx -d nginx:stable-perl 节点挂掉的情况节点挂掉再启动会自动加入集群","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"mqtt","slug":"mqtt","permalink":"https://blog.smilexin.cn/tags/mqtt/"},{"name":"EMQX","slug":"EMQX","permalink":"https://blog.smilexin.cn/tags/EMQX/"}]},{"title":"基于Docker搭建Redis哨兵模式","slug":"基于Docker搭建Redis哨兵模式","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-25T06:33:31.557Z","comments":true,"path":"2021/06/23/基于Docker搭建Redis哨兵模式.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/23/基于Docker搭建Redis哨兵模式.html","excerpt":"","text":"生产环境使用三台服务器搭建redis哨兵集群，3个redis实例（1主2从）+ 3个哨兵实例。生产环境能够保证在哨兵存活两台的情况下，只有一台redis能够继续提供服务（一主两从三哨兵） Redis 的 Sentinel 文档：http://www.redis.cn/topics/sentinel.html 集群信息 宿主机IP port 类型 isMaster 镜像版本 容器名称 192.168.1.100 6379 Redis TRUE redis:alpine3.13 redis-node1 192.168.1.101 6379 Redis FALSE redis:alpine3.13 redis-node2 192.168.1.102 6379 Redis FALSE redis:alpine3.13 redis-node3 192.168.1.100 26379 Sentinel - redis:alpine3.13 redis_sentinel1 192.168.1.101 26379 Sentinel - redis:alpine3.13 redis_sentinel2 192.168.1.102 26379 Sentinel - redis:alpine3.13 redis_sentinel3 启动Redis服务123docker run -d --name redis-node1 --restart=always -p 6379:6379 redis:alpine3.13 --requirepass Admin@123 --masterauth Admin@123docker run -d --name redis-node2 --restart=always -p 6379:6379 redis:alpine3.13 --requirepass Admin@123 --masterauth Admin@123docker run -d --name redis-node3 --restart=always -p 6379:6379 redis:alpine3.13 --requirepass Admin@123 --masterauth Admin@123 -d 以守护进程模式运行 -p 将容器的6379端口映射到宿主机的6379端口 --requirepass 设置redis密码 --masterauth 设置连接主服务的密码，需要和requirepass设置一样 查看容器IP地址123docker inspect redis-node1|egrep -w &quot;IPAddress&quot; # node1: 172.17.0.6docker inspect redis-node2|egrep -w &quot;IPAddress&quot; # node2: 172.17.0.2docker inspect redis-node3|egrep -w &quot;IPAddress&quot; # node3: 172.17.0.2 配置从库redis-node212345678910111213141516171819202122232425262728[root@node-1 ~]# docker exec -it redis-node2 /bin/sh/data # redis-cli -a Admin@123Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe.127.0.0.1:6379&gt; SLAVEOF 192.168.1.100 6379 # 配置master节点主机映射后的的IP PortOK127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.1.100master_port:6379master_link_status:upmaster_last_io_seconds_ago:2master_sync_in_progress:0slave_repl_offset:14slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:d3d275d21d1a7a3930497fc37c30ef40c9c26369master_replid2:0000000000000000000000000000000000000000master_repl_offset:14second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:14127.0.0.1:6379&gt; redis-node3node3同node2操作一致12345678910111213141516171819202122232425262728[root@node-2 ~]# docker exec -it redis-node3 /bin/sh/data # redis-cli -a Admin@123Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe.127.0.0.1:6379&gt; SLAVEOF 192.168.1.100 6379OK127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.1.100master_port:6379master_link_status:upmaster_last_io_seconds_ago:2master_sync_in_progress:0slave_repl_offset:238slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:d3d275d21d1a7a3930497fc37c30ef40c9c26369master_replid2:0000000000000000000000000000000000000000master_repl_offset:238second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:225repl_backlog_histlen:14127.0.0.1:6379&gt; 配置哨兵建立sentinel.conf配置文件,内容如下：12345678sentinel monitor mymaster 192.168.1.100 6379 2sentinel down-after-milliseconds mymaster 20000sentinel failover-timeout mymaster 180000sentinel parallel-syncs mymaster 1sentinel auth-pass mymaster Admin@123logfile &quot;/data/log.txt&quot;port 26379daemonize yes sentinel monior mymaster 192.168.1.100 6379 2配置指示 Sentinel 去监视一个名为 mymaster 的主服务器， 这个主服务器的 IP 地址为 192.168.1.100 ， 端口号为 6379 ， 而将这个主服务器判断为失效至少需要 2 个 Sentinel 同意 （只要同意 Sentinel 的数量不达标，自动故障迁移就不会执行） daemonize yes以守护进程方式运行 sentinel auth-pass mymaster &lt;password&gt;验证主redis密码 sentinel down-after-milliseconds mymaster 20000如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 将这个服务器标记为主观下线（subjectively down，简称 SDOWN ）。不过只有一个 Sentinel 将服务器标记为主观下线并不一定会引起服务器的自动故障迁移： 只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（objectively down， 简称 ODOWN ）， 这时自动故障迁移才会执行。 sentinel failover-timeout mymaster 180000180秒超时，当主服务器失效时， 在不询问其他 Sentinel 意见的情况下， 强制开始一次自动故障迁移 （不过发起故障转移的 Sentinel 会向其他 Sentinel 发送一个新的配置，其他 Sentinel 会根据这个配置进行相应的更新） logfile &quot;/data/log.txt&quot;日志输出位置 parallel-syncs指定在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。你可以通过将这个值设为 1 来保证每次只有一个从服务器处于不能处理命令请求的状态。 Example sentinel.conf12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# Example sentinel.conf # 哨兵sentinel实例运行的端口 默认26379port 26379 # 哨兵sentinel的工作目录dir /tmp # 哨兵sentinel监控的redis主节点的 ip port # master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。# quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster 192.168.1.108 6379 2 # 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster MySUPER--secret-0123passw0rd # 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;sentinel down-after-milliseconds mymaster 30000 # 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，#这个数字越小，完成failover所需的时间就越长，#但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。#可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;sentinel parallel-syncs mymaster 1 # 故障转移的超时时间 failover-timeout 可以用在以下这些方面： #1. 同一个sentinel对同一个master两次failover之间的间隔时间。#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。#3.当想要取消一个正在进行的failover所需要的时间。 #4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了# 默认三分钟# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;sentinel failover-timeout mymaster 180000 # SCRIPTS EXECUTION #配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。#对于脚本的运行结果有以下规则：#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 #通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，#这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，#一个是事件的类型，#一个是事件的描述。#如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。#通知脚本# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel notification-script mymaster /var/redis/notify.sh # 客户端重新配置主节点参数脚本# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。# 以下参数将会在调用脚本时传给脚本:# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;# 目前&lt;state&gt;总是“failover”,# &lt;role&gt;是“leader”或者“observer”中的一个。 # 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的# 这个脚本应该是通用的，能被多次调用，不是针对性的。# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;sentinel client-reconfig-script mymaster /var/redis/reconfig.sh 启动哨兵在三台服务器上都执行下面语句，启动哨兵服务。1docker run -it --name redis_sentinel --restart=always -p 26379:26379 -v /usr/local/docker/redis/sentinel.conf:/data/sentinel.conf -d redis:alpine3.13 验证哨兵随便进入一个哨兵容器进行查看12345678910[root@master data]# docker exec -it redis_sentinel sh/data # redis-cli -p 26379127.0.0.1:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=192.168.1.100:6379,slaves=2,sentinels=3 测试哨兵地址连接 192.168.1.100:26379 192.168.1.101:26379 192.168.1.102:26379 经过本人多次模拟master挂掉的情况，能够正常切换master并提供服务","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Redis","slug":"Redis","permalink":"https://blog.smilexin.cn/tags/Redis/"}]},{"title":"ElasticSearch之修改shards数","slug":"ElasticSearch之修改shards数","date":"2021-06-20T16:00:00.000Z","updated":"2021-06-21T06:17:42.510Z","comments":true,"path":"2021/06/21/ElasticSearch之修改shards数.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/21/ElasticSearch之修改shards数.html","excerpt":"","text":"今天突然发现开发环境的 SkywalkingUI 没有数据显示了 通过查看skywalking-oap-server日志中发现大量的以下内容报错： [150]: index [sw_segment-20210621], type [_doc], id [5411d1d0da7d47408ca1b7e0fb6501eb.35.16242471306362196], message [ElasticsearchException[Elasticsearch exception [type=validation_exception, reason=Validation Failed: 1: this action would add [5] total shards, but this cluster currently has [1000]/[1000] maximum shards open;]]] 这个问题是ES的索引不够导致的 网上说此问题是因为elasticsearch7以上默认只有1000个分片，超过这个数新收集的日志就没地方存储、展示 所以需要扩大ES的shards数 方法如下： 在ES的主机上执行下列命令：1curl -XPUT -H &quot;Content-Type:application/json&quot; -d &apos;&#123;&quot;persistent&quot;:&#123;&quot;cluster&quot;:&#123;&quot;max_shards_per_node&quot;:10000&#125;&#125;&#125;&apos; &apos;http://es-host:9200/_cluster/settings&apos;","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.smilexin.cn/tags/ElasticSearch/"}]},{"title":"基于Docker搭建MySQL主从复制","slug":"基于Docker搭建MySQL主从复制","date":"2021-06-17T16:00:00.000Z","updated":"2021-06-21T10:01:06.269Z","comments":true,"path":"2021/06/18/基于Docker搭建MySQL主从复制.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/18/基于Docker搭建MySQL主从复制.html","excerpt":"","text":"数据库安装主从信息 ip port 类型 镜像版本 容器名称 192.168.1.100 3306 主库 8.0.25 mysql-master-3306 192.168.1.100 3307 从库 8.0.25 mysql-slave01-3307 创建 MySQL 目录123mkdir -p /usr/local/docker/mysqlcd /usr/local/docker/mysqlmkdir master_3306 slave01_3307 准备my.cnf 这里准备这个配置文件的主要目的是为了后续方便主从的配置；使用的就是8.0.25版本对应的my.cnf；是预先从容器的/etc/mysql目录中拷贝出来的；如果你使用的不同的mysql镜像版本，可以按以下方式去拷贝出一份对应版本的my.cnf。 123456789101112131415# 如果你使用的是其他的版本，可以将8.0.25更换为你所使用的版本docker run --name mysql-test -p 6033:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:8.0.25# 查看镜像是否运行成功 下面指令如果可以找到对应的详细信息，说明成功docker ps# 将容器/etc/mysql/my.cnf文件拷贝到当前目录docker cp mysql-test:/etc/mysql/my.cnf /usr/local/docker/mysql# 查看是否拷贝成功ll /usr/local/docker/mysql# 将文件拷贝到各自的工作目录cp /usr/local/docker/mysql/my.cnf /usr/local/docker/mysql/master_3306cp /usr/local/docker/mysql/my.cnf /usr/local/docker/mysql/slave01_3307 主库123456789101112131415# 进入master_3306的工作目录cd /usr/local/docker/mysql/master_3306docker run \\-p 3306:3306 \\--name mysql-master-3306 \\-v $PWD/conf:/etc/mysql/conf.d \\-v $PWD/my.cnf:/etc/mysql/my.cnf \\-v $PWD/logs:/logs \\-v $PWD/data:/var/lib/mysql \\-v $PWD/tmp:/tmp \\-v /etc/localtime:/etc/localtime:ro \\-e TZ=Asia/Shanghai \\-e MYSQL_ROOT_PASSWORD=123456 \\-d mysql:8.0.25 从库123456789101112131415# 进入slave01_3307的工作目录cd /usr/local/docker/mysql/slave01_3307docker run \\-p 3307:3306 \\--name mysql-slave01-3307 \\-v $PWD/conf:/etc/mysql/conf.d \\-v $PWD/my.cnf:/etc/mysql/my.cnf \\-v $PWD/logs:/logs \\-v $PWD/tmp:/tmp \\-v $PWD/data:/var/lib/mysql \\-v /etc/localtime:/etc/localtime:ro \\-e TZ=Asia/Shanghai \\-e MYSQL_ROOT_PASSWORD=123456 \\-d mysql:8.0.25 配置说明 -p 用于映射端口，如上所示分别将宿主机的3306、3307分别映射到容器master01和slave01的3306端口上 –name 设置容器的名称 -v 设置映射，将宿主机的目录映射到容器的目录；主要用于持久化关键数据，如/data目录就是用来持久化数据库文件的，这样就算是容器被remove掉之后，数据库的持久化文件依然还在，下次使用这个持久化文件启动一个新的容器数据依然还在。 -e 设置参数；MYSQL_ROOT_PASSWORD为数据库的root密码；TZ用来设置时区 -d 后台运行容器 支持外部IP访问主库从库都需要配置一下1234567# 进入容器docker exec -it mysql-master-3306 bash# 连接mysqlmysql -uroot -p# 切换到mysql数据库use mysqlALTER USER&apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;; navicat连接测试 配置主从主库配置123456789101112131415161718192021vi /usr/local/docker/mysql/master_3306/my.cnf## 添加以下配置# 集群唯一id# 同个局域网内唯一 所以可以使用ip的最后一段用来作为id 如192.168.1.123，那就把id设置为123，方便查找为题# 这里由于使用的docker，且在一台机器上面，所以就用1 2来表示，实际使用过程中，没有谁会将主从部署在同一台机器上的server-id=1# 开启二进制日志功能log-bin=mysql-master01-bin# 设置要同步的数据库，这里的t_mall为测试同步到数据库名# 如果不设置标识全部同步# binlog-do-db=t_mall# 设置屏蔽系统默认的数据库binlog-ignore-db=mysqlbinlog-ignore-db=information_schemabinlog-ignore-db=performance_schema# sql_mode 关闭only_full_group_bysql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 从库配置123456789101112131415161718192021vi /usr/local/docker/mysql/slave_3307/my.cnf# 从库不限制数据导出目录secure-file-priv=# 集群唯一idserver-id=2# 开启二进制日志功能log-bin=mysql-slave01-bin# 设置同步的库#replicate_wild_do_table=t_mall.%# 设置忽略的库replicate_wild_ignore_table=mysql.%replicate_wild_ignore_table=information_schema.%replicate_wild_ignore_table=performance_schema.%# sql_mode 关闭only_full_group_bysql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 重启数据库1docker restart mysql-master-3306 mysql-slave01-3307 在主库创建用于复制操作的用户12345-- repl的%可以改为从库的ip地址mysql&gt; CREATE USER &apos;repl&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;%&apos;;mysql&gt; flush privileges; -- 刷新授权表信息mysql&gt; SHOW MASTER STATUS; -- 获取主节点当前binary log文件名和位置（position） 在从（Slave）节点上设置主节点参数123456789mysql&gt; STOP SLAVE;mysql&gt; CHANGE MASTER TOMASTER_HOST=&apos;192.168.1.100&apos;,MASTER_USER=&apos;repl&apos;,MASTER_PASSWORD=&apos;123456&apos;,MASTER_LOG_FILE=&apos;mysql-master01-bin.000002&apos;,MASTER_LOG_POS=156;mysql&gt; START SLAVE;mysql&gt; SHOW SLAVE STATUS; Slave_IO_Running 和 Slave_SQL_Running 必须为Yes 到这里，MySQL的主从复制就已经搭建完成了，这里是基于Docker的搭建，基于操作系统的安装和使用Docker的本质是没有什么不同的；但是使用Docker对系统的污染较少且处理异常更方便，所以个人是比较推荐使用Docker搭建！","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"}]},{"title":"基于Docker的MySQL常用备份及恢复命令","slug":"基于Docker的MySQL常用备份及恢复命令","date":"2021-06-17T16:00:00.000Z","updated":"2021-06-21T10:02:40.301Z","comments":true,"path":"2021/06/18/基于Docker的MySQL常用备份及恢复命令.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/18/基于Docker的MySQL常用备份及恢复命令.html","excerpt":"","text":"创建备份文件的目录1mkdir -p /home/mysql_bak 备份数据备份mydb1数据库中所有的表结构及数据1docker exec mysql-slave01 mysqldump -uroot -p123456 mydb1 &gt; /home/mysql_bak/mydb1.sql 只导出数据不导出结构1docker exec mysql-slave01 mysqldump -t -uroot -p123456 mydb1 &gt; /home/mysql_bak/mydb1_data.sql 只导出结构不导出数据1docker exec mysql-slave01 mysqldump --opt -d -uroot -p123456 mydb1 &gt; /home/mysql_bak/mydb1_struct.sql 导出特定表结构1docker exec mysql-slave01 mysqldump -uroot -p123456 mydb1 sys_user &gt; /home/mysql_bak/sys_user.sql 恢复数据123docker cp /home/mysql_bak/mydb1.sql mysql-slave01:/root/docker exec -it mysql-slave01 /bin/bashmysql -uroot -p kitty_backup &lt; /root/mydb1.sql 问题解决：使用 crontab 执行脚本备份数据为空先看备份脚本1docker exec -it mysql-slave01 mysqldump -uroot -p123456 mydb1 &gt; /home/mysql_bak/mydb1.sql 乍一看上去是没问题的，但是crontab定时执行的时候dump出来的文件大小始终是0，后来发现去掉-it就可以了，按照文档解释-t是分配一个伪终端,但是crontab执行的时候实际是不需要的 问题解决：Warning: Using apassword on the command line interface can be insecure.mysql -u root -pPASSWORD 或 mysqldump -u root -pPASSWORD 都会输出这样的警告信息. 解决方法在MYSQL配置文件 my.cnf 里增加以下内容1234567vi my.cnf[mysqldump]user=your_backup_user_namepassword=your_backup_password 修改完配置文件后, 只需要执行mysqldump 脚本就可以了;备份脚本中不需要涉及用户名密码相关信息;1docker exec mysql-slave01-3307 mysqldump test2 &gt; /home/mysqlbak/test2_data.sql 使用crontab定时执行备份脚本mysqlbak.sh123456789101112131415# Name:mysqlbak.sh# This is a ShellScript For Auto MySQL Backup and Delete old Backupbakdir=/home/mysqlbaktime=` date +%Y%m%d%H%M%S`if [ ! -d $bakdir ]; then mkdir -p $bakdirfidocker exec mysql-slave01-3307 mysqldump test2 &gt; $bakdir/mysql_test2_$time.sqlfind $bakdir -name &quot;mysql_*.sql&quot; -type f -mtime +10 -exec rm -rf &#123;&#125; \\;echo &apos;mysql backup successful&apos; 配置定时任务1234# 编辑定时任务crontab -e# 每天凌晨1点执行0 1 * * * sh /etc/cron.d/mysqlbak.sh","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"}]},{"title":"使用Rancher部署Skywalking","slug":"使用Rancher部署Skywalking","date":"2021-06-15T16:00:00.000Z","updated":"2021-06-28T07:31:13.371Z","comments":true,"path":"2021/06/16/使用Rancher部署Skywalking.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/16/使用Rancher部署Skywalking.html","excerpt":"","text":"skywalking-oap-server 存储：elasticsearch 7.x 镜像：apache/skywalking-oap-server:8.6.0-es7 collector.backend_service：hostip:30001 skywalking-oap-server 环境变量123456# ElasticSearch 地址SW_STORAGE_ES_CLUSTER_NODES=192.168.1.5:9200# 配置使用的存储类型SW_STORAGE=elasticsearch7# 配置明细记录的有效期 recordDataTTL ，默认是三天SW_CORE_RECORD_DATA_TTL=15 数据清理机制有关的配置12345678910111213141516171819202122232425262728# Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.enableDataKeeperExecutor: $&#123;SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true&#125; # Turn it off then automatically metrics data delete will be close.dataKeeperExecutePeriod: $&#123;SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5&#125; # How often the data keeper executor runs periodically, unit is minuterecordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:3&#125; # Unit is daymetricsDataTTL: $&#123;SW_CORE_METRICS_DATA_TTL:7&#125; # Unit is day# Cache metrics data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,# the metrics may not be accurate within that minute.enableDatabaseSession: $&#123;SW_CORE_ENABLE_DATABASE_SESSION:true&#125;topNReportPeriod: $&#123;SW_CORE_TOPN_REPORT_PERIOD:10&#125; # top_n record worker report cycle, unit is minute# Extra model column are the column defined by in the codes, These columns of model are not required logically in aggregation or further query,# and it will cause more load for memory, network of OAP and storage.# But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana-&gt;ES, to query the data by themselves.activeExtraModelColumns: $&#123;SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false&#125;# The max length of service + instance names should be less than 200serviceNameMaxLength: $&#123;SW_SERVICE_NAME_MAX_LENGTH:70&#125;instanceNameMaxLength: $&#123;SW_INSTANCE_NAME_MAX_LENGTH:70&#125;# The max length of service + endpoint names should be less than 240endpointNameMaxLength: $&#123;SW_ENDPOINT_NAME_MAX_LENGTH:150&#125;# Define the set of span tag keys, which should be searchable through the GraphQL.searchableTracesTags: $&#123;SW_SEARCHABLE_TAG_KEYS:http.method,status_code,db.type,db.instance,mq.queue,mq.topic,mq.broker&#125;# Define the set of log tag keys, which should be searchable through the GraphQL.searchableLogsTags: $&#123;SW_SEARCHABLE_LOGS_TAG_KEYS:level&#125;# Define the set of alarm tag keys, which should be searchable through the GraphQL.searchableAlarmTags: $&#123;SW_SEARCHABLE_ALARM_TAG_KEYS:level&#125;# The number of threads used to synchronously refresh the metrics data to the storage.syncThreads: $&#123;SW_CORE_SYNC_THREADS:2&#125;# The maximum number of processes supported for each synchronous storage operation. When the number of the flush data is greater than this value, it will be assigned to multiple cores for execution.maxSyncOperationNum: $&#123;SW_CORE_MAX_SYNC_OPERATION_NUM:50000&#125; skywalking-ui 镜像：apache/skywalking-ui:8.6.0 访问地址：主机ip:30100 skywalking_ui skywalking-agent In Kubernetes：https://hub.docker.com/r/apache/skywalking-java-agent java 启动命令 1java -javaagent:./agent/skywalking-agent.jar -jar .\\app1.jar --app2Address=http://localhost:9001 agent 需要修改的配置项12345678910# 命名空间，用于隔离跨进程传播的header。如果进行了配置，header将为HeaderName:Namespace# agent.namespace=$&#123;SW_AGENT_NAMESPACE:default-namespace&#125;# 在SkyWalking UI中展示的服务名。建议：为每个服务设置个唯一的名字，服务的多个服务实例为同样的服务名agent.service_name=$&#123;SW_AGENT_NAME:app1&#125;# 接收skywalking trace数据的后端地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.1.101:30644&#125;# 收集SpringMVC请求参数plugin.springmvc.collect_http_params=true# 请求参数收集的最大字符长度, 配置过大会影响性能.plugin.http.http_params_length_threshold=1024 Java Agent配置方式agent配置有多种姿势，上面修改 agent.config 文件中的值，只是其中一种。下面专门探讨agent支持的配置方式。 系统属性(-D)使用 -Dskywalking. + agent.config配置文件中的key 即可。例如：agent.config 文件中有一个属性名为 agent.service_name ，那么如果使用系统属性的方式，则可以写成 1java -javaagent:/opt/agent/skywalking-agent.jar -Dskywalking.agent.service_name=你想设置的值 -jar somr-spring-boot.jar 代理选项在JVM参数中的代理路径之后添加属性即可。格式：-javaagent:/path/to/skywalking-agent.jar=[option1]=[value1],[option2]=[value2]例如： 1java -javaagent:/opt/agent/skywalking-agent.jar=agent.service_name=你想设置的值 -jar somr-spring-boot.jar 系统环境变量agent.config 文件中默认的大写值，都可以作为环境变量引用。例如，agent.config 中有如下内容 1agent.service_name=$&#123;SW_AGENT_NAME:Your_ApplicationName&#125; 这说明Skywalking会读取名为 SW_AGENT_NAME 的环境变量。 优先级 代理选项 &gt; 系统属性（-D） &gt; 系统环境变量 &gt; 配置文件 服务之间调用注意：服务之间的调用，需要用spring提供的restTemplate，不要直接用apache的httpclient工具包 使用 SkyWalking 和 Envoy 访问日志服务对服务网格进行观察http://skywalking.apache.org/zh/observe-service-mesh-with-skywalking-and-envoy-access-log-service/","categories":[],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://blog.smilexin.cn/tags/Kubernetes/"},{"name":"Skywalking","slug":"Skywalking","permalink":"https://blog.smilexin.cn/tags/Skywalking/"},{"name":"Rancher","slug":"Rancher","permalink":"https://blog.smilexin.cn/tags/Rancher/"}]},{"title":"Kubernetes下安装Skywalking","slug":"Kubernetes下安装Skywalking","date":"2021-06-10T16:00:00.000Z","updated":"2021-06-11T09:19:42.712Z","comments":true,"path":"2021/06/11/Kubernetes下安装Skywalking.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/11/Kubernetes下安装Skywalking.html","excerpt":"","text":"环境介绍 确保有一套运行正常的 Kubernetes 集群，本文默认为使用 Elasticsearch7 作为后端存储。 确保你本地的 kubectl能够正常运行。 Skywalking 介绍Skywalking 在大体上分为四大部分: oap-server: 无状态服务后端，主要负责处理核心逻辑，可以简单理解为一个标准 java web 项目。 skywalking-ui: UI 前端，通过 graphql 连接 oap-server 提供用户查询等 UI 展示。 agent: 各种语言实现的 agent 负责抓取应用运行数据并上报给 oap-server，核心的指标上报来源。 DB: 各种数据库，负责存储 Skywalking 的指标数据，生产环境推荐 ES、TiDB、MySQL。 安装 Elasticsearch123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778cat &gt; elasticsearch-single.yaml &lt;&lt; EOFapiVersion: apps/v1kind: Deploymentmetadata: name: elasticsearch-single namespace: efk labels: k8s-app: elasticsearch-singlespec: replicas: 1 selector: matchLabels: k8s-app: elasticsearch-single template: metadata: labels: k8s-app: elasticsearch-single spec: containers: - image: elasticsearch:7.12.0 name: elasticsearch-single resources: limits: cpu: 2 memory: 3Gi requests: cpu: 0.5 memory: 500Mi env: - name: &quot;discovery.type&quot; value: &quot;single-node&quot; - name: ES_JAVA_OPTS value: &quot;-Xms512m -Xmx2g&quot; ports: - containerPort: 9200 name: db protocol: TCP volumeMounts: - name: elasticsearch-data mountPath: /usr/share/elasticsearch/data volumes: - name: elasticsearch-data persistentVolumeClaim: claimName: es-pvc---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: es-pvc namespace: efkspec:#指定动态PV 名称 storageClassName: &quot;elastic-nfs-client&quot; accessModes: - ReadWriteMany resources: requests: storage: 10Gi---apiVersion: v1kind: Servicemetadata: name: elasticsearch-single namespace: efkspec: ports: - port: 9200 protocol: TCP targetPort: 9200 selector: k8s-app: elasticsearch-singleEOFkubectl apply -f elasticsearch-single.yaml 部署 Skywalking安装 Helm由于 Skywalking 官方给出的 Kubernetes 安装方式为 Helm 安装，所以需要本地先安装 Helm；Helm 安装方式非常简单，根据官方文档在网络没问题的情况下直接执行以下命令即可:1curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash 如果网络不是那么 OK 的情况下请参考官方文档的包管理器方式安装或直接下载二进制文件安装。 初始化 skywalking 的 charts 配置Helm 部署之前按照官方文档提示需要先初始化 Helm 仓库:12345678910# clone helm 仓库git clone https://github.com/apache/skywalking-kubernetescd skywalking-kubernetes/chart# 即使使用外部 ES 也要添加这个 repo，否则会导致依赖错误helm repo add elastic https://helm.elastic.cohelm dep up skywalking# 创建 skywalking 的 namespacekubectl create namespace skywalking 安装 skywalking初始化完成后需要自行调整配置文件，配置 oap-server 使用外部 ES，当然你也可以使用 values 自带的 es 的配置示例，这里不做过多介绍1234567891011121314151617181920212223cat &gt; skywalking/values-my-es-01.yaml &lt;&lt;EOFoap: image: tag: 8.4.0-es7 storageType: elasticsearch7ui: image: tag: 8.4.0 service: type: NodePort externalPort: 80 internalPort: 8080 nodePort: 30008elasticsearch: enabled: false config: host: elasticsearch-single.efk port: http: 9200 #user: &quot;&quot; # [optional] #password: &quot;xxx&quot; # [optional]EOF helm 安装 skywalking 8.4.01helm install skywalking skywalking -n skywalking -f ./skywalking/values-my-es-01.yaml 如果安装出错或者其他问题可以使用以下命令进行卸载:1helm uninstall skywalking -n skywalking 持续查看 pod 安装进度1kubectl get pod -n skywalking -w 对外暴露 skywalking 端口，临时，但是本篇我用了 NodePort 的方法开放了端口，生产中也可以使用 ingress 的方式开放12export POD_NAME=$(kubectl get pods --namespace skywalking -l &quot;app=skywalking,release=skywalking,component=ui&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)kubectl port-forward $POD_NAME 8080:8080 --namespace skywalking 查看 skywalking 的访问：其实就是 k8s master/node ip + nodeport123export NODE_PORT=$(kubectl get --namespace skywalking -o jsonpath=&quot;&#123;.spec.ports[0].nodePort&#125;&quot; services skywalking-ui)export NODE_IP=$(kubectl get nodes --namespace skywalking -o jsonpath=&quot;&#123;.items[0].status.addresses[0].address&#125;&quot;)echo http://$NODE_IP:$NODE_PORT 运行状态检查12345678910[root@node01 chart]# kubectl get pod,svc -n skywalkingNAME READY STATUS RESTARTS AGEpod/skywalking-es-init-22g88 0/1 Completed 0 115spod/skywalking-oap-687f98bd9b-p5d69 1/1 Running 0 114spod/skywalking-oap-687f98bd9b-wxffb 1/1 Running 0 114spod/skywalking-ui-6fd5544496-cmmf9 1/1 Running 0 115sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/skywalking-oap ClusterIP 10.0.0.88 &lt;none&gt; 12800/TCP,11800/TCP 115sservice/skywalking-ui NodePort 10.0.0.87 &lt;none&gt; 80:30553/TCP 115s 到这里一切正常的话,Elasticsearch里会多出很多index Agent 配置 Skywalking 在简单使用时不需要侵入代码，对于 jar 包启动的项目只需要在启动时增加 -javaagent 选项即可。 Agent 获取javaagent 可以通过下载对应的 skywalking release 安装包获取，将此 agent 目录解压到任意位置，稍后将添加到 java 启动参数。 Agent 配置Agent 主配置文件存放在 config/agent.config 配置文件中，配置文件内支持环境变量读取，可以自行添加其他配置和引用其他变量；通常这个配置文件在容器化时有两种选择，一种是创建 ConfigMap，然后通过 ConfigMap 挂载到容器里进行覆盖；另一种是在默认配置里引用各种变量，在容器启动时通过环境变量注入。 agent.config agent.config deployment.yml deployment.yml 注意事项 默认情况下 Helm 相关命令执行缓慢，可能需要设置 http(s)_proxy …( ＿ ＿)ノ｜壁(自行体会这个表情) Skywalking 镜像一般比较大，下载缓慢，推荐预先拉取好然后 load 到每个节点 ES 如果设置了密码，不要忘记在 Helm 安装时调整好密码配置 jar 包启动时 -javaagent 不能放在 -jar 选项之后，否则可能不生效 集群内连接 oap-server 推荐通过 skywalking-oap.skywalking.svc.cluster.local 域名服务发现方式寻址","categories":[],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://blog.smilexin.cn/tags/Kubernetes/"},{"name":"Skywalking","slug":"Skywalking","permalink":"https://blog.smilexin.cn/tags/Skywalking/"}]},{"title":"Linux 安装ffmpeg","slug":"Linux 安装ffmpeg","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T08:55:04.852Z","comments":true,"path":"2021/06/01/Linux 安装ffmpeg.html","link":"","permalink":"https://blog.smilexin.cn/2021/06/01/Linux 安装ffmpeg.html","excerpt":"","text":"安装ffmpeg首先去官网下载源码包 http://ffmpeg.org/download.html#releases 我这里下载的是ffmpeg-4.4.tar.gz，下载之后上传至Linux准备安装。 解压安装包，然后进到ffmpeg文件目录下面：1234tar -xjvf ffmpeg-4.4.tar.gzcd ffmpeg-4.4./configure --enable-shared --prefix=/usr/local/ffmpeg //自己想要存放的地方make &amp;&amp; make install 可能会报如下的错误：yasm/nasm 包不存在或者很旧 出现这个错误需要安装yasm。下载地址：http://yasm.tortall.net/Download.html1234tar -xvzf yasm-1.3.0.tar.gzcd yasm-1.3.0/./configuremake &amp;&amp; make install 编译参数都是默认的，直接安装到系统中即可，安装成功之后继续回到ffmpeg解压后的目录，执行下面命令编译并安装：12./configure --enable-shared --prefix=/mydir/ffmpeg //自己想要存放的地方make &amp;&amp; make install 这里编译时间非常长，等待的时间可以去喝杯coffee压压惊 好了之后执行cd /mydir/ffmpeg 进入安装目录，查看一下发现有bin,include,lib,share这4个目录，其中bin是ffmpeg主程序二进制目录，include是C/C++头文件目录，lib是编译好的库文件目录，share是文档目录，然后进入bin目录，执行 ./ffmpeg -version 查看当前版本的详细信息，默认情况下一般会报libavdevice.so.57: cannot open shared object file: No such file or directory，原因是lib目录未加载到链接到系统库中。 添加这些库：vi /etc/ld.so.conf添加一行内容： /mydir/ffmpeg/lib保存并退出然后执行 sudo ldconfig 重新加载资源使配置生效，现在再次执行 ./ffmpeg -version 显示就正常了 然后可以根据需要将bin目录添加至环境变量中以保证任何时候都能使用ffmpeg命令1vi /etc/profile 添加下面这行1export PATH=/mydir/ffmpeg/bin:$PATH 保存退出，运行profile1source /etc/profile 全局ffmpeg生效到这ffmpeg安装完成并且生效","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://blog.smilexin.cn/tags/ffmpeg/"}]},{"title":"我的健身记录贴","slug":"我的健身记录贴","date":"2021-05-24T16:00:00.000Z","updated":"2021-08-27T07:50:15.127Z","comments":true,"path":"2021/05/25/我的健身记录贴.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/25/我的健身记录贴.html","excerpt":"","text":"说明从2021-05-25开始正式记录训练内容 三分化训练和五分化训练 五分化胸背腿肩臂 三分化3分化训练计划主要分为推，拉，腿。主练大肌群，小肌群最后做两个动作，一个四组就行了，推，拉，腿。 推：平板卧推，上斜卧推，高位龙门架夹胸，推肩，杠铃推举，哑铃推举，侧平举，然后三头来两个动作，一个四组。 拉：引体向上，杠铃划船，高位下拉，坐姿划船，绳索面拉练肩后束，然后练二头。 腿就不用说了吧 增肌饮食推荐每kg体重1.5-2g蛋白 每kg体重碳水3g 每kg体重脂肪1g 3-4次力量穿插2次低强度有氧促进恢复 只要不吃火锅汉堡什么的，不会很肥的 训练方法以偏向力量举为主 不要太沉迷于孤立训练 说明 哑铃重量为单个哑铃。 例：双手各拿10kg的哑铃进行卧推，则记录哑铃卧推10kg。 杠铃重量为整体的片。 例：杠铃左右各上5kg的片进行卧推，则记录杠铃卧推10kg。 固定器械则为插销的标记重量。 动作提醒哑铃卧推哑铃卧推肘部微微内收可以极大减小对肩部的压力。具体角度自己可以先用小重量感受。 2021-05-25 星期二（肩）今日体重未称重 训练内容 哑铃侧平举4kg 12 12 12 12 坐姿俯身哑铃侧平举4kg（训练后束） 8 8 8 8 坐姿哑铃推举 10kg 10 11 12 10 12kg 8 8 8 史密斯颈后推举5kg 8 8 8 龙门架绳索面拉（8kg?）（后束）8 8 8 哑铃8kg/曲杆杠铃15kg提拉 8 8 8 2021-05-26 星期三（胸）今日体重未称重 训练内容 平躺哑铃热身胸部 蝴蝶机夹胸18kg 20 16 12 哑铃上斜卧推 8kg 12 10kg 10 12kg 10 14kg 8 10 11 10 16kg 7 8 8 杠铃上斜卧推10kg 6 7 6 固定器械把座椅垫高推下胸 27kg 8 12 36kg 8 8 10 俯身双杠臂屈伸（下胸）54kg↑ 10 10 10 蝴蝶机夹胸27kg 10 10 10 10 练后总结胸部充血良好,今天更喜欢哑铃卧推,感觉杠铃推起来有点别手。 2021-05-27 星期四（背）今日体重未称重 训练内容 直臂下压练背27kg 12 12 8 8 宽距引体向上59kg↑ 8 8 8 8 麒麟抱拉15kg 12 12 12 12 划船超级组(ab动作一轮为一组，动作a做了立马做动作b) 动作a：器械单手划船12.5kg 10 10 10 10 动作b：器械双手划船25kg 6 8 10 8 2021-05-28 星期五（腿&amp;手臂）今日体重未称重 训练内容快走15分钟热身 杠铃负重深蹲 10kg 10 20kg 8 9 8 8 坐姿蹬腿 33kg 10 12 44kg 12 56kg 8 10 坐姿腿屈伸27kg 10 9 9 9 杠铃弯举15kg 10 9 8 8 绳索下压 27.3kg 10 34.1kg 6 6 6 20.5kg 8 9 9 2021-05-30 星期天（推：胸、肩、三头）今日体重未称重 训练内容 坐姿哑铃推举 10kg 12 12kg 12 14kg 8 8 8 6 哑铃侧平举6kg 8 9 8 8 俯身哑铃侧平举4kg 9 13 12 12 上斜哑铃推胸 8kg 10 12kg 14 16kg 8 9 9 7 固定器械把座椅垫高推下胸 32kg 10 45kg 8 8 7 6 蝴蝶机夹胸27kg 12 12 12 12 绳索下拉 20.5kg 13 27.3kg 8 8 7 6 爬梯10分钟 2021-05-31 星期一（拉：背、肩后束）今日体重未称重 训练内容 引体向上 1 1 1.5 宽距助力引体45kg↑ 8 7 4 7 固定重量杠铃划船25kg 10 12 13 15 2.2米杠铃划船15kg 9 10 11 高位下拉32kg 8 8 8 8 坐姿划船 41kg 8 36kg 8 8 绳索面拉练肩后束20.5kg 8 8 8 8 哑铃弯举8kg 8 8 8 8.5 2021-06-01 星期二（腿）今日体重未称重 训练内容 倒蹬20kg 12 13 12 13 哈克深蹲30kg 8 8 8 8 史密斯深蹲20kg 8 8 8 8 坐姿腿屈伸23kg 10 10 10 11 9 2021-06-02 星期三（胸）今日体重刚吃完午饭：70kg 训练内容 蝴蝶机夹胸27kg 12 12 12 12 上斜哑铃推胸 12kg 12 14kg 8 16kg 9 8 8 9 平板哑铃推胸 14kg 8 16kg 8 平板杠铃卧推20kg 5 5 4.5 2.5 3 固定器械把座椅垫高推下胸 45kg 3 41kg 5 5 5 4.8 练后总结胸部充血良好,平板哑铃卧推做完起身困难。 2021-06-03 星期四（背）今日体重未称重 训练内容 宽距助力引体45kg↑ 8 8 8 6 直臂下压练背 20.5kg 12 8 7 27.3kg 7 8 2.2米杠铃划船 10kg 12 15kg 12 10 12 12 麒麟抱拉15kg 12 12 12 12 坐姿划船30kg 9 9 8.8 8 2021-06-04 星期五（腿）今日体重未称重 训练内容 深蹲40kg 8 8 9 8 倒蹬30kg 12 12 12 12 单腿蹬23kg 6 9 8 8 坐姿腿屈伸 36kg 7 7 27kg 8 8 10 2021-06-05 星期六（肩&amp;手臂）今日体重未称重 训练内容 坐姿哑铃推举 8kg 12 10kg 9 12kg 8 14kg 8 10 8 6 固定器械推举 前束 20kg 8 30kg 5 3 10kg 8 5 哑铃侧平举 6kg 8 9 8 8 坐姿俯身哑铃侧平举6kg 8 9 9 8 史密斯颈后推举 10kg 12 15kg 8 6 6 6 绳索下拉（三头）23kg 10 8 8 8 牧师凳杠铃弯举（二头）20kg 9 8 7 6 双杠臂屈伸（三头） 5 5 5 5 腹肌抬腿 12 12 12 12 2021-06-08 星期二（胸）今日体重未称重 训练内容中午 上斜哑铃推胸 10kg 12 12kg 10 16kg 8 18kg 8 8 9 8晚上 蝴蝶机夹胸32kg 12 12 12 8 5 俯卧撑 10 10 10 上斜哑铃推胸16kg 6 8 8 平板杠铃卧推 30kg 8 35kg 8 8 6 3练后总结杠铃卧推差点受伤，没人保护就不要太勉强… 2021-06-09 星期三（背）今日体重未称重 训练内容 宽距助力引体 36kg↑ 6 6 6 3.8 45kg 3 直臂下压 18kg 8 23kg 8 8 8 高位下拉27kg 8 8 8 12 麒麟抱拉20kg 12 12 12 哑铃划船 10kg 12 12kg 8 10 12 杠铃划船20kg 12 12 12 龙门架划船 36kg 12 12 45kg 12 12 12 12 练后总结龙门架划船简直不要太爽，背炸了。哈哈哈哈哈 2021-06-10 星期四（腿）今日体重未称重 训练内容 深蹲 40kg 10 45kg 9 50kg 8 8 6 倒蹬 30kg 12 40kg 12 12 45kg 9 哈克深蹲50kg 7 8 8 坐姿腿屈伸27kg 12 12 12 10 练后总结快走不得路了 2021-06-11 星期五（肩）今日体重未称重 训练内容 坐姿哑铃推举 10kg 8 14kg 8 8 8 7 7 史密斯推举15kg 8 8 8 8 哑铃测评举 8,6,4,2kg 递减超级组 x 3 绳索面拉23kg 10 12 12 12 宽距划船（背） 23kg 12 32kg 12 12 10 爬梯机 10分钟 2021-06-13 星期天（胸）今日体重未称重 训练内容 俯卧撑 12 12 12 12 哑铃上斜卧推 10kg 8 16kg 8 8 8 8 史密斯平板卧推 20kg 7 7 9 30kg 6 4 史密斯上斜卧推 20kg 7 7 8.5 固定器械推胸 23kg 12 41kg 5 5 4.7 27kg 8 下胸臂屈伸45kg 12 13 13 15 哑铃中缝训练 2021-06-14 星期一（背）今日体重未称重 训练内容 直臂下拉 18kg 8 27kg 12 8 8 助力引体36kg 5 5 6 5 龙门架斜凳高位下拉 41kg 12 54kg 12 10 12 10 坐姿划船32kg 8 10 8 9 反手窄距高位下拉23kg 8 8 10 2021-06-15 星期二（有氧）天气太热了，就做了有氧 训练内容 有氧划船2500米，总共12分钟 2021-06-16 星期三（肩）今日体重未称重 训练内容 坐姿哑铃推举 12kg 8 9 14kg 8 16kg 8 8 6 杠铃提拉20kg 8 9 8 8 哑铃侧平举 10kg 8 8kg 8 8 8 8 坐姿俯身侧平举8kg 8 8 8 8 2021-06-17 星期四（感冒了）感冒了，没力气 ，休息一天。o(╥﹏╥)o 2021-06-19 星期六（胸）今日体重未称重 训练内容 蝴蝶机夹胸27kg 12 12 12 13 史密斯上斜卧推 20kg 9 30kg 7 5 6 5 哈克推胸20kg 7 上斜哑铃卧推 12kg 9 18kg 7 7 6 双杠臂屈伸36kg 7 7 8 8 固定器械推胸 41kg 3.8 36kg 8 8 8 哑铃练中缝 2021-06-23 星期三（背）今日体重未称重 训练内容 助力引体36kg 6 6 5 4 直臂下压23kg 8 8 8 8 窄距划船 23kg 12 27kg 12 32kg 9 9 11 中距划船32kg 8 9 9 宽距龙门架高位下拉 41kg 9 54kg 8 7 高位下拉32kg 8 6 6 2021-06-24 星期四（肩）今日体重未称重 训练内容 坐姿哑铃推举 12kg 7 7 16kg 8 8 8 5 哑铃侧平举8kg 8 8 8 坐姿俯身哑铃侧平举6kg 8 9 8 10 2021-06-25 星期五（胸）今日体重未称重 训练内容 蝴蝶机夹胸 27kg 12 12 12 哑铃上斜卧推 14kg 8 9 18kg 6 7 7 史密斯上斜卧推20kg 7 7 8 8 器械推下胸36kg 8 8 8 8 双杠臂屈伸练下胸45kg↑ 6 8 9 2021-06-26 星期六（手臂）今日体重未称重 训练内容 直杆二头弯举 18kg 12 12 27kg 8 8 绳索弯举18kg 12 8 8 哑铃立式弯举8kg 8 8 8 7 杠铃弯举15kg 8 8 8 哑铃臂屈伸 10kg 6 8kg 9 8 6kg 8 双杠臂屈伸（三头） 5 6 6 6 机械压腿56kg 8 9 12 12 12 2021-06-27 星期天（背）今日体重未称重 训练内容 助力引体36kg 8 6 6 4.3 直臂下压23kg 8 8 8 9 窄距划船32kg 12 12 12 10 中距划船32kg 8 10 8 9 2021-06-28 星期一（肩）今日体重未称重 训练内容 坐姿哑铃推举 10kg 10 12kg 10 16kg 8 8 8 5 哑铃侧平举8kg 8 9 9 10 坐姿哑铃俯身侧平举8kg 7 7 8 8 哑铃侧平举4kg 15 15 15 8 2021-06-29 星期二（手臂）今日体重未称重 训练内容 直杆弯举 23kg 12 12 12 32kg 6 曲杠杠铃弯举20kg 6 6 7 7 哑铃锤式弯举6kg 8 8 9 8 哑铃臂屈伸6kg 8 12 12 12 绳索下拉 23kg 8 27kg 7 6 6 8 2021-06-30 星期三（胸）今日体重未称重 训练内容 哑铃上斜卧推 14kg 8 9 8 9 18kg 7 7 6 6 固定器械推胸 27kg 9 8 32kg 8 9 9 蝴蝶机夹胸27kg 8 8 8 9 史密斯平板卧推30kg 5 5 4 2021-07-01 星期四（背）今日体重未称重 训练内容 辅助引体36kg 7 6 5 4.3 直臂下压23kg 8 8 8 8 窄距划船32kg 9 10 12 11 10 龙门架中距划船 45kg 9 50kg 9 12 10 10 2021-07-02 星期五（腿）今日体重未称重 训练内容 深蹲 10kg 7 7 8 20kg 8 8 7 杠铃弯举20kg 8 8 倒蹬70kg 8 8 8 8 2021-07-03 星期六（肩）今日体重未称重 训练内容 坐姿哑铃推举 12kg 8 8 8 16kg 7 7 8 6 哑铃侧平举8kg 9 9 8 8 俯身哑铃侧平举 6kg 7 9 10 11 2021-07-04 星期天（胸）今日体重未称重 训练内容 蝴蝶机夹胸27kg 13 12 8 8 上斜哑铃卧推 12kg 9 9 18kg 8 8 8 8 史密斯平板卧推20kg 8 9 9 10 器械推下胸32kg 8 9 9 9 哑铃练中缝10kg 8 8 8 8 8 2021-07-05 星期一（背）今日体重未称重 训练内容 辅助引体32kg↑ 6 6 3 4 3 直臂下压23kg 9 9 9 9 6 高位下拉32kg 7 8 8 8 龙门架中距划船 45kg 12 54kg 10 10 10 窄距划船 39kg 5 32kg 8 8 9 窄距高位下拉23kg 8 9 8 9 2021-07-06 星期二（手臂）今日体重未称重 训练内容 龙门架直杆弯举27kg 9 9 8 9 单手交替哑铃锤式弯举10kg 6 8 8 6 曲杆杠铃窄握弯举15kg 12 12 12 8 双杠臂屈伸(三头肌) 8 8 6 6 绳索下拉(三头肌)27.3kg 8 6 6 7 2021-07-07 星期三（肩）今日体重未称重 训练内容 坐姿哑铃推举 10kg 8 16kg 8 8 8 6 6 固定器械推肩10kg 6 6 哑铃侧平举8kg 12 12 12 12 俯身哑铃侧平举8kg 8 8 8 8 8 哑铃提拉8kg 12 13 14 13 2021-07-09 星期五（胸）今日体重未称重 训练内容 蝴蝶机夹胸27kg 12 12 8 6 上斜哑铃卧推 14kg 8 18kg 8 8 7 6 史密斯平板卧推 20kg 8 25kg 8 8 6 固定器械推下胸36kg 8 8 8 8 双杠臂屈伸下胸36kg 5 8 8 哑铃单手锤式胸前举10kg 8 8 8 8 8 2021-07-11 星期日（背、臂力器）今日体重未称重 训练内容下午 辅助引体向上32kg 6 6 5 4 直臂下拉 23kg 9 8 10 9 8 窄握划船32kg 10 10 10 9 8 中距划船 32kg 8 8 9 9 单臂哑铃划船12kg 10 9 11 窄距高位下拉32kg 8 8 8 8晚上 臂力器 50kg 6 40kg 8 8 50kg 8 40kg 12 今日总结臂力器一来就上大重量，把肩伤了。还是要先用小重量热身。 2021-07-12 星期一（手臂）今日体重未吃饭：70kg 训练内容 窄距曲杠铃弯举15kg 12 12 12 8 正握杠铃弯举 10kg 12 15kg 12 12 12 龙门架绳索二头弯举18kg 8 6 8 9 龙门架直杆弯举14kg 8 9 12 10 绳索下拉27kg 9 8 6 6 双杠臂屈伸（三头） 5 5 6 6 2021-07-13 星期二（肩）今日体重未称重 训练内容 哑铃坐姿推举 12kg 9 9 16kg 8 7 7 6 哑铃侧平举8kg 12 12 8 8 俯身哑铃侧平举6kg 8 8 8 10 哑铃提拉10kg 12 12 12 12 器械推肩前束10kg 12 8 8 有氧8分钟 今日总结训练状态不佳，人都要晕了。下次训练前需要补充能量 2021-07-14 星期三（胸）今日体重未称重 训练内容 蝴蝶机夹胸27kg 12 12 8 史密斯上斜卧推 10kg 8 40kg 2 30kg 6 6 6 5 史密斯平板卧推30kg 4 5 6 6 固定器械推下胸 36kg 8 45kg 6 6 7 36kg 6 双杠臂屈伸下胸36kg 6 6 6 7 哑铃锤式胸前举10kg 10 8 8 8 龙门架夹上胸 最轻重量 9 11 12 13.6kg 6 2021-07-15 星期四（游泳）今日体重未称重 训练内容游泳玩水25分钟 2021-07-16 星期五（背）今日体重未称重 训练内容 辅助引体向上32kg 6 6 5 3.8 直臂下拉 23kg 8 8 8 8 6 龙门架单臂划船23kg 8 8 8 8 窄握划船32kg 10 10 10 8 中距划船 32kg 8 6 8 8 窄距高位下拉 23kg 8 27kg 9 8 9 9 2021-07-19 星期一（肩）今日体重未称重 训练内容 器械推肩前束单边10kg 8 8 6 9 哑铃推举 12kg 8 16kg 6 7 7 5 哑铃侧平举8kg 12 12 12 12 俯身哑铃侧平举6kg 8 9 12 9 哑铃提拉 10kg 15 12kg 10 10 8 10kg 8 2021-07-20 星期二（胸）今日体重空腹68kg 训练内容 蝴蝶机夹胸27kg 12 12 12 8 哑铃上斜卧推 16kg 8 18kg 8 8 8 6 史密斯平板卧推 20kg 9 9 12 25kg 6 6 5 固定器械推下胸41kg 8 6 6 6 哑铃锤式胸前举10kg 8 8 8 龙门架夹上胸 12 12 双杠臂屈伸下胸36kg 9 8 9 6 2021-07-21 星期三（游泳）今日体重训练内容游泳16圈 2021-07-22 星期四（背）今日体重空腹68kg 训练内容 宽距高位下拉 23kg 9 27kg 10 9 8 8 辅助引体向上36kg 5 5 3 直臂下压 27kg 8 8 8 8 窄握划船32kg 12 12 8 8 龙门架单臂划船18kg 12 12 12 12 中距划船 32kg 10 8 9 8 窄距高位下拉27kg 9 9 8 8 2021-07-24 星期六（胸）今日体重训练内容 蝴蝶机夹胸 18kg 12 12 8 史密斯上斜卧推 20kg 8 8 30kg 5 6 5 6 史密斯平板卧推30kg 6 5 5 5 哑铃上斜卧推20kg 3 固定器械推下胸36kg 9 8 8 2021-07-26 星期一（背）今日体重训练内容 辅助引体32kg 6 5 5 5 直臂下压27kg 8 8 8 8 龙门架单臂划船 27kg 8 8 8 9 龙门架中距划船45kg 8 10 10 10 窄距划船32kg 8 8 8 8 窄距高位下拉32kg 6 7 6 6 2021-07-28 星期三（肩）今日体重训练内容 坐姿哑铃推举 10kg 9 8 14kg 8 16kg 8 6 6 6 固定器械推肩10kg 8 8 8 7 哑铃侧平举8kg 12 12 12 12 8 俯身哑铃侧平举6kg 12 12 12 12 哑铃提拉12kg 8 9 10 8 2021-08-03 星期二（游泳）2021-08-04 星期三（游泳）2021-08-05 星期四（游泳）2021-08-06 星期五（游泳）2021-08-07 星期六（游泳）2021-08-08 星期天（游泳）2021-08-09 星期一（游泳） 游泳18圈,一个来回算一圈。 2021-08-10 星期二（游泳） 游泳20圈 2021-08-13 星期五（胸） 蝴蝶机夹胸27kg 12 12 10 7 哑铃上斜卧推14kg 8 8 8 8 平板杠铃卧推20kg 5 5 5 4 固定器械推下胸32kg 8 8 8 8 8 哑铃锤式胸前举10kg 8 12 10 8 10 2021-08-16 星期一（背） 助力引体32kg 6 6 6 6 直臂下压23kg 9 9 10 9 龙门架单臂划船32kg 8 8 8 8 窄距划船32kg 8 8 8 7.6 窄距高位下拉27kg 8 8 8 8 高拉背肌训练器45kg 6 6 6 6 2021-08-17 星期二（游泳）2021-08-18 星期三（游泳）2021-08-19 星期四（游泳）2021-08-20 星期五（游泳）2021-08-21 星期六（胸） 蝴蝶机夹胸 23kg 12 12 12 12 哑铃上斜卧推 14kg 8 8 8 16kg 8 8 6 史密斯上斜卧推20kg 6 6 6 史密斯平板杠铃卧推20kg 6 7 7 7 固定器械推下胸36kg 8 8 8 7 哑铃锤式胸前举10kg 10 10 11 10 2021-08-22 星期天（背） 助力引体32kg 6 6 6 6 直臂下压23kg 8 8 8 9 龙门架单臂划船32kg 8 8 8 8 龙门架中距划船32kg 12 9 9 窄距划船32kg 8 8 8 8 高拉背肌训练器（单侧30kg） 8 6 8 7 2021-08-24 星期二（胸） 蝴蝶机夹胸 23kg 12 12 12 12 哑铃上斜卧推 14kg 12 18kg 6 6 5 5 史密斯平板卧推 10kg 9 30kg 6 6 4 5 固定器械推下胸36kg 8 8 8 8 哑铃锤式胸前举10kg 11 12 12 12 2021-08-25 星期三（二头、臀、腿） 龙门架直杆弯举32kg 6 6 6 6 哈克深蹲 20kg 12 12 12 12 器械蹬腿56kg 8 9 8 10 器械夹腿32kg 8 8 8 8 2021-08-26 星期四（游泳）2021-08-27 星期五（背） 助力引体32kg 8 6 6 5 直臂下压23kg 8 9 8 8 龙门架单臂划船36kg 6 6 6 6 窄距划船32kg 8 8 8 8 窄距高位下拉32kg 6 6 6 6","categories":[],"tags":[{"name":"健身","slug":"健身","permalink":"https://blog.smilexin.cn/tags/健身/"}]},{"title":"windows使用NVM管理nodejs版本","slug":"windows使用NVM管理nodejs版本","date":"2021-05-20T16:00:00.000Z","updated":"2021-05-21T03:22:14.605Z","comments":true,"path":"2021/05/21/windows使用NVM管理nodejs版本.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/21/windows使用NVM管理nodejs版本.html","excerpt":"","text":"前言比如我们手上同时在做好几个项目，这些项目的需求都不太一样，导致了这些个项目需要依赖的nodejs版本也不同，这种情况下，我们就可以通过nvm来切换nodejs的版本，而不需要频繁地下载/卸载不同版本的nodejs来满足当前项目的要求。 下载安装 下载地址：https://github.com/coreybutler/nvm-windows/releases 可下载以下版本： nvm-noinstall.zip：绿色免安装版，但使用时需要进行配置。 nvm-setup.zip：安装版，推荐使用 安装的时候注意安装目录不要出现中文和空格。 检查是否安装成功 打开CMD，输入nvm，安装成功则会如下图所示，它会显示出当前nvm版本以及nvm的命令 使用nvm1234567nvm list // 显示已安装的版本（同 nvm list installed）nvm list installed // 显示已安装的版本nvm list available // 显示所有可以下载的版本nvm install 12.22.1 // 安装12.22.1版本nodenvm install latest // 安装最新版本nodenvm use 12.22.1 // 使用14.5.0版本nodenvm uninstall 14.5.0 // 卸载14.5.0版本node 在运行nvm install 的时候，有可能会出现无权限安装的问题，如果遇到此问题，请以管理员身份运行cmd。","categories":[],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://blog.smilexin.cn/tags/nodejs/"}]},{"title":"Markdown 常用语法","slug":"Markdown 常用语法","date":"2021-05-11T16:00:00.000Z","updated":"2021-05-14T12:23:54.116Z","comments":true,"path":"2021/05/12/Markdown 常用语法.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/12/Markdown 常用语法.html","excerpt":"","text":"简介Markdown 是一种轻量级标记语言，它用简洁的语法代替排版，使我们专心于码字。它的目标是实现易读易写，成为一种适用于网络的书写语言。同时，Markdown支持嵌入html标签。 注意：Markdown使用#、+、*等符号来标记， 符号后面必须跟上 至少1个 空格才有效！ Markdown的常用语法标题用#标记 在 标题开头 加上1~6个#，依次代表一级标题、二级标题….六级标题 一级标题二级标题三级标题四级标题五级标题六级标题列表Markdown 支持有序列表和无序列表。 无序列表无序列表使用-、+和*作为列表标记： 1234567891011- Red- Green- Blue* Red* Green* Blue+ Red+ Green+ Blue 效果如下 Red Green Blue Red Green Blue Red Green Blue 有序列表有序列表则使用数字加英文句点.来表示：1231. Red2. Green3. Blue 效果如下 Red Green Blue 引用引用以&gt;来表示，引用中支持多级引用、标题、列表、代码块、分割线等常规语法。 常见的引用写法：12345678910111213141516171819&gt; 这是一段引用 //在`&gt;`后面有 1 个空格&gt; &gt; 这是引用的代码块形式 //在`&gt;`后面有 5 个空格&gt; &gt; 代码例子：&gt; protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); &#125;&gt; 一级引用&gt; &gt; 二级引用&gt; &gt; &gt; 三级引用&gt; #### 这是一个四级标题&gt; &gt; 1. 这是第一行列表项&gt; 2. 这是第二行列表项 效果如下： 这是一段引用 //在&gt;后面有 1 个空格 这是引用的代码块形式 //在`&gt;`后面有 5 个空格 代码例子： protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); } 一级引用 二级引用 三级引用 这是一个四级标题 这是第一行列表项 这是第二行列表项 强调两个*或-代表加粗，一个*或-代表斜体，~~代表删除。12345**加粗文本** 或者 __加粗文本__*斜体文本* 或者_斜体文本_~~删除文本~~ 效果如下：加粗文本 或者 加粗文本 斜体文本 或者斜体文本 删除文本 图片与链接图片与链接的语法很像，区别在一个 ! 号。二者格式：123图片：![]() ![图片文本(可忽略)](图片地址)链接：[]() [链接文本](链接地址) 链接又分为行内式、参考式和 自动链接：12345678910111213这是行内式链接：[Junxin&apos;s Blog](https://smilexin.cn/)。这是参考式链接：[Junxin&apos;s Blog][url]，其中url为链接标记，可置于文中任意位置。[url]: https://smilexin.cn// &quot;Junxin&apos;s Blog&quot;链接标记格式为：[链接标记文本]: 链接地址 链接title(可忽略)这是自动链接：直接使用`&lt;&gt;`括起来&lt;https://smilexin.cn/&gt;这是图片：![][avatar][avatar]: https://connorlin.github.io/images/avatar.jpg 效果如下： 这是行内式链接：Junxin’s Blog。 这是参考式链接：Junxin’s Blog，其中url为链接标记，可置于文中任意位置。 链接标记格式为：[链接标记文本]: 链接地址 链接title(可忽略) 这是自动链接：直接使用&lt;&gt;括起来https://smilexin.cn/ 这是图片： 代码代码分为行内代码和代码块。 行内代码使用 `代码` 标识，可嵌入文字中 代码块使用4个空格或```标识 ```这里是代码``` 代码语法高亮在 ```后面加上空格和语言名称即可``` 语言//注意语言前面有空格这里是代码``` 例如：12345678910这是行内代码`onCreate(Bundle savedInstanceState)`的例子。这是代码块和语法高亮：``` java// 注意java前面有空格protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main);&#125; 效果如下：这是行内代码onCreate(Bundle savedInstanceState)的例子。 这是代码块和语法高亮： 12345// 注意java前面有空格protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main);&#125; 表格表格对齐格式 居左：:---- 居中：:----:或----- 居右：----:例子： 123456|标题|标题|标题||:---|:---:|---:||居左测试文本|居中测试文本|居右测试文本||居左测试文本1|居中测试文本2|居右测试文本3||居左测试文本11|居中测试文本22|居右测试文本33||居左测试文本111|居中测试文本222|居右测试文本333| 效果如下：|标题|标题|标题||:—|:—:|—:||居左测试文本|居中测试文本|居右测试文本||居左测试文本1|居中测试文本2|居右测试文本3||居左测试文本11|居中测试文本22|居右测试文本33||居左测试文本111|居中测试文本222|居右测试文本333| 分隔线在一行中用三个以上的*、-、_来建立一个分隔线，行内不能有其他东西。也可以在符号间插入空格。12345***---___* * * 效果均为一条分割线： Markdown常用的Html标签字体12&lt;font face=&quot;微软雅黑&quot; color=&quot;red&quot; size=&quot;6&quot;&gt;字体及字体颜色和大小&lt;/font&gt;&lt;font color=&quot;#0000ff&quot;&gt;字体颜色&lt;/font&gt; 效果如下： 字体及字体颜色和大小 字体颜色 换行1使用html标签`&lt;br/&gt;`&lt;br/&gt;换行 效果如下：使用html标签&lt;br/&gt;第二行 下划线1&lt;u&gt;下划线文本&lt;/u&gt; 效果如下：下划线文本","categories":[],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://blog.smilexin.cn/tags/Markdown/"}]},{"title":"谁动了我的 Linux？history 命令详解！","slug":"谁动了我的 Linux","date":"2021-05-11T16:00:00.000Z","updated":"2021-05-12T02:42:24.310Z","comments":true,"path":"2021/05/12/谁动了我的 Linux.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/12/谁动了我的 Linux.html","excerpt":"","text":"当我们频繁使用 Linux 命令行时，有效地使用历史记录，可以大大提高工作效率。 在平时 Linux 操作过程中，很多命令是重复的，你一定不希望大量输入重复的命令。如果你是系统管理员，你可能需要对用户操作进行审计，管理好 Linux 命令历史记录显得非常重要。 今天我们来介绍一下，在 Linux 使用 history 来减少重复命令的几个实用技巧。 基本原理 Linux 命令的历史记录，会持久化存储，默认位置是当前用户home目录的 .bash_history 文件。 当 Linux 系统启动一个 Shell 时，Shell 会从 .bash_history文件中，读取历史记录，存储在相应内存的缓冲区中。 我们平时所操作的 Linux 命令，都会记录在缓冲区中。包括 history 命令所执行的历史命令管理，都是记录在缓冲区，而不是直接记录到 .bash_history 文件。 当我们退出 Shell，比如按下 Ctrl+D 时，Shell 进程会把缓冲区的内容，写回到 .bash_history 文件中去。 使用详解清楚了 history 的基本原理，我们来具体学习一下如何使用它。 基础用法直接输入 history 命令，可以看到最近操作的所有命令都显示出来了1$ history 有时候我不需要显示所有的历史命令，只显示最后的 10 条历史记录，可以在命令后加数字 N 即可1$ history 10 正常情况下，只有在 Shell 正常退出时，才会将缓冲区内容保存到文件。如果你想主动保存缓冲区的历史记录，执行 -w 选项即可1$ history -w 当然，如果你执行了一些敏感的命令操作，可以执行 -c 将缓冲区内容直接删除1$ history -c 重复执行命令如果要重复执行一些命令，可以使用 ! 来快速执行重复的命令。 举个例子，重复执行第 1024 历史命令，可以执行如下命令 1$ !1024 1024 这个编号可以通过 history 查看 重复执行上一条命令 1$ !! 重复执行倒数第 6 条历史命令，可以通过负数表示，-6 表示倒数第 6 条记录 1$ !-6 搜索历史命令有时候，需要重复执行某字符串开头的最后一个命令，同样可以通过 ! 来操作，然后按 Enter 执行即可 比如，刚才执行了一个很长命令，只记录命令开头是 curl，这时就可以通过 !curl 快速执行该命令1$ !curl 这个用法很高效，但存在不安全因素，因为有可能执行的命令不是你想要执行的，那就坏事了。可以通过 :p 来安全地执行。12$ !curl:pcurl www.sina.com.cn 加上 :p 后，只是打印出了搜索到的命令，如果要执行，请按 Up 键，然后回车即可。 如果你只知道某条命令包含了 “hi” 信息，不是以 “hi” 开头，同样可以通过 ? 来执行包含字符串的命令 1$ !?hi 交互式搜索历史命令在 Linux 搜索历史命令，还可以通过交互式的搜索方式，简直高效直接。在命令行输入 Ctrl+R 后，进入交互界面，键入需要搜索的关键字，如果匹配到多条命令，可以多次键入 Ctrl+R 来切换上一条匹配的命令。1(reverse-i-search)`sina&apos;: echo sina 可以看到，我输入了 sina 后，就自动匹配到最近一次和 sina 匹配的命令，这时按下回车就可以执行该命令。 重复执行上条命令在这里总结下多种重复执行上条命令的方式，你可以选择一种自己喜欢的就可以啦 !! !-1 Ctrl+p Up 显示命令时间有时候需要对 Linux 系统做审计，那为历史记录添加时间显示非常有用。12345$ export HISTTIMEFORMAT=&apos;%F %T &apos;$ history 3 8 2021-05-12 10:29:48 echo sina 9 2021-05-12 10:32:13 export HISTTIMEFORMAT=&apos;%F %T &apos; 10 2021-05-12 10:32:17 history 可以看到，历史记录已经显示了时间。其实这些对于审计需求，还不够，可以加上更详细的信息：1234$ export HISTTIMEFORMAT=&quot;%F %T `who -u am i 2&gt;/dev/null| awk &apos;&#123;print $NF&#125;&apos;|sed \\-e &apos;s/[()]//g&apos;` `whoami` &quot; 6 2021-04-18 16:07:48 14.116.240.195 root ls 7 2021-04-18 16:07:59 14.116.240.195 root pwd 8 2021-04-18 16:08:14 14.116.240.195 root history 控制历史记录总数默认情况下，Linux 系统最多存储 1000 条历史记录，可以通过 HISTSIZE 环境变量查看12$ echo $HISTSIZE1000 对于需要做审计的场景，1000 条历史记录可能会太少了，我们可以修改为合适的值1$ export HISTSIZE=10000 注意，HISTSIZE 变量只能控制缓冲区中的历史记录数量，如果需要控制 bash_history 文件存储的最大记录数，可以通过 HISTFILESIZE 进行控制上述命令行修改只在当前 Shell 环境生效，如果需要永久生效，需要写入配置文件123$ echo &quot;export HISTSIZE=10000&quot; &gt;&gt; ~/.bash_profile$ echo &quot;export HISTFILESIZE=200000&quot; &gt;&gt; ~/.bash_profile$ source ~/.bash_profile 更改历史记录文件名有时，为了方便管理和备份，需要更改历史记录文件的路径和名称。简单，同样可以通过环境变量 HISTFILE 更改它的文件名称 12$ echo &quot;export HISTFILE=/data/backup/chopin.bash_history&quot; &gt;&gt; ~/.bash_profile$ souce ~/.bash_profile 禁用历史记录处于某种特殊环境，我们需要禁用历史记录 123$ echo &quot;export HISTSIZE=0&quot; &gt;&gt; ~/.bash_profile$ echo &quot;export HISTFILESIZE=0&quot; &gt;&gt; ~/.bash_profile$ source ~/.bash_profile 直接把上述两个变量的值设置为 0，就实现了禁用历史记录的功能 黑客必知的一个小技巧最后分享一个不为人知的，黑客必知的小技巧。 在命令前额外多加一个空格，这样的命令是不会被记录到历史记录的，感觉是不是很酷 这个技巧如果在你的系统不管用，请查看下环境变量 HISTCONTROL 是否包含 ignorespace，貌似 centos 系统默认没有设置这个值。 总结在 Linux 系统，history 命令可以非常方便，帮助我们管理历史命令，平时我们命令都会先记录在缓存区，在 Shell 退出时才会记录到文件中。 history 命令提供了很方便的管理功能，合理去配置和管理历史记录，可以让你的 Linux 系统更加健壮和安全。 现在总结一下 history 命令常用方法 history n：只显示最近的 n 条历史记录 history -c：清除缓存区中的历史记录 history -w：将缓存区的历史记录保存到文件 history -d N：删除第 N 条历史记录几种重复执行命令的方法：!!、!N、!start 等 交互式历史命令搜索，请使用 Ctrl+R 快捷键 合适使用几个相关的环境变量，让你的 Linux 系统更安全： HISTSIZE：控制缓冲区历史记录的最大个数 HISTFILESIZE：控制历史记录文件中的最大个数 HISTIGNORE：设置哪些命令不记录到历史记录 HISTTIMEFORMAT：设置历史命令显示的时间格式 HISTCONTROL：扩展的控制选项 如果在生产环境，这些环境变量需要持久化到配置文件 ~/.bash_profile 123456789101112# ignorespace: 忽略空格开头的命令# ignoredups: 忽略连续重复命令# ignoreboth: 表示上述两个参数都设置export HISTCONTROL=ignoreboth# 设置追加而不是覆盖shopt -s histappendexport HISTSIZE=1000export HISTFILESIZE=200000export HISTTIMEFORMAT=&quot;%F %T &quot;export HISTIGNORE=&quot;ls:history&quot;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"}]},{"title":"IDEA 代码补全操作技巧","slug":"IDEA 代码补全操作技巧","date":"2021-05-10T16:00:00.000Z","updated":"2021-05-11T10:02:50.304Z","comments":true,"path":"2021/05/11/IDEA 代码补全操作技巧.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/11/IDEA 代码补全操作技巧.html","excerpt":"","text":"IDEA 有个很牛逼的功能，那就是代码补全，极大的方便了开发人员。 下面是我比较常用的 var 声明变量 null 判空 nn 判非空 for 遍历 fori 带索引的遍历 if 条件判断 cast 强转","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://blog.smilexin.cn/tags/IDEA/"}]},{"title":"Nginx 配置详解","slug":"Nginx 配置详解","date":"2021-05-10T16:00:00.000Z","updated":"2021-05-11T02:47:50.614Z","comments":true,"path":"2021/05/11/Nginx 配置详解.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/11/Nginx 配置详解.html","excerpt":"","text":"Nginx相关地址 源码：https://trac.nginx.org/nginx/browser官网：http://www.nginx.org/ Nginx常用功能 Http代理，反向代理：作为web服务器最常用的功能之一，尤其是反向代理。 这里我给来2张图，对正向代理与反响代理做个诠释，具体细节，大家可以翻阅下资料。 负载均衡Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Iphash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。 轮询(默认方式)每个请求按时间顺序逐一分配到后端服务器,如果后端服务器down掉,能自动剔除 权重weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream example1 &#123; server 192.168.159.10 weight=10; server 192.168.159.11 weight=10;&#125; ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream example2 &#123; ip_hash; server 192.168.159.10:8080; server 192.168.159.11:8080; &#125; fair(第三方)按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream resinserver&#123; server server1; server server2; fair;&#125; web缓存 Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 Nginx配置文件 nginx.conf这个是nginx的主配置文件,nginx启动的时候就是读取这个配置文件。 conf.d这是一个目录,里面可以写我们自己自定义的配置文件,文件结尾一定是.conf才可以生效(当然也可以通过修改nginx.conf来取消这个限制) sites-enabled这里面的配置文件其实就是sites-available里面的配置文件的软连接,但是由于nginx.conf默认包含的是这个文件夹,所以我们在sites-available里面建立了新的站点之后,还要建立个软连接到sites-enabled里面才行 sites-available这里是我们的虚拟主机的目录，我们在在这里面可以创建多个虚拟主机 Nginx配置结构在 nginx.conf 的注释符号为： # 123456789101112131415161718192021222324252627... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 server块：配置虚拟主机的相关参数，一个http中可以有多个server。 location块：配置请求的路由，以及各种页面的处理情况。 下面给大家上一个配置文件，作为示例。 123456789101112131415161718192021222324252627282930313233343536373839404142########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1,建议设置同CPU数一致#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergevents &#123; #accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on #multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为512&#125;http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain #access_log off; #取消服务日志 log_format myFormat &apos;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&apos;; #自定义格式 access_log log/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块。 # 负载均衡 upstream myserver &#123; server 127.0.0.1:7878; server 127.0.0.1:7879; server 192.168.10.121:3333 backup; #热备 &#125; error_page 404 https://www.baidu.com; #错误页 server &#123; keepalive_requests 120; #单连接请求上限次数。 listen 4545; #监听端口 server_name 127.0.0.1; #监听地址,一般为域名 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #root path; #根目录 #index vv.txt; #设置默认页 proxy_pass http://myserver; #请求转向myserver定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip &#125; &#125;&#125; 上面是nginx的基本配置，需要注意的有以下几点： 几个常见配置项： $remote_addr 与 $http_x_forwarded_for 用以记录客户端的ip地址； $remote_user ：用来记录客户端用户名称； $time_local ： 用来记录访问时间与时区； $request ： 用来记录请求的url与http协议； $status ： 用来记录请求状态；成功是200； $body_bytes_s ent ：记录发送给客户端文件主体内容大小； $http_referer ：用来记录从那个页面链接访问过来的； $http_user_agent ：记录客户端浏览器的相关信息； 惊群现象：一个网络连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得连接，这样会影响系统性能。","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.smilexin.cn/tags/Nginx/"}]},{"title":"VMware 克隆虚拟机","slug":"VMware 克隆虚拟机","date":"2021-05-09T16:00:00.000Z","updated":"2021-05-10T09:53:36.753Z","comments":true,"path":"2021/05/10/VMware 克隆虚拟机.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/10/VMware 克隆虚拟机.html","excerpt":"","text":"修改hostname1$ sudo hostnamectl set-hostname &lt;newhostname&gt; 这条命令会删除/etc/hostname文件中的主机名，然后替换为新的主机名。我们还需要更新/etc/hosts文件,追加newhostname的解析1127.0.0.1 &lt;newhostname&gt; /etc/hosts文件是用来将主机名映射为ip地址的文件，也就是域名解析的作用，在之前没有DNS的时候是使用该文件来进行域名和ip地址的映射。 有些同学的etc/hosts文件中包括如下两行12127.0.0.1 localhost::1 localhost 127.0.0.1表示ipv4的本地地址 而::1表示的时ipv6的本地地址，也就是0000:0000:0000:0000:0000:0000:0000:0001 修改新节点的内网IP 修改网络配置文件更新ip 1vi /etc/sysconfig/network-scripts/ifcfg-ens33 systemctl restart network 重启network 如果不能用systemctl就重启系统reboot","categories":[],"tags":[{"name":"VMware","slug":"VMware","permalink":"https://blog.smilexin.cn/tags/VMware/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://blog.smilexin.cn/tags/虚拟机/"}]},{"title":"使用Docker快速搭建代理服务器","slug":"使用Docker快速搭建代理服务器","date":"2021-05-09T16:00:00.000Z","updated":"2021-05-20T07:38:15.659Z","comments":true,"path":"2021/05/10/使用Docker快速搭建代理服务器.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/10/使用Docker快速搭建代理服务器.html","excerpt":"","text":"快速使用http代理当前服务器有个第三方部署的服务只支持内网IP访问,我就需要在内网服务器上搭建一个HTTP代理服务进行访问该服务。 启动HTTP代理服务1docker run --name myprivoxy -d -p 1080:8118 splazit/privoxy-alpine socks5代理启动socks5代理服务器123docker run -d -p 1080:1080 nithoalif/microsocks# 测试curl --proxy socks5://localhost:1080 www.baidu.com 下面是我在网上找的HTTP代理服务使用方法(还没测试使用)，这里做个记录Dockerfile1234567891011121314151617181920212223FROM alpineEXPOSE 8118RUN apk --no-cache --update add privoxy wget ca-certificates bash p7zip &amp;&amp; \\ wget https://s3.amazonaws.com/ab2p/ab2p.all_rus.7z &amp;&amp; \\ mkdir temp &amp;&amp; \\ 7za e ab2p.all_rus.7z -y -otemp &amp;&amp; \\ cp temp/ab2p.system.action temp/ab2p.action temp/ab2p.system.filter temp/ab2p.filter /etc/privoxy &amp;&amp; \\ sed -i&apos;&apos; &apos;s/127\\.0\\.0\\.1:8118/0\\.0\\.0\\.0:8118/&apos; /etc/privoxy/config &amp;&amp; \\ sed -i&apos;&apos; &apos;s/enable-edit-actions\\ 0/enable-edit-actions\\ 1/&apos; /etc/privoxy/config &amp;&amp; \\ sed -i&apos;&apos; &apos;s/#max-client-connections/max-client-connections/&apos; /etc/privoxy/config &amp;&amp; \\ sed -i&apos;&apos; &apos;s/accept-intercepted-requests\\ 0/accept-intercepted-requests\\ 1/&apos; /etc/privoxy/config &amp;&amp; \\ sed -i&apos;&apos; &apos;s/http/https/g&apos; /etc/privoxy/ab2p.system.filter &amp;&amp; \\ echo &apos;actionsfile ab2p.system.action&apos; &gt;&gt; /etc/privoxy/config &amp;&amp; \\ echo &apos;actionsfile ab2p.action&apos; &gt;&gt; /etc/privoxy/config &amp;&amp; \\ echo &apos;filterfile ab2p.system.filter&apos; &gt;&gt; /etc/privoxy/config &amp;&amp; \\ echo &apos;filterfile ab2p.filter&apos; &gt;&gt; /etc/privoxy/config &amp;&amp; \\ rm -Rf temp ab2p.all_rus.7z &amp;&amp; \\ apk del bash p7zipRUN chown privoxy.privoxy /etc/privoxy/*ENTRYPOINT [&quot;privoxy&quot;]CMD [&quot;--no-daemon&quot;,&quot;--user&quot;,&quot;privoxy&quot;,&quot;/etc/privoxy/config&quot;] RUN1$ docker run -d --restart unless-stopped --name privoxy -p 8118:8118 splazit/privoxy-alpine TEST1curl -vv https://www.bing.com --proxy localhost:8118 Win10电脑启用HTTP代理服务在本地电脑配置代理服务 然后就可以打开浏览器通过内网IP访问该服务了。 问题处理：Maximum number of open connections reached.错误信息：已达到最大打开连接数。某些时候我们使用代理打开一个网页会出现这个异常提示,是因为网页的资源过多(JS,CSS…),造成代理服务器的连接超过 max-client-connections配置的数值了。这个时候需要修改配置文件 /etc/privoxy/config 改大 max-client-connections 配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 6.9. max-client-connections# ============================## Specifies:## Maximum number of client connections that will be served.## Type of value:## Positive number.## Default value:## 128## Effect if unset:## Connections are served until a resource limit is reached.## Notes:## Privoxy creates one thread (or process) for every incoming# client connection that isn&apos;t rejected based on the access# control settings.## If the system is powerful enough, Privoxy can theoretically# deal with several hundred (or thousand) connections at the# same time, but some operating systems enforce resource limits# by shutting down offending processes and their default limits# may be below the ones Privoxy would require under heavy load.## Configuring Privoxy to enforce a connection limit below the# thread or process limit used by the operating system makes# sure this doesn&apos;t happen. Simply increasing the operating# system&apos;s limit would work too, but if Privoxy isn&apos;t the only# application running on the system, you may actually want to# limit the resources used by Privoxy.## If Privoxy is only used by a single trusted user, limiting the# number of client connections is probably unnecessary. If there# are multiple possibly untrusted users you probably still want# to additionally use a packet filter to limit the maximal# number of incoming connections per client. Otherwise a# malicious user could intentionally create a high number of# connections to prevent other users from using Privoxy.## Obviously using this option only makes sense if you choose a# limit below the one enforced by the operating system.## One most POSIX-compliant systems Privoxy can&apos;t properly deal# with more than FD_SETSIZE file descriptors at the same time# and has to reject connections if the limit is reached. This# will likely change in a future version, but currently this# limit can&apos;t be increased without recompiling Privoxy with a# different FD_SETSIZE limit.## Example:## max-client-connections 256# 处理过程12# /opt/myprivoxy/ 为宿主机目录docker cp myprivoxy:/etc/privoxy/config /opt/myprivoxy/ 编辑配置文件,设置max-client-connections12vi /opt/myprivoxy/configmax-client-connections 65535 启动容器12# 挂载修改后的config文件启动容器docker run --name myprivoxy2 -d -p 1080:8118 -v /opt/myprivoxy/config:/etc/privoxy/config splazit/privoxy-alpine","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Privoxy","slug":"Privoxy","permalink":"https://blog.smilexin.cn/tags/Privoxy/"}]},{"title":"Linux（Centos版本）快速安装Docker","slug":"Linux（Centos版本）快速安装Docker","date":"2021-05-08T16:00:00.000Z","updated":"2021-05-09T02:18:02.466Z","comments":true,"path":"2021/05/09/Linux（Centos版本）快速安装Docker.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/09/Linux（Centos版本）快速安装Docker.html","excerpt":"","text":"使用脚本安装 Docker 使用 sudo 或 root 权限登录 Centos。 确保 yum 包更新到最新。 1$ yum -y update 执行 Docker 安装脚本。 12$ curl -fsSL https://get.docker.com -o get-docker.sh$ sudo sh get-docker.sh // 执行这个脚本会添加 docker.repo 源并安装 Docker。 启动 Docker 进程。1service docker start 或 systemctl start docker 验证Docker是否安装成功12$ docker -vDocker version 20.10.6, build 370c289 镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。 新版的 Docker 使用 /etc/docker/daemon.json（Linux） 或者 %programdata%\\docker\\config\\daemon.json（Windows） 来配置 Daemon。 请在该配置文件中加入（没有该文件的话，请先建一个）：123&#123; &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;]&#125;","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"}]},{"title":"Docker 常用命令","slug":"Docker 常用命令","date":"2021-05-07T16:00:00.000Z","updated":"2021-06-21T07:48:52.228Z","comments":true,"path":"2021/05/08/Docker 常用命令.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/08/Docker 常用命令.html","excerpt":"","text":"Docker常用命令记录，方便查询 拷贝文件074af74c669d 是容器id,也可以换成容器名称,可以使用 docker ps -a 查看 从容器中拷贝文件到宿主机 1sudo docker cp 074af74c669d:/etc/data.xls /tmp 从宿主机拷贝到容器 1sudo docker cp /tmp/index.html 074af74c669d:/etc/ 获取镜像 docker search [OPTIONS] 镜像名12# 查找stars数不低于10的centos镜像docker search -f stars=10 centos 1234# 查看本地的镜像$ docker images# 如果我们本地没有 ubuntu 镜像，我们可以使用 docker pull 命令来载入 ubuntu 镜像：$ docker pull ubuntu 查看容器12345docker ps // 查看Docker正在运行的容器docker ps -a // 列出Docker所有容器docker ps -l // 列出最新创建的一个容器docker ps [-a][-l]docker inspect 容器名字|容器ID // 查看指定容器信息 启动容器 docker run:使用镜像启动对应的容器 docker run 参数说明： -d :代表后台运行容器，返回容器ID –name: 自定义容器的名称，不加这命令docker会随便给一个名给你，所以建议打上这命令 -p :代表映射的端口 本地端口:容器端口 -i: 以交互模式运行容器，通常与 -t 同时使用； -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -P: 随机端口映射，容器内部端口随机映射到主机的高端口 –volume , -v: 挂载一个卷到容器 1234567# 启动交互式容器docker run -it IMAGE_NAME /bin/bash# 使用nginx镜像启动一个容器，容器名称设置为mynginxdocker run --name=mynginx -it nginx /bin/bash# 在大部分的场景下，我们希望 docker 的服务是在后台运行的，可以使用 -d 指定容器在后台运行。# 注：加了 -d 参数默认不会进入容器，想要进入容器需要使用指令 docker execdocker run --name=mynginx -d nginx docker start:启动停止的容器 1234# 启动一个容器名为nginx-1的容器docker start nginx-1# 启动两个容器，分别为容器名为nginx-1、容器ID为356466a99c7f的两个容器docker start nginx-1 356466a99c7f 停止容器1234567# 优雅的停止容器docker stop 容器ID或容器名# 直接关闭容器docker kill 容器ID或容器名# 参数 -t：关闭容器的限时，如果超时未能关闭则用kill强制关闭，默认值10s，这个时间用于容器的自己保存状态docker stop -t 容器ID或容器名docker stop -t=60 容器ID或容器名 映射端口容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P（大写） 或 -p （小写） 参数来指定端口映射。（1）当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。（2）-p（小写）则可以指定要映射的IP和端口，但是在一个指定端口上只可以绑定一个容器。-p 标记可以多次使用来绑定多个端口。支持的格式有 hostPort:containerPort、ip:hostPort:containerPort、 ip::containerPort。 hostPort:containerPort（映射所有接口地址）将本地的 5000 端口映射到容器的 5000 端口，可以执行如下命令：1$ docker run -d -p 5000:5000 training/webapp python app.py ip:hostPort:containerPort （映射指定地址的指定端口）指定映射使用一个特定地址，比如 localhost 地址 127.0.0.11$ docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py ip::containerPort （映射指定地址的任意端口）绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。1$ docker run -d -p 127.0.0.1::5000 training/webapp python app.py 还可以使用 udp 标记来指定 udp 端口1$ docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py 12345678# 参数 -p 是指把镜像内的12345端口映射到宿主机的80端口$ docker run -d -p 80:12345 nginx# 不指定宿主机端口，随机映射出来# 查看容器c5b暴露的端口,27017是容器端口,37017是宿主机端口$ docker port c5b27017tcp -&gt; 0.0.0.0:37017# -p 标记可以多次使用来绑定多个端口$ docker run -d -p 5000:5000 -p 3000:80 nginx 进入容器在使用 -d 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入： docker exec docker attach使用attach的话，如果从这个容器退出，会导致容器的停止。推荐使用exec12# 进入id为243c32535da7的这个容器docker exec -it 243c32535da7 /bin/bash 提交容器在本地创建一个容器后，可以依据这个容器创建本地镜像，并可把这个镜像推送到Docker hub中，以便在网络上下载使用。docker commit:从容器创建一个新的镜像。123$ docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]# 创建myubuntu:v1镜像$ docker commit -a &quot;hejx&quot; -m &quot;this is test&quot; 651a8541a47d myubuntu:v1 -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 推送镜像12# 推送镜像到docker hub仓库$ docker push [OPTIONS] NAME[:TAG] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152首先是登录docker hub （用户名：hejx 密码:*******）[root@docker-test1 ~]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.Username (hejx): hejxPassword:Login Succeeded [root@docker-test1 ~]# docker push hejx/myubuntu:v1The push refers to a repository [docker.io/hejx/myubuntu]An image does not exist locally with the tag: docker.io/hejx/myubuntu 这里需要将ubuntu:v1镜像改名，在名称前加上自己的docker hub的Docker ID，即hejx [root@docker-test1 ~]# docker tag 6ce4aedd12cd hejx/myubuntu:v1[root@docker-test1 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmyubuntu v1 6ce4aedd12cd 6 minutes ago 84.1 MBhejx/myubuntu v1 6ce4aedd12cd 6 minutes ago 84.1 MBdocker.io/ubuntu 16.04 7aa3602ab41e 5 weeks ago 115 MB 再次进行推送（注意：下面的v1的tag标签可以不打，默认是latest）。推送操作时间稍微会有一点长，耐心等待～[root@docker-test1 ~]# docker push hejx/myubuntu:v1 The push refers to a repository [docker.io/hejx/myubuntu]b5948ba9486d: Pushed8d7ea83e3c62: Mounted from library/ubuntu6a061ee02432: Mounted from library/ubuntuf73b2816c52a: Mounted from library/ubuntu6267b420796f: Mounted from library/ubuntua30b835850bf: Mounted from library/ubuntuv1: digest: sha256:e9cd9075d262848a307c92751e1a5890d883b814a31abd118161442461a1ca2d size: 1564 最后登录自己的Docker Hub，即https://hub.docker.com/登录后，在Repositories里面就可以看到自己在上面推送的镜像hejx/myubuntu:v1了，这是个对外的镜像，可以在网络上下载。在Docker hub上可以看到这个镜像的下载命令（注意下载时跟上tag标签，如果是latest的默认tag可以不跟）也可以直接在Docker hub上删除这个镜像（Repositories-镜像-Settings-delete） 比如在另一台服务器上下载这个镜像[root@kevin-test ~]# docker pull hejx/myubuntuPulling repository hejx/myubuntuRepository not found 需要跟上tag标签[root@kevin-test ~]# docker pull hejx/myubuntu:v1v1: Pulling from hejx/myubuntu68e2a091ef24: Pull completec393a882769e: Pull completeDigest: sha256:845fa3dcc9d0de1b9c701e1009918995da35a29012015f6c297a05edc489e018Status: Downloaded newer image for hejx/myubuntu:v1[root@kevin-test ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEhejx/myubuntu v1 c393a882769e 12 minutes ago 84.11 MB","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"}]},{"title":"Linux 指定目录扩容","slug":"Linux 指定目录扩容","date":"2021-05-07T16:00:00.000Z","updated":"2021-05-09T02:21:33.635Z","comments":true,"path":"2021/05/08/Linux 指定目录扩容.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/08/Linux 指定目录扩容.html","excerpt":"","text":"场景在阿里云上面使用自定义的镜像可能会导致系统盘无法扩容，这个时候就需要挂载数据盘进行弯道扩容。 挂载新硬盘到home目录挂载到home目录有两种情况：一种home目录是新的目录里面没有数据。第二种是home目录已经有了数据。 第一种很好处理，直接使用mount /dev/vdb1 /home命令就可以完成挂载,后面的就不用看了。第二种就比较麻烦，因为如果home目录有内容直接按第一种方法挂载会发现挂载之后home目录下的东西都不见了。1如果已经已经使用了直接挂载的方法造成home目录下的文件丢失，不要慌直接再将盘卸载掉（umount /dev/vdb1）就可以，卸载完文件就会恢复了。 下面主要讲一下第二种方法来挂载到home目录 使用mkdir transfer创建一个中转文件夹 使用mount /dev/vdb1 /transfer 将新硬盘挂载到transfer上 使用 cp -R /home/* /transfer 将home目录下的所有文件复制到中转文件夹 rm -rf /home/* 删除原硬盘上的home文件夹，为原硬盘腾出空间(可选项,可不删除) mount /dev/sdb1 /home接着讲硬盘再挂载到home文件夹 如果挂载时出现mount: you must specify the filesystem type错误这是因为没有设置文件系统格式，可使用-t参数设置文件系统格式 mount -t ext3 /dev/sdb1 /homedf -h 查看硬盘挂载情况，/dev/sdb1 如果现实了挂载到transfer 和home说明都挂载成功 [root@iZj6capfjz1mgt4s5ab7e6Z /]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 24G 14G 63% /tmpfs 3.9G 0 3.9G 0% /dev/shm/dev/vdb1 40G 13G 25G 34% /transfer/dev/vdb1 40G 13G 25G 34% /home卸载transfer上的挂载 umount /transfer(如无法卸载 可使用umount -fl /transfer强制卸载) 最后删除transfer文件夹rm -rf transfer","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"},{"name":"阿里云","slug":"阿里云","permalink":"https://blog.smilexin.cn/tags/阿里云/"}]},{"title":"Linux常用命令","slug":"Linux 常用命令","date":"2021-05-06T16:00:00.000Z","updated":"2021-05-07T03:48:07.378Z","comments":true,"path":"2021/05/07/Linux 常用命令.html","link":"","permalink":"https://blog.smilexin.cn/2021/05/07/Linux 常用命令.html","excerpt":"","text":"ln这是linux中一个非常重要命令。它的功能是为某一个文件在另外一个位置建立一个同步的链接，当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个相同的文件，我们只要在某个固定的目录，放上该文件，然后在其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。类似于windows里的快捷方式。 命令格式1ln [参数][源文件或目录][目标文件或目录] 命令参数1234567-b 删除，覆盖以前建立的链接-d 允许超级用户制作目录的硬链接-f 强制执行-i 交互模式，文件存在则提示用户是否覆盖-n 把符号链接视为一般目录-s 软链接(符号链接)-v 显示详细的处理过程 示例给文件创建软链接，为log2013.log文件创建软链接link2013，如果log2013.log丢失，link2013将失效：12# 注意建立软连接最好使用文件的绝对路径ln -s /opt/log2013.log /opt/link2013","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"}]},{"title":"Docker 部署MongoDB","slug":"Docker 部署MongoDB","date":"2020-04-16T16:00:00.000Z","updated":"2021-04-30T02:44:33.305Z","comments":true,"path":"2020/04/17/Docker 部署MongoDB.html","link":"","permalink":"https://blog.smilexin.cn/2020/04/17/Docker 部署MongoDB.html","excerpt":"","text":"MongoDB 是一款较为常用的NOSQL 数据库，结合 Docker 使用，能实现轻松配置部署、迁移，本文以下为简要介绍如何在 Docker 中部署并使用 MongoDB MongoDB Docker 镜像安装MongoDB 提供官方镜像，下载安装镜像方法如下：1docker pull mongo 以上命令为安装 MongoDB 最新版本的镜像。(需配置国内的镜像源) MongoDB Docker 容器创建MongoDB Docker 容器创建主要关心的就是数据文件的存储问题，这个可以使用容器的 volume 功能来解决 1docker run -p 17017:27017 -v &lt;LocalDirectoryPath&gt;:/data/db --name mongodb -d mongo --auth 在上面的命令中，几个命令参数的详细解释如下：-p 17017:27017 容器内部服务端口为27017, 映射到主机的17017端口-v 为设置容器的挂载目录，这里是将即本机中的目录挂载到容器中的/data/db中，作为 mongodb 的存储目录–name 为设置该容器的名称为 mongodb-d 设置容器以守护进程方式运行–auth 开启权限验证 配置容器1234567# 进入容器docker exec -it mongodb /bin/bash# 安装vimapt-get updateapt-get install vim# 修改 mongo 配置文件vim /etc/mongod.conf.orig 将其中的1bindIp: 127.0.0.1 注释掉 # bindIp: 127.0.0.1或者改成 bindIp: 0.0.0.0即可开启远程连接 MongoDB权限配置创建超级管理员 1db.createUser(&#123; user: &apos;admin&apos;, pwd: &apos;adminPwd&apos;, roles: [ &quot;root&quot; ] &#125;); MongoDB 内置角色root 超级管理员readAnyDatabase 任何数据库的只读权限userAdminAnyDatabase 任何数据库的读写权限userAdminAnyDatabase 任何数据库用户的管理权限dbAdminAnyDatabase 任何数据库的管理权限 开关MongoDB123456# 列出所有在运行的容器信息docker ps# 启动 mongodb 容器docker start mongodb# 关闭 mongodb 容器docker stop mongodb 结语这样我们就可以愉快的使用Docker运行MongoDB了 MongoDB Address: localhost:17017","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.smilexin.cn/tags/Docker/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.smilexin.cn/tags/MongoDB/"}]},{"title":"Golang 环境安装","slug":"Golang 环境安装","date":"2020-03-28T16:00:00.000Z","updated":"2021-04-30T02:44:33.309Z","comments":true,"path":"2020/03/29/Golang 环境安装.html","link":"","permalink":"https://blog.smilexin.cn/2020/03/29/Golang 环境安装.html","excerpt":"","text":"Go语言的安装可以在Go语言中文网进行下载对应系统版本的Go语言: https://studygolang.com/dl 我这里下载的是 1.14.1 的版本 环境配置123456# 使用go module管理依赖go env -w GO111MODULE=on# 配置国内镜像go env -w GOPROXY=https://goproxy.cn,direct# 安装goimports,go imports包的引入可以让代码书写变得更加快捷go get -v golang.org/x/tools/cmd/goimports GoLand配置主要配置File Watchers插件，使用goimports，让写代码更加舒服。","categories":[],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://blog.smilexin.cn/tags/Golang/"}]},{"title":"ActiveMQ的消息重试机制","slug":"ActiveMQ_消息重试机制","date":"2018-08-31T16:00:00.000Z","updated":"2021-04-30T02:44:33.304Z","comments":true,"path":"2018/09/01/ActiveMQ_消息重试机制.html","link":"","permalink":"https://blog.smilexin.cn/2018/09/01/ActiveMQ_消息重试机制.html","excerpt":"","text":"消费端处理失败时的消息重发机制 处理失败 指的是MessageListener的onMessage方法里抛出RuntimeException。 Message头里有两个相关字段：Redelivered默认为false，redeliveryCounter默认为0。 消息先由broker发送给consumer，consumer调用listener，如果处理失败，本地redeliveryCounter++，给broker一个特定应答，broker端的message里redeliveryCounter++，延迟一点时间继续调用，默认1s。超过6次，则给broker另一个特定应答，broker就直接发送消息到DLQ。 如果失败2次，consumer重启，则broker再推过来的消息里，redeliveryCounter=2，本地只能再重试4次即会进入DLQ。 重试的特定应答发送到broker，broker即会在内存将消息的redelivered设置为true，redeliveryCounter++，但是这两个字段都没有持久化，即没有修改存储中的消息记录。所以broker重启时这两个字段会被重置为默认值。","categories":[],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://blog.smilexin.cn/tags/ActiveMQ/"}]},{"title":"SpringBoot 配置加密","slug":"SpringBoot 配置加密","date":"2018-08-16T16:00:00.000Z","updated":"2021-04-30T02:44:33.316Z","comments":true,"path":"2018/08/17/SpringBoot 配置加密.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/17/SpringBoot 配置加密.html","excerpt":"","text":"前言实际项目开发过程中，我们的应用程序都有很多的配置文件（例如properties或者yml文件等），我们时常会遇到需要对配置文件敏感字段的参数内容进行加密处理(比如数据库连接密码、与第三方的通信密钥等)。 传统Spring解析配置文件传统Spring解析配置文件可以继承PropertyPlaceholderConfigurer类并重写其converProperty方法，在该方法内一般需要做两步处理： 根据参数名propertyName或者根据参数值propertyValue判断当前是否需要进行内容解密（判断是否需要进行解密操作） 如果需要解密，根据系统设计调用解密处理逻辑，然后调用父级converProperty方法 按照上面的思路，我们先实现自己的PropertyPlaceholderConfigurer子类，假如当前我们的需求是要将test.content参数值后面追加内容“《我是后加的内容》”1234567891011121314@Slf4jpublic class MyPropertyPlaceholderConfigurer extends PropertyPlaceholderConfigurer &#123; @Override protected String convertProperty(String propertyName, String propertyValue) &#123; //这里做对属性的内容的加解密等操作 if (propertyName.equalsIgnoreCase(&quot;test.content&quot;)) &#123; log.info(&quot;当前即将过滤的内容[&quot; + propertyName + &quot;]=[&quot; + propertyValue + &quot;]&quot;); propertyValue = propertyValue + &quot;《我是后加的内容》&quot;; &#125; else if (propertyName.equalsIgnoreCase(&quot;spring.datasource.password&quot;)) &#123; propertyValue = propertyValue.replace(&quot;abc&quot;, &quot;&quot;); &#125; return super.convertProperty(propertyName, propertyValue); &#125;&#125; 接下来，我们要告诉spring使用自定义的PropertyPlaceholderConfigurer，如果我们使用xml方式配置，则代码如下：1234567&lt;bean id=&quot;propertyConfigurer&quot; class=&quot;com.spring.boot.test.util.MyPropertPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath:application.poperties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 如果采用javaconfig方式时代码如下：12345678@Beanpublic PropertyPlaceholderConfigurer propertyPlaceholderConfigurer()&#123; PropertyPlaceholderConfigurer placeholderConfigurer=new MyPropertyPlaceholderConfigurer(); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource resource = resolver.getResource(&quot;classpath:application.properties&quot;); placeholderConfigurer.setLocation(resource); return placeholderConfigurer;&#125; 通过上面的步骤，我们可以在程序的TestService中使用自动注入或者Spring表达式@Value(“$(参数名)”)获取到的内容就是我们解密之后的内容。启动程序后可以看到日志内容12c.s.b.t.u.MyPropertyPlaceholderConfigurer[16] - 当前即将过滤的内容[test.content]=[测试内容]c.s.b.t.s.TestService[24] - 当前拿到的testContent=测试内容《我是后加的内容》 遗憾的时，上述方式存在两个缺点： 目前只支持properties配置文件，当我们使用yml文件后就不生效了，运行会报文件格式异常，如果要生效，必须复写底层的loadProperties方法分别对不同格式的文件进行解析。但是这样可能会麻烦的多。 当我们使用spring boot后，对数据库相关配置参数解析后，数据库自动初始化装配无法成功，即数据库会在PropertyPlaceholderConfigurer类之前初始化，如果加密内容正好是数据库连接密码，那么程序启动后会因为数据库无法连接而报错，程序自动挂断。错误内容：Failed to initialize pool: Access denied for user ‘root‘@’localhost’ (using password: YES) 面对以上问题，直接通过修改PropertyPlaceholderConfigurer解决的路子我并没有去测试，不过接下来我介绍另外一种方式解决这个问题，那就是spring boot集成jasypt框架实现对配置文件的参数内容加解密。 使用jasypt进行配置文件的加解密（推荐）Jasypt是一个优秀的加密库，支持密码、Digest认证、文本、对象加密，此外密码加密复合RFC2307标准。官方地址jasypt-spring-boot，集成Spring Boot，在程序引导时对属性进行解密。该工具包使用jasypt框架来处理properties和yml配置文件参数内容的加解密操作，该工具已经发布到了中央仓库供大家使用。而且文档信息非常详细。下面我简单说一下该工具的优势。 该工具支持注解方式开启jasypt功能，以及注解方式引入一个或多个需要处理的配置文件。 该工具同时支持properties与yml文件的解析处理。 该工具支持自定义加解密类型和复写加解密方法。 使用jasypt框架默认的加密方式存在一定的风险，那就是程序配置文件中，存在解密密文的密码。因为PBEWithMD5AndDES算法到处都可以找到实现。如果拿到了数据库密文和算法的密码，那么很容易解析出连接数据库的密码。一般严谨的做法是不会将密文信息与解密工具放在一起，避免程序被获取后，加密算法和数据库密码密文以及解密密码都同时被泄露。我们可以使用自定义的解密方案,将密钥信息同应用程序分离,增加安全性。 为了方便演示,我这里就直接把秘钥信息写在程序里面了 实现代码引入工具包12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 因为我这里引用的是jasypt-spring-boot-starter,所以它是引入后自动开启的,并不需要使用注解@EnableEncryptableProperties提示启动 实现自定义加解密规则MyEncryptablePropertyResolver1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.*.util.encdec.RSAUtil;import com.ulisesbocchio.jasyptspringboot.EncryptablePropertyResolver;/** * Created by hejx on 2018/8/11. */public class MyEncryptablePropertyResolver implements EncryptablePropertyResolver &#123; /** 需要解密的标识 **/ private final String cipher = &quot;ENC@&quot;; private final String PRIVATE_KEY = &quot;私钥&quot;; private final String PUBLIC_KEY = &quot;公钥&quot;; @Override public String resolvePropertyValue(String value) &#123; if (value != null &amp;&amp; value.startsWith(cipher)) &#123; value = value.substring(cipher.length()); // System.out.println(&quot;decrypt configure:&quot;+ value); return decrypt(value); &#125; return value; &#125; /** * 加密配置文件 * @param data * @return */ public final String encrypt(String data)&#123; return RSAUtil.encryptByPublicKey(data, PUBLIC_KEY); &#125; /** * 解密配置文件 * @param data * @return */ public final String decrypt(String data)&#123; return RSAUtil.decryptByPrivateKey(data, PRIVATE_KEY); &#125; public static void main(String[] args) &#123;// String username = encrypt(&quot;帐号&quot;);// String password = encrypt(&quot;密码&quot;);// System.out.println(&quot;username:&quot;+username);// System.out.println(&quot;password:&quot;+password); &#125;&#125; 注入自定义的解密规则 123456789@Configurationpublic class BaseBeanConfiguration &#123; @Bean(name=&quot;encryptablePropertyResolver&quot;) public EncryptablePropertyResolver encryptablePropertyResolver() &#123; return new MyEncryptablePropertyResolver(); &#125;&#125; 配置文件123456# 密文规则: ENC@ + 密文信息spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.url=ENC@datasourceUrlspring.datasource.username=ENC@djiwoqjdojqwodihdcdjfjfspring.datasource.password=ENC@密文jdsajoidwjqonkjsadfjifjwfspring.datasource.driver-class-name=com.mysql.jdbc.Driver 大功告成,自己去试试吧! 自定义解密逻辑这里记录一下我的小思路,大家可以根据项目具体情况选择使用 采用比较安全的RSA加密算法 构建时、运行时传入密钥，在加载属性前进行解密 开发环境可以将密钥放置在代码中，测试、灰度、生产等环境放置在构建脚本或者启动脚本中 提供专门的程序进行密钥的管理和配置的加解密操作（接口）","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"https://blog.smilexin.cn/tags/网络安全/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.smilexin.cn/tags/SpringBoot/"},{"name":"jasypt","slug":"jasypt","permalink":"https://blog.smilexin.cn/tags/jasypt/"},{"name":"加密","slug":"加密","permalink":"https://blog.smilexin.cn/tags/加密/"},{"name":"配置","slug":"配置","permalink":"https://blog.smilexin.cn/tags/配置/"},{"name":"配置文件加解密","slug":"配置文件加解密","permalink":"https://blog.smilexin.cn/tags/配置文件加解密/"}]},{"title":"layui 表单数据回显问题处理","slug":"layui 表单数据回显问题处理","date":"2018-08-15T16:00:00.000Z","updated":"2021-04-30T02:44:33.316Z","comments":true,"path":"2018/08/16/layui 表单数据回显问题处理.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/16/layui 表单数据回显问题处理.html","excerpt":"","text":"问题描述后台编辑页面的数据回显,时好时坏!（多发生于单选框） 尝试使用setTimeout进行延时填充数据,效果还是时好时坏,并不能有效解决问题! HTML1234567&lt;div class=&quot;layui-form-item&quot; pane=&quot;&quot;&gt; &lt;label class=&quot;layui-form-label&quot;&gt;议价规则&lt;/label&gt; &lt;div class=&quot;layui-input-block&quot;&gt; &lt;input lay-filter=&quot;is_bargain&quot; ng-model=&quot;entity.is_bargain&quot; type=&quot;radio&quot; name=&quot;is_bargain&quot; value=&quot;0&quot; title=&quot;不支持议价&quot;&gt; &lt;input lay-filter=&quot;is_bargain&quot; ng-model=&quot;entity.is_bargain&quot; type=&quot;radio&quot; name=&quot;is_bargain&quot; value=&quot;1&quot; title=&quot;支持议价&quot;&gt; &lt;/div&gt;&lt;/div&gt; JS1234567891011121314// 我这里还做了延时装载,效果不理想setTimeout(function()&#123; UE.getEditor(&apos;editor&apos;).setContent($scope.entity.product_content); layui.use(&apos;form&apos;, function()&#123; var form = layui.form; form.val(&apos;inputForm&apos;, &#123; &quot;is_bargain&quot;: $scope.entity.is_bargain, &quot;is_advance&quot;: $scope.entity.is_advance, &quot;freight_type&quot;: $scope.entity.freight_type, &quot;product_state&quot;: $scope.entity.product_state, &quot;product_unit&quot;: $scope.entity.product_unit &#125;); &#125;);&#125;,500); 问题分析因为是页面异步加载数据,所以可能存在加载数据的时候,layui组件没有完全加载完毕的情况。所以数据装载失败。 解决思路我没有在layui官方API中找到相关组件加载完毕的回调方法,所以这里改为HTML同步数据填充,让layui加载完成后直接显示HTML的内容即可。 原因是数据装载的时候,layui相关组件没有加载完毕造成装载数据失败! 后改为使用thymeleaf标签实现html的同步加载 相关代码后端1234567891011121314151617181920212223private final String PAGE_PREFIX = &quot;product/&quot;; // 页面前缀@RequestMapping(value = &quot;inputPage&quot;)public String inputPage(String id, ModelMap modelMap)&#123; String tempId = &quot;none&quot;; if(StringUtils.isNotBlank(id)) &#123; // 修改 ParamsMap productInfo = this.findProductInfo(id); // 查询需要修改的实体信息 modelMap.put(&quot;productInfo&quot;, productInfo); tempId = id; &#125; else &#123; // 新增 ParamsMap entity = initEntity(); modelMap.put(&quot;productInfo&quot;, entity); &#125; return PAGE_PREFIX + &quot;input&quot;;&#125;/** * 初始化实体(用于新增) * @return */private ParamsMap initEntity()&#123; String json = &quot;JSON对象字符串&quot;; return new ParamsMap(json);&#125; 前端123456789101112131415161718192021222324&lt;div class=&quot;layui-form-item&quot; pane=&quot;&quot;&gt; &lt;label class=&quot;layui-form-label&quot;&gt;预付款&lt;/label&gt; &lt;div class=&quot;layui-input-block&quot;&gt; &lt;input th:checked=&quot;$&#123;productInfo.is_advance==0&#125;&quot; lay-filter=&quot;is_advance&quot; type=&quot;radio&quot; name=&quot;is_advance&quot; value=&quot;0&quot; title=&quot;全款&quot;&gt; &lt;input th:checked=&quot;$&#123;productInfo.is_advance==1&#125;&quot; lay-filter=&quot;is_advance&quot; type=&quot;radio&quot; name=&quot;is_advance&quot; value=&quot;1&quot; title=&quot;支持预付款&quot;&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;layui-form-item&quot;&gt; &lt;label class=&quot;layui-form-label&quot;&gt;编辑内容&lt;/label&gt; &lt;div class=&quot;layui-input-inline&quot; style=&quot;padding-left: 20px;&quot;&gt; &lt;!-- 百度编辑器 --&gt; &lt;script id=&quot;editor&quot; th:utext=&quot;$&#123;productInfo.product_content&#125;&quot; type=&quot;text/plain&quot; style=&quot;width:500px;height:600px;&quot;&gt;&lt;/script&gt; &lt;/div&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt; var productInfo = [[$&#123;productInfo&#125;]]; // 可以让相关JS操作该对象 $().ready( function() &#123; if(productInfo)&#123; console.log(&quot;productInfo:&quot;,productInfo); &#125; &#125;);&lt;/script&gt;","categories":[],"tags":[{"name":"layui","slug":"layui","permalink":"https://blog.smilexin.cn/tags/layui/"}]},{"title":"thymeleaf 常用标签","slug":"thymeleaf 常用标签","date":"2018-08-15T16:00:00.000Z","updated":"2021-04-30T02:44:33.318Z","comments":true,"path":"2018/08/16/thymeleaf 常用标签.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/16/thymeleaf 常用标签.html","excerpt":"","text":"记录自己常用的thymeleaf标签 th:value属性赋值,常用于表单回显1&lt;input th:value=&quot;$&#123;user.name&#125;&quot; /&gt; th:checked选中为true,未选中为false,用于数据回显。1234567&lt;div class=&quot;layui-form-item&quot; pane=&quot;&quot;&gt; &lt;label class=&quot;layui-form-label&quot;&gt;议价规则&lt;/label&gt; &lt;div class=&quot;layui-input-block&quot;&gt; &lt;input th:checked=&quot;$&#123;productInfo.is_bargain==0&#125;&quot; lay-filter=&quot;is_bargain&quot; type=&quot;radio&quot; name=&quot;is_bargain&quot; value=&quot;0&quot; title=&quot;不支持议价&quot;&gt; &lt;input th:checked=&quot;$&#123;productInfo.is_bargain==1&#125;&quot; lay-filter=&quot;is_bargain&quot; type=&quot;radio&quot; name=&quot;is_bargain&quot; value=&quot;1&quot; title=&quot;支持议价&quot;&gt; &lt;/div&gt;&lt;/div&gt; th:selected给页面select下拉框赋值12345678910&lt;div class=&quot;layui-inline&quot;&gt; &lt;label class=&quot;layui-form-label&quot;&gt;商品单位&lt;/label&gt; &lt;div class=&quot;layui-input-block&quot;&gt; &lt;select id=&quot;product_unit&quot; name=&quot;product_unit&quot; lay-filter=&quot;product_unit&quot;&gt; &lt;option th:selected=&quot;$&#123;productInfo.product_unit==&apos;吨&apos;&#125;&quot; value=&quot;吨&quot; &gt;吨&lt;/option&gt; &lt;option th:selected=&quot;$&#123;productInfo.product_unit==&apos;千克&apos;&#125;&quot; value=&quot;千克&quot; &gt;千克&lt;/option&gt; &lt;option th:selected=&quot;$&#123;productInfo.product_unit==&apos;斤&apos;&#125;&quot; value=&quot;斤&quot; &gt;斤&lt;/option&gt; &lt;/select&gt; &lt;/div&gt;&lt;/div&gt; th:utext支持html的文本替换,可用于百度编辑器ueditor的数据回显12&lt;p th:utext=&quot;$&#123;htmlcontent&#125;&quot;&gt;conten&lt;/p&gt;&lt;script id=&quot;editor&quot; th:utext=&quot;$&#123;productInfo.product_content&#125;&quot; type=&quot;text/plain&quot; style=&quot;width:500px;height:600px;&quot;&gt;&lt;/script&gt; th:inline定义js脚本可以使用变量12345678&lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt; var productInfo = [[$&#123;productInfo&#125;]]; // productInfo 为后台传递过来的对象参数 $().ready( function() &#123; if(productInfo)&#123; console.log(&quot;productInfo:&quot;,productInfo); &#125; &#125;);&lt;/script&gt; th:if判断条件1&lt;a th:if=&quot;$&#123;userId == collect.userId&#125;&quot; &gt; th:unless和th:if判断相反1&lt;a th:href=&quot;@&#123;/login&#125;&quot; th:unless=$&#123;session.user != null&#125;&gt;Login&lt;/a&gt;","categories":[],"tags":[{"name":"thymeleaf","slug":"thymeleaf","permalink":"https://blog.smilexin.cn/tags/thymeleaf/"}]},{"title":"ElasticSearch 集群部署","slug":"ElasticSearch 集群部署","date":"2018-08-11T16:00:00.000Z","updated":"2021-04-30T02:44:33.308Z","comments":true,"path":"2018/08/12/ElasticSearch 集群部署.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/12/ElasticSearch 集群部署.html","excerpt":"","text":"集群节点角色默认情况下,每个节点都有成为主节点的资格,也会存储数据,还会处理客户端的请求。在一个生产集群中我们可以对这些节点的职责进行划分。集群中节点可以分为4种类型,主要是node.master和node.data这两个属性的不同组合 node.master：这个属性表示节点是否具有成为主节点的资格 注意：此属性的值为true,并不意味着这个节点就是主节点。 因为真正的主节点,是由多个具有主节点资格的节点进行选举产生的。 所以,这个属性只是代表这个节点是不是具有主节点选举资格。 node.data：这个属性表示节点是否存储数据。 全能节点(默认) node.master: true node.data: true这种组合表示这个节点即有成为主节点的资格,又存储数据,这个时候如果某个节点被选举成为了真正的主节点,那么他还要存储数据,这样对于这个节点的压力就比较大了。elasticsearch默认每个节点都是这样的配置 data节点 node.master: false node.data: true这种组合表示这个节点没有成为主节点的资格,也就不参与选举,只会存储数据。这个节点我们称为data(数据)节点。在集群中需要单独设置几个这样的节点负责存储数据。后期提供存储和查询服务。 master节点 node.master: true node.data: false这种组合表示这个节点不会存储数据,有成为主节点的资格,可以参与选举,有可能成为真正的主节点。 client节点 node.master: false node.data: false这种组合表示这个节点即不会成为主节点,也不会存储数据,这个节点的意义是作为一个client(客户端)节点,主要是针对海量请求的时候可以进行负载均衡。该类型节点只提供搜索结果的二级聚合功能。 master节点：普通服务器即可(CPU 内存 消耗一般)data节点：主要消耗磁盘,内存client节点：普通服务器即可(如果要进行分组聚合操作的话,建议这个节点内存也分配多一点) 部署集群我这里集群设置3个全能节点,让它们互相依靠,因为我这里只有一台物理机🤣。下载ElasticSearch安装包,启动head插件。 12345678910# 建立集群文件夹mkdir -p es_cluster/es_master# 将elasticsearch安装包拷贝到es_master文件夹待用cp elasticsearch-6.3.2.tar.gz es_cluster/es_master# 解压elasticsearchtar -vxf elasticsearch-6.3.2.tar.gz# 复制成 slave1 和 slave2cp -r elasticsearch-6.3.2 es_cluster/es_master/es_master1cp -r elasticsearch-6.3.2 es_cluster/es_master/es_master2cp -r elasticsearch-6.3.2 es_cluster/es_master/es_master3 修改节点配置12cd es_cluster/es_master/es_master1/es_master1$ vim config/elasticsearch.yml 在文件末尾加上以下配置123456789101112131415161718192021222324# 设置集群名称（唯一标识）cluster.name: smile# 设置节点名称node.name: master# 该节点可以竞争masternode.master: true# 该节点存储数据node.data: true# 设置绑定的ip,端口默认9200network.host: 127.0.0.1# Elasticsearch 服务使用的端口。http.port: 9200# 设置集群中各个节点之间的通信端口transport.tcp.port: 9300# 处理跨域问题http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 这个配置主要作用是找寻master候选者,如果不做配置,此节点会游离于集群之外discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;]# 当集群中Master候选者数量&gt;minimum_master_nodes数量时才执行选举行为# 推荐使用 int(master_eligible_nodes / 2) + 1discovery.zen.minimum_master_nodes: 2 同理修改Master2和Master3的配置文件,注意端口不要设置冲突了,主要就是修改以下三个配置 节点名称 内部通信端口 服务端口 启动集群123456➜ es_master cd es_master1➜ es_master1 ./bin/elasticsearch -d➜ es_master cd es_master2➜ es_master2 ./bin/elasticsearch -d➜ es_master cd es_master3➜ es_master3 ./bin/elasticsearch -d 进入es-head查看集群情况 合理配置避免脑裂现象elasticsearch集群一旦建立起来以后，会选举出一个master，其他都为slave节点。但是具体操作的时候，每个节点都提供写和读的操作。就是说，你不论往哪个节点中做写操作，这个数据也会分配到集群上的所有节点中。 这里有某个节点挂掉的情况，如果是slave节点挂掉了，那么首先关心，数据会不会丢呢？不会。如果你开启了replicate，那么这个数据一定在别的机器上是有备份的。别的节点上的备份分片会自动升格为这份分片数据的主分片。这里要注意的是这里会有一小段时间的yellow状态时间。 如果是主节点挂掉怎么办呢？当从节点们发现和主节点连接不上了，那么他们会自己决定再选举出一个节点为主节点。但是这里有个脑裂的问题，假设有5台机器，3台在一个机房，2台在另一个机房，当两个机房之间的联系断了之后，每个机房的节点会自己聚会，推举出一个主节点。这个时候就有两个主节点存在了，当机房之间的联系恢复了之后，这个时候就会出现数据冲突了。解决的办法就是设置参数：1discovery.zen.minimum_master_nodes: int(master_eligible_nodes / 2) + 1 discovery.zen.minimum_master_nodes这个参数决定了要选举一个Master需要多少个节点（最少候选节点数）。默认值是1。根据一般经验这个一般设置成 N/2 + 1，N是集群中Master节点的数量,并不是网上其他朋友解释的所有节点总数。官网有写明：官方文档说明 To prevent data loss, it is vital to configure the discovery.zen.minimum_master_nodes setting so that each master-eligible node knows the minimum number of master-eligible nodes that must be visible in order to form a cluster.Without this setting, a cluster that suffers a network failure is at risk of having the cluster split into two independent clusters — a split brain — which will lead to data loss. A more detailed explanation is provided in Avoiding split brain with minimum_master_nodesedit.To avoid a split brain, this setting should be set to a quorum of master-eligible nodes:1(master_eligible_nodes / 2) + 1 In other words, if there are three master-eligible nodes, then minimum master nodes should be set to (3 / 2) + 1 or 2:1discovery.zen.minimum_master_nodes: 2 discovery.zen.ping.timeoutdiscovery.zen.ping.timeout，等待ping响应的超时时间，默认值是3秒。如果网络缓慢或拥塞，建议略微调大这个值。这个参数不仅仅适应更高的网络延迟，也适用于在一个由于超负荷而响应缓慢的节点的情况。 如果您刚开始使用elasticsearch，建议搭建拥有3个Master节点的集群，这种方式可以把discovery.zen.minimum_master_nodes设置成2，这样就限制了发生脑裂现象的可能，且保持着高度的可用性：如果你设置了副本，在丢失一个节点的情况下，集群仍可运行。 集群选型轻量型服务全部节点可以直接使用默认配置【node.master: true node.data: true】,让它们互相依靠,可以更高的利用集群中机器的性能。 高访问量服务建议集群中设置3台以上的节点作为master节点【node.master: true node.data: false】这些节点只负责成为主节点，维护整个集群的状态。其他的机器作为【node.master: false node.data: true】的数据索引机器，并根据集群中索引机器数量，合理的设置shard的数量，提高并发度，降低集群压力。shard = hash(routing) % number_of_primary_shards。如果觉得检索性能还有瓶颈还可以考虑加入一些client类型机器【node.master=false node.data=false】,分担负载压力。","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.smilexin.cn/tags/ElasticSearch/"},{"name":"全文搜索","slug":"全文搜索","permalink":"https://blog.smilexin.cn/tags/全文搜索/"}]},{"title":"ElasticSearch 安装","slug":"ElasticSearch 安装","date":"2018-08-11T16:00:00.000Z","updated":"2021-04-30T02:44:33.307Z","comments":true,"path":"2018/08/12/ElasticSearch 安装.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/12/ElasticSearch 安装.html","excerpt":"","text":"安装环境 MacOS 10.13.6 jdk 1.8+ # es5.x 之后jdk的依赖版本最低1.8 nodejs v8.11.1 # es-head插件最低依赖 6.0 安装Elasticsearch进入Elasticsearch官网找寻最新版本的ElasticSearch进行下载安装123456789# 进入指定目录cd /MyDownloads# 下载elasticsearchwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.tar.gz# 解压elasticsearchtar -vxf elasticsearch-6.3.2.tar.gzcd elasticsearch-6.3.2 # 进入es# 启动es,将会打印大量日志信息,看到started就是启动成功了,es的默认端口是9200sh ./bin/elasticsearch 浏览器访问: http://127.0.0.1:9200/ 见到当前Elasticsearch信息就是启动成功了 es核心目录介绍 bin: 存放es的启动脚本的 config: 存放es配置文件的目录 lib: es依赖的第三方类库的目录 modules: 模块目录 plugins: 存放第三方插件的目录 安装head插件es返回信息是json结构,不够友好,head插件提供了友好的web界面,可以实现基本信息的查看,rest请求的模拟,以及数据的基本检索 下载安装elasticsearch-head 进去下载zip包12345678910111213141516# 解压unzip elasticsearch-head-master.zip# 安装cd elasticsearch-head-master/elasticsearch-head-master$ node -v # 查看nodejs版本是否为6.0以上/elasticsearch-head-master$ npm install # 安装插件elasticsearch-head/elasticsearch-head-master$ npm run start # 启动head插件/elasticsearch-head-master$ npm run start&gt; elasticsearch-head@0.0.0 start /elasticsearch-head-master&gt; grunt server(node:8433) ExperimentalWarning: The http2 module is an experimental API.Running &quot;connect:server&quot; (connect) taskWaiting forever...Started connect web server on http://localhost:9100 这里状态是未连接是因为我现在没启动es 集群状态 green: 代表es的服务正常运行 yellow: 代表集群健康不是很好,但是集群可以正常使用 red: 代表集群健康很差,这个时候可能有的虽然可以正常搜索数据但是已经出现了丢失数据的问题 注意事项因为ElasticSearch和elasticsearch-head本身是属于两个独立的进程的,他们之间的访问是有跨域问题的,所以需要进行跨域的配置修改1vim config/elasticsearch.yml # 修改配置文件 在elasticsearch.yml文件的末尾添加123#action.destructive_requires_name: truehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 启动es和head插件123/elasticsearch-6.3.2$ ./bin/elasticsearch -d/elasticsearch-6.3.2$ cd ../elasticsearch-head-master/Develop/elasticsearch-head-master$ npm run start 关闭ElasticSearch的几种方式如何不再使用CTRL+C关闭Elasticsearch CTRL+C当es在控制台运行的时候可以使用CTRL+C来关闭它 kill命令12ps -ef | grep elastic # 查看所有es进程信息kill pid 进入需要关闭的es文件夹中123cd /elasticsearch-6.3.2/elasticsearch-6.3.2$ ps -ef | grep `pwd` # 查看es进程信息kill pid","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.smilexin.cn/tags/ElasticSearch/"},{"name":"全文搜索","slug":"全文搜索","permalink":"https://blog.smilexin.cn/tags/全文搜索/"}]},{"title":"SpringBoot 定时任务","slug":"SpringBoot 定时任务","date":"2018-08-06T16:00:00.000Z","updated":"2021-04-30T02:44:33.315Z","comments":true,"path":"2018/08/07/SpringBoot 定时任务.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/07/SpringBoot 定时任务.html","excerpt":"","text":"SpringBoot自带了一个定时任务工具,不需要过多配置就可以轻松实现任务调度的功能,可以动态改变执行状态。也可以使用cron表达式设置定时任务。 代码内容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import lombok.extern.slf4j.Slf4j;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.scheduling.annotation.SchedulingConfigurer;import org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler;import org.springframework.scheduling.config.ScheduledTaskRegistrar;import java.util.Date;/** * Created by 追风少年 on 2018/8/7. * 定时任务管理 * @desc: 当任务线程池没有空闲线程的时候,之后的任务会等待线程池空闲后才运行 */@Slf4j@Configuration@EnableSchedulingpublic class TaskManager implements SchedulingConfigurer &#123; public static final ThreadPoolTaskScheduler threadPoolTaskSchedule = new ThreadPoolTaskScheduler(); @Scheduled(cron = &quot;0 0 2 * * *&quot;) public void task1() &#123; // 每天2点执行 log.info(&quot; running task1...&quot;); &#125; @Scheduled(cron = &quot;*/10 * * * * *&quot;) public void task2() &#123; log.info(&quot; running task2 10 秒运行一次...&quot;); &#125; @Scheduled(cron = &quot;*/10 * * * * *&quot;) public void task3() &#123; log.info(&quot; running task3 10 秒运行一次...&quot;); &#125; @Scheduled(cron = &quot;*/10 * * * * *&quot;) public void task4() &#123; log.info(&quot; running task4 10 秒运行一次...&quot;); int a = 10 / 0; // 任务异常终止不会影响后续任务执行 &#125; @Scheduled(cron = &quot;*/10 * * * * *&quot;) public void task5() &#123; log.info(&quot; running task5 10 秒运行一次...&quot;); Date now = new Date(); // 动态添加执行计划 for (int i = 0; i &lt; 15; i++) &#123; final int num = i; threadPoolTaskSchedule.schedule(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info(&quot; ==============&gt; other task num:&#123;&#125;&quot;, num); &#125; &#125;, now); &#125; &#125; /** * 配置任务执行线程池 * @param scheduledTaskRegistrar */ @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; log.info(&quot;==========&gt; threadPoolTaskSchedule initializing&quot;); threadPoolTaskSchedule.initialize(); threadPoolTaskSchedule.setPoolSize(4); scheduledTaskRegistrar.setScheduler(threadPoolTaskSchedule); &#125;&#125; @EnableScheduling 注解注：这里的 @EnableScheduling 注解,它的作用是发现注解 @Scheduled的任务并由后台执行。没有它的话将无法执行定时任务。引用官方文档原文：@EnableScheduling ensures that a background task executor is created. Without it, nothing gets scheduled. @Scheduled 注解@Scheduled接受两种定时的设置：Cron表达式和Rate/Delay表达式（毫秒值） Cron表达式cron的表达式是字符串，实际上是由六个子表达式，描述个别细节的时间表。这些子表达式使用空格分割，从左到右依次代表： Seconds Minutes Hours Day-of-Month Month Day-of-Week 例 “0 0 12 ? * WED” 在每星期三下午12:00 执行。 个别子表达式可以包含范围, 例如，在前面的例子里(“WED”)可以替换成 “MON-FRI”, “MON, WED, FRI”甚至”MON-WED,SAT”.Cron表达式在线生成器：http://cron.qqe2.com/ Rate/Delay表达式（毫秒值） @Scheduled(fixedRate = 6000)：上一次开始执行时间点后每隔6秒执行一次。 @Scheduled(fixedDelay = 6000)：上一次执行完毕时间点之后6秒再执行。 @Scheduled(initialDelay=1000, fixedRate=6000)：第一次延迟1秒后执行，之后按fixedRate的规则每6秒执行一次。 多线程处理定时任务SpringBoot定时任务都是通过一个线程来处理的，我估计是在定时任务的配置中设定了一个SingleThreadScheduledExecutor，于是看了源码，从ScheduledAnnotationBeanPostProcessor类开始一路找下去。果然，在ScheduledTaskRegistrar（定时任务注册类）中的ScheduleTasks中又这样一段判断：1234if(this.taskScheduler == null) &#123; this.localExecutor = Executors.newSingleThreadScheduledExecutor(); this.taskScheduler = new ConcurrentTaskScheduler(this.localExecutor);&#125; 这就说明如果taskScheduler为空，那么就给定时任务做了一个单线程的线程池，正好在这个类中还有一个设置taskScheduler的方法：1234567891011121314public void setScheduler(@Nullable Object scheduler) &#123; if(scheduler == null) &#123; this.taskScheduler = null; &#125; else if(scheduler instanceof TaskScheduler) &#123; this.taskScheduler = (TaskScheduler)scheduler; &#125; else &#123; if(!(scheduler instanceof ScheduledExecutorService)) &#123; throw new IllegalArgumentException(&quot;Unsupported scheduler type: &quot; + scheduler.getClass()); &#125; this.taskScheduler = new ConcurrentTaskScheduler((ScheduledExecutorService)scheduler); &#125;&#125; 这样问题就很简单了，我们只需用调用这个方法显式的设置一个ScheduledExecutorService就可以达到并发的效果了。我们要做的仅仅是实现SchedulingConfigurer接口，重写configureTasks方法就OK了；1234567891011121314151617181920212223242526272829303132import lombok.extern.slf4j.Slf4j;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.scheduling.annotation.SchedulingConfigurer;import org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler;import org.springframework.scheduling.config.ScheduledTaskRegistrar;/** * Created by 追风少年 on 2018/8/7. * 定时任务管理 * @desc: 当任务线程池没有空闲线程的时候,之后的任务会等待线程池空闲后才运行 */@Slf4j@Configuration@EnableSchedulingpublic class TaskManager implements SchedulingConfigurer &#123; public static final ThreadPoolTaskScheduler threadPoolTaskSchedule = new ThreadPoolTaskScheduler(); /** * 配置任务执行线程池 * @param scheduledTaskRegistrar */ @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; log.info(&quot;==========&gt; threadPoolTaskSchedule initializing&quot;); threadPoolTaskSchedule.initialize(); threadPoolTaskSchedule.setPoolSize(4); scheduledTaskRegistrar.setScheduler(threadPoolTaskSchedule); &#125;&#125;","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.smilexin.cn/tags/SpringBoot/"},{"name":"定时任务","slug":"定时任务","permalink":"https://blog.smilexin.cn/tags/定时任务/"}]},{"title":"Linux 定时删除以前的日志文件","slug":"Linux 定时删除以前的日志文件","date":"2018-08-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.311Z","comments":true,"path":"2018/08/03/Linux 定时删除以前的日志文件.html","link":"","permalink":"https://blog.smilexin.cn/2018/08/03/Linux 定时删除以前的日志文件.html","excerpt":"","text":"问题场景磁盘空间有限,需要定时删除6个月之前的应用系统日志相关文件。 实现策略使用crontab,每天凌晨删除以前的日志文件 编写shell脚本auto-del-180-days-ago-log.sh123456#!/bin/sh#description: Auto remove 6 months ago log file# 删除180天前的nohup文件find /data/appjar/*/nohup -mtime +180 -name &quot;nohup_*&quot; -exec rm &#123;&#125; \\;# 删除180天前的log文件find /data/appjar/*/log -mtime +180 -name &quot;*.log&quot; -exec rm &#123;&#125; \\; 命令解析：12# 这里的文件名需要根据应用的实际备份脚本生成的文件名称进行筛选find 对应目录 -mtime +天数 -name &quot;文件名&quot; -exec rm &#123;&#125; \\; 定时执行123crontab -e # 设置定时任务计划# 每天凌晨1点执行备份0 1 * * * sh /usr/script/auto-del-180-days-ago-log.sh","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://blog.smilexin.cn/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"},{"name":"shell","slug":"shell","permalink":"https://blog.smilexin.cn/tags/shell/"}]},{"title":"URL中jsessionid问题处理","slug":"url中jsessionid问题处理","date":"2018-07-29T16:00:00.000Z","updated":"2021-04-30T02:44:33.318Z","comments":true,"path":"2018/07/30/url中jsessionid问题处理.html","link":"","permalink":"https://blog.smilexin.cn/2018/07/30/url中jsessionid问题处理.html","excerpt":"","text":"问题描述当我从A系统中点击链接,使用内嵌iframe第一次跳转到B系统页面时,页面的ajax访问会出现如下异常,因为我这里的应用系统都是在同一台虚拟机上面的所以为了session的独立,我给每个系统设置了不同的session.cookie.name,所以这里url拼接的不是jsessionid而是我设置的cookiename 打开一个新的浏览器窗口，第一次访问服务器时，encodeRedirectURL()会在url后面附加上一段jsessionid。如果初始的url为:http://www.sina.com.cn最终得到的url为:http://www.sina.com.cn;jsessionid=2jcligmgi6fh。这样浏览器就会出现找不到服务器的异常信息。 解决方案后台编写一个过滤器,来阻止url中jsessionid的出现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import javax.servlet.*;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpServletResponseWrapper;import javax.servlet.http.HttpSession;import java.io.IOException;/** * Created by 追风少年 on 2018/7/28. * desc: 去除url中jsessionid */public class DisableUrlSessionFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; // skip non-http requests if (!(request instanceof HttpServletRequest)) &#123; chain.doFilter(request, response); return; &#125; HttpServletRequest httpRequest = (HttpServletRequest) request; HttpServletResponse httpResponse = (HttpServletResponse) response; // clear session if session id in URL if (httpRequest.isRequestedSessionIdFromURL()) &#123; HttpSession session = httpRequest.getSession(); if (session != null) session.invalidate(); &#125; // wrap response to remove URL encoding HttpServletResponseWrapper wrappedResponse = new HttpServletResponseWrapper(httpResponse) &#123; public String encodeRedirectURL(String url) &#123; return url; &#125; public String encodeURL(String url) &#123; return url; &#125; &#125;; // process next request in chain chain.doFilter(request, wrappedResponse); &#125; @Override public void destroy() &#123; &#125; &#125; Springboot配置过滤器简介 注解配置 12345678/** * 在SpringBoot中通过注解注册的方式简单的使用Filter * @author chengxi */@WebFilter(urlPatterns = &quot;/*&quot;, filterName = &quot;myfilter&quot;)public class FileterController implements Filter &#123; // ...&#125; 手动配置 1234567891011/** * 配置过滤器 * @param registry */@Beanpublic FilterRegistrationBean filterRegist() &#123; FilterRegistrationBean frBean = new FilterRegistrationBean(); frBean.setFilter(new DisableUrlSessionFilter()); frBean.addUrlPatterns(&quot;/*&quot;); return frBean;&#125; 配置 DisableUrlSessionFilter因为我这个过滤器是写在spring扫描范围之外的,所以我这里手动配置123456789101112131415161718192021222324import com.xx.xxxx.filter.DisableUrlSessionFilter;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Created by 追风少年 on 2018/7/30. */@Configurationpublic class ComponentFilterOrderConfig &#123; /** * 配置过滤器 * @param registry */ @Bean public FilterRegistrationBean filterRegist() &#123; FilterRegistrationBean frBean = new FilterRegistrationBean(); frBean.setFilter(new DisableUrlSessionFilter()); frBean.addUrlPatterns(&quot;/*&quot;); return frBean; &#125;&#125;","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.smilexin.cn/tags/SpringBoot/"},{"name":"session","slug":"session","permalink":"https://blog.smilexin.cn/tags/session/"}]},{"title":"nohup 日志过大的处理策略","slug":"nohup日志过大的处理策略","date":"2018-07-23T16:00:00.000Z","updated":"2021-04-30T02:44:33.317Z","comments":true,"path":"2018/07/24/nohup日志过大的处理策略.html","link":"","permalink":"https://blog.smilexin.cn/2018/07/24/nohup日志过大的处理策略.html","excerpt":"","text":"问题场景使用nohup后台运行应用程序,会将控制台日志持续录入 nohup.out 文件,当应用程序运行一段时间后会产生大量的日志记录,造成nohup.out文件巨大,难以查阅… 解决思路在服务不重启的情况下,把 nohup.out 文件按照日期或者文件大小来分成不同的文件 实现策略使用crontab，每天凌晨把日志文件复制一份，然后清空原来的日志文件，让程序往清空的日志文件里继续写日志。 注意事项：因为Linux只认服务一开始创建的那个文件，删除之后程序输出日志不会再新建一个日志文件，手工新建日志文件之后也不再往里面写日志。 所以只有清空以前的日志文件。 编写shell脚本脚本放置在 nohup.out 文件的同级目录下12345678910111213141516#!/bin/sh#description: Partition backup script for nohup.outthis_path=$(cd `dirname $0`;pwd)cd $this_path#echo $this_pathcurrent_date=`date -d &quot;-1 day&quot; &quot;+%Y%m%d&quot;`dir_path=$&#123;this_path&#125;/nohup/`date -d &quot;-1 day&quot; &quot;+%Y/%m/&quot;`#echo $current_date#echo $dir_pathif [ ! -d &quot;$&#123;dir_path&#125;&quot; ];then mkdir -p $&#123;dir_path&#125;else echo &quot;$&#123;dir_path&#125; existed&quot;ficp -f nohup.out $&#123;dir_path&#125;nohup_$&#123;current_date&#125;cat /dev/null &gt; nohup.out 定时执行123crontab -e # 设置定时任务计划# 每天凌晨1点执行备份0 1 * * * sh /data/appjar/myapp/myShell.sh 总结这样就能够实现按天保存历史的日志记录，如果服务每天的日志异常巨大则可以考虑使用更细粒度的时间划分，我这里使用天就足够了","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://blog.smilexin.cn/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"},{"name":"shell","slug":"shell","permalink":"https://blog.smilexin.cn/tags/shell/"},{"name":"部署","slug":"部署","permalink":"https://blog.smilexin.cn/tags/部署/"}]},{"title":"SpringBoot jar包部署实践","slug":"SpringBoot jar包部署实践","date":"2018-07-01T16:00:00.000Z","updated":"2021-04-30T02:44:33.315Z","comments":true,"path":"2018/07/02/SpringBoot jar包部署实践.html","link":"","permalink":"https://blog.smilexin.cn/2018/07/02/SpringBoot jar包部署实践.html","excerpt":"","text":"前言为实现快速搭建和开发，项目以Springboot框架搭建，Springboot搭建的项目可以将项目直接打成jar包并运行，无需自己安装配置Tomcat或者其他服务器，是一种方便快捷的部署方式。 使用maven打包项目123456789101112131415161718192021222324252627282930313233&lt;build&gt; &lt;finalName&gt;server&lt;/finalName&gt; &lt;!-- 打包时排除配置文件 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.properties&lt;/exclude&gt; &lt;exclude&gt;**/*.xml&lt;/exclude&gt; &lt;exclude&gt;**/*.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- 当项目中有多个main函数时需要指定启动的main函数 --&gt; &lt;!--&lt;configuration&gt;--&gt; &lt;!--&lt;mainClass&gt;com.hejx.managecenter.ManagecenterApplication&lt;/mainClass&gt;--&gt; &lt;!--&lt;/configuration&gt;--&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 外置配置文件Springboot读取核心配置文件（application.properties）的优先级为 Jar包同级目录的config目录 Jar包同级目录 classPath(即resources目录)的config目录 classpath目录 上面是springboot默认去拿自己的核心配置文件的优先级，还有一种最高优先级的方式是项目启动时通过命令的方式指定项目加载核心配置文件，命令如下 1java –jar -Dspring.config.location=xxx/xxx/xxxx.properties xxxx.jar 如果Spring Boot在优先级更高的位置找到了配置，那么它会无视优先级更低的配置。 所以我们只需要将配置文件放置到合适的位置就能够轻松实现外置配置文件的效果 编写shell脚本自定义shell脚本，实现项目的快捷启动，停止，重启，查看服务器运行状态，gc运行情况123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#!/bin/sh#chkconfig: 345 86 14#description: Startup and shutdown script for server.jar# 用于记录pidPIDFILE=./java.pid# jar包位置,可以统一使用server.jar这个名字,具体项目由文件夹决定SERVER=./server.jarARGS=&quot;-Xms128m-Xmx128m-Xss256k-XX:+DisableExplicitGC-XX:+UseConcMarkSweepGC-XX:+CMSParallelRemarkEnabled-XX:LargePageSizeInBytes=128m-XX:+UseFastAccessorMethods-XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=50&quot;start()&#123; if test -e $SERVER then echo -e &quot;Starting $SERVER&quot; if nohup java $ARGS -jar $SERVER &amp; then echo $! &gt; $PIDFILE echo -e &quot;server start OK&quot; else echo -e &quot;server start failed&quot; fi else echo -e &quot;Couldn&apos;t find jar&quot; fi&#125;status()&#123; if test -e $PIDFILE then echo -e &quot;Server is running, Pid is `cat $PIDFILE`&quot; else echo -e &quot;Server is not running&quot; fi&#125; stop()&#123; if test -e $PIDFILE then echo -e &quot;Stopping server&quot; if kill `cat $PIDFILE` then echo -e &quot;server stop OK&quot; else echo -e &quot;server stop faild&quot; fi else echo -e &quot;No server running&quot; fi&#125; restart()&#123; echo -e &quot;Restarting server&quot; stop start&#125;gc()&#123;echo -e &quot;gc status:\\n&quot;if jstat -gc `cat $PIDFILE` 1000 10then echo -e &quot;gc ok&quot;else echo -e &apos;gc fail&apos;fi&#125;# 根据输入的参数,选择执行对应方法,输入错误则提示使用说明case $1 in start) start ;; stop) stop ;; restart) restart ;; status) status ;; gc) gc ;; *) echo &quot;Usage: $SCRIPTNAME &#123;start|stop|restart|status|gc&#125;&quot; &gt;&amp;2 exit 1 ;;esacexit 0 部署结构linux服务器上新建个文件夹，将我们打好的项目jar包丢进去，在jar包的同级目录新建config文件夹用于存储配置文件，其结构如下图，server.sh为自己写的项目启动shell脚本 因为springboot默认先会去Jar包同级目录的config目录中寻找配置文件，所以jar包中就算含有配置文件也会被更高级别的配置文件所替代。所以打包时不是必须排除配置文件，但是我个人还是推荐打包时排除配置文件，如此一来就只有外部配置文件，这样如果配置异常发生异常会处理更加一目了然。 logback.xml 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt; %blue(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;) %green(%5p[%t]) %boldWhite(%-40.40logger&#123;39&#125; %3.3L) : %cyan(%m%n) &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;contextName&gt;managecenter&lt;/contextName&gt; &lt;property name=&quot;LOG_PATH&quot; value=&quot;log&quot; /&gt; &lt;!--设置系统日志目录--&gt; &lt;property name=&quot;APPDIR&quot; value=&quot;managecenter&quot; /&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_error.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。 而2013-12-21的日志文件在由fileNamePattern指定。%d&#123;yyyy-MM-dd&#125;指定日期格式，%i指定索引 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/error/log-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始， 命名日志文件，例如log-error-2013-12-21.0.log --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;===%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %logger Line:%-3L - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录error级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;error&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEWARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_warn.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/warn/log-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;===%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %logger Line:%-3L - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录warn级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEINFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_info.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/info/log-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;===%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %logger Line:%-3L - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录info级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot; /&gt; &lt;logger name=&quot;org.hibernate&quot; level=&quot;WARN&quot; /&gt; &lt;!-- 生产环境下，将此级别配置为适合的级别，以免日志文件太多或影响程序性能 --&gt; &lt;!--这里改level 生产环境改成ERROR 开发环境为INFO--&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;FILEERROR&quot; /&gt; &lt;appender-ref ref=&quot;FILEWARN&quot; /&gt; &lt;appender-ref ref=&quot;FILEINFO&quot; /&gt; &lt;!-- 生产环境将请stdout,testfile去掉 --&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; 操作项目进入 server.sh 所在的目录运行12345sh server.sh start # 启动项目sh server.sh status # 查看项目运行状态sh server.sh restart # 重启项目sh server.sh stop # 停止项目sh server.sh gc # 查看gc相关信息","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://blog.smilexin.cn/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.smilexin.cn/tags/Linux/"},{"name":"shell","slug":"shell","permalink":"https://blog.smilexin.cn/tags/shell/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.smilexin.cn/tags/SpringBoot/"},{"name":"部署","slug":"部署","permalink":"https://blog.smilexin.cn/tags/部署/"}]},{"title":"SpringBoot 2.0 jpa多数据源配置","slug":"SpringBoot 2.0 jpa多数据源配置","date":"2018-06-15T16:00:00.000Z","updated":"2021-04-30T02:44:33.314Z","comments":true,"path":"2018/06/16/SpringBoot 2.0 jpa多数据源配置.html","link":"","permalink":"https://blog.smilexin.cn/2018/06/16/SpringBoot 2.0 jpa多数据源配置.html","excerpt":"","text":"前言随着Springboot升级到2.0，原来1.5.x的Jpa多数据源配置不能用了。在此记录一下Springboot2.0的jpa多数据源配置 引入依赖首先，在pom.xml引入如下jar包 12345678910111213&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件1234567891011121314spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.one.url=jdbc:mysql://127.0.0.1:3306/test1?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=falsespring.datasource.one.username=spring.datasource.one.password=spring.datasource.one.driver-class-name=com.mysql.jdbc.Driverspring.datasource.druid.one.max-active=10spring.datasource.druid.one.max-wait=10000spring.datasource.test2.url=jdbc:mysql://127.0.0.1:3306/test2?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=falsespring.datasource.test2.username=spring.datasource.test2.password=spring.datasource.test2.driver-class-name=com.mysql.jdbc.Driverspring.datasource.druid.test2.max-active=10spring.datasource.druid.test2.max-wait=10000 强烈注意：Spring Boot 2.X 版本不再支持配置继承，多数据源的话每个数据源的所有配置都需要单独配置，否则配置不会生效 修改springboot数据库相关配置DataSourceConfig数据源配置12345678910111213141516171819202122232425262728293031import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import javax.sql.DataSource;/** * Created by 追风少年 on 2018/6/14. */@Configurationpublic class DataSourceConfig &#123; @Primary // 必须设置一个默认数据源 @Bean(name = &quot;oneDataSource&quot;) @Qualifier(&quot;oneDataSource&quot;) @ConfigurationProperties(&quot;spring.datasource.one&quot;) public DataSource supplyChainDataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125; @Bean(name = &quot;test2DataSource&quot;) @Qualifier(&quot;test2DataSource&quot;) @ConfigurationProperties(&quot;spring.datasource.test2&quot;) public DataSource orderDataSource()&#123; return DruidDataSourceBuilder.create().build(); &#125;&#125; OneDataSourceConfig配置第一个数据源（作为默认值）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.orm.jpa.HibernateSettings;import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties;import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.data.jpa.repository.config.EnableJpaRepositories;import org.springframework.orm.jpa.JpaTransactionManager;import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;import org.springframework.transaction.PlatformTransactionManager;import org.springframework.transaction.annotation.EnableTransactionManagement;import javax.annotation.Resource;import javax.persistence.EntityManager;import javax.sql.DataSource;import java.util.Map;/** * Created by 追风少年 on 2018/6/14. */@Configuration@EnableTransactionManagement@EnableJpaRepositories( entityManagerFactoryRef = &quot;oneEntityManagerFactory&quot;, transactionManagerRef = &quot;oneTransactionManager&quot;, basePackages = &#123;&quot;com.hejx.demo.dao.one&quot;&#125;)public class OneDataSourceConfig &#123; @Autowired @Qualifier(&quot;oneDataSource&quot;) private DataSource dataSource; @Primary @Bean(name = &quot;entityManagerPrimary&quot;) public EntityManager entityManager(EntityManagerFactoryBuilder builder) &#123; return entityManagerFactory(builder).getObject().createEntityManager(); &#125; @Resource private JpaProperties jpaProperties; private Map&lt;String, Object&gt; getVendorProperties() &#123; return jpaProperties.getHibernateProperties(new HibernateSettings()); &#125; @Primary // 设置为默认 @Bean(name = &quot;oneEntityManagerFactory&quot;) public LocalContainerEntityManagerFactoryBean entityManagerFactory(EntityManagerFactoryBuilder builder) &#123; return builder .dataSource(dataSource) .packages(&quot;com.hejx.demo.entity.one&quot;) .persistenceUnit(&quot;primaryPersistenceUnit&quot;) .properties(getVendorProperties()) .build(); &#125; @Primary // 设置为默认 @Bean(name = &quot;oneTransactionManager&quot;) public PlatformTransactionManager oneTransactionManager(EntityManagerFactoryBuilder builder) &#123; return new JpaTransactionManager(entityManagerFactory(builder).getObject()); &#125;&#125; Test2DataSourceConfig配置第二个数据源123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.orm.jpa.HibernateSettings;import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties;import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.jpa.repository.config.EnableJpaRepositories;import org.springframework.orm.jpa.JpaTransactionManager;import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;import org.springframework.transaction.PlatformTransactionManager;import org.springframework.transaction.annotation.EnableTransactionManagement;import javax.annotation.Resource;import javax.persistence.EntityManager;import javax.sql.DataSource;import java.util.Map;/** * Created by 追风少年 on 2018/6/14. */@Configuration@EnableTransactionManagement@EnableJpaRepositories( entityManagerFactoryRef = &quot;test2EntityManagerFactory&quot;, transactionManagerRef = &quot;test2TransactionManager&quot;, basePackages = &#123;&quot;com.hejx.demo.dao.test2&quot;&#125;)public class Test2DataSourceConfig &#123; @Autowired @Qualifier(&quot;test2DataSource&quot;) private DataSource dataSource; @Bean(name = &quot;test2EntityManager&quot;) public EntityManager entityManager(EntityManagerFactoryBuilder builder) &#123; return entityManagerFactory(builder).getObject().createEntityManager(); &#125; @Resource private JpaProperties jpaProperties; private Map&lt;String, Object&gt; getVendorProperties() &#123; return jpaProperties.getHibernateProperties(new HibernateSettings()); &#125; @Bean(name = &quot;test2EntityManagerFactory&quot;) public LocalContainerEntityManagerFactoryBean entityManagerFactory(EntityManagerFactoryBuilder builder) &#123; return builder .dataSource(dataSource) .packages(&quot;com.hejx.demo.entity.test2&quot;) .persistenceUnit(&quot;test2PersistenceUnit&quot;) .properties(getVendorProperties()) .build(); &#125; @Bean(name = &quot;test2TransactionManager&quot;) public PlatformTransactionManager transactionManager(EntityManagerFactoryBuilder builder) &#123; return new JpaTransactionManager(entityManagerFactory(builder).getObject()); &#125;&#125; 启动类最后需要排除默认数据库配置123456789101112131415import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.context.annotation.Configuration;@SpringBootApplication@Configuration@EnableAutoConfiguration(exclude=&#123;DataSourceAutoConfiguration.class&#125;)public class demoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(demoApplication.class, args); &#125;&#125; 注意事项各个框架的相关配置尽量去看官方文档进行配置，看第三方文章可能会有版本适时性问题。druid: https://github.com/alibaba/druid","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.smilexin.cn/tags/SpringBoot/"},{"name":"jpa","slug":"jpa","permalink":"https://blog.smilexin.cn/tags/jpa/"},{"name":"druid","slug":"druid","permalink":"https://blog.smilexin.cn/tags/druid/"}]},{"title":"高并发场景解决方案-应用拆分","slug":"高并发场景解决方案-应用拆分","date":"2018-05-19T16:00:00.000Z","updated":"2021-04-30T02:44:33.322Z","comments":true,"path":"2018/05/20/高并发场景解决方案-应用拆分.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/20/高并发场景解决方案-应用拆分.html","excerpt":"","text":"前言我们都知道单个服务器再优化它的处理都是有上限的，我们可以使用扩容以及使用缓存、消息队列等对程序进行优化，这些手段都可行但还不是全部。随着项目的需求完成的越来越多，应用自然会跟着越来越大，因此架构师就设计出了特别容易拓展的方案，从整体将一个应用拆分成多个应用。当然应用不是随便拆的，需要根据项目的实际情况进行拆分，一般大家会选择按照功能模块进行拆分，比如从一个大的交易系统里面单独拆出来订单系统和产品系统等等。 举例说明这里使用我现在负责并参与过的股票系统拆分过程，让大家体会一下这里的应用拆分。 最开始来公司的时候只有一个特别大的股票系统，这个系统包含了所有股票相关的功能，比如（用户查看股票行情数据、 用户在开市时间下单、用户查看订单信息、用户开户等等…），在深入的了解这个系统之后呢，我们发现这个系统许多功能在不同时间段内请求差别很大，比如大家都习惯在非开市期间开美股账户，在开市期间更多的是查看行情，在开市期间才能下单，查看订单信息个别时间段差别不是很大等等。 这种设计有个很明显的问题，就是开市期间股票行情的数据量特别的大，进行交易和查看订单可能稍微少一点，而开户操作基本上就没有。换句话说开户这种操作本身就没有什么压力，每个用户一般就开户一次就够了，而如果这个时候股票行情在开市期间出现了问题，它可能会带来整个系统都没有办法使用了，比如系统出现了长时间的Full GC 而本质上这可能只是行情的某一块出现了问题。 这种情况就非常有必要做应用拆分，同时对于拆分后，请求多压力大的应用我们可以多部署几台服务器来分担压力，这个效果会更好，实际改造中我们也是按照功能模块进行拆分。这个大系统被我们拆分出来很多应用，分别是： 行情中心（定时任务[3]，流程处理） 交易中心（股票买入和卖出） 账户中心（流程处理，定时任务） 用户中心（基础数据维护） 通知中心（短信、邮件、推送） 最开始的大系统基本上就只剩下接收API的请求了，拿到请求后调用各个系统提供的接口更新或者获取数据，这里我们各个系统之间调用使用的是dubbo,为了加深大家对拆分的理解我具体说一下拆分后的这些应用。 行情中心是我们最重要的一个应用，它本身要做的事情相对于好理解一些，就是我之前介绍过8000多支股票,这些股票相关的各种数据，比如股票在每个交易日每分钟的价格，开盘价，收盘价，最高价，最低价。以及股票的历史数据包括统计数据、分析数据等等。它还负责用户请求不同行情数据，提供对应的处理好的数据。因此我们就把行情中心继续进行拆分,一个应用主要是做定时任务的（负责抓取和订阅股票的所有数据），另外一个应用是负责处理用户的请求返回对应的数据，其实到这里拆分并没有完全，我们发现开市过程中有两个订阅的数据量特别大,很可能在开市期间会出现问题，因此我们把那2个订阅单独拆分出来各自成为一个应用，这样一来这里的定时任务实际上又被拆分成了3个独立的应用，这个算是比较复杂的了，其他的就相对简单很多。 我们这里都是使用分布式的任务，同时都是单独部署自成一个应用。主要原因是跑定时任务的系统和处理流程的系统他们通常差别还是挺大的，跑定时任务的系统它有时经常会需要更多的内存来处理。 根据核心功能拆分完行情中心、交易中心、账户中心这三大块应用中心之后呢，我们又从这里面拆分出来用户中心和通知中心，用户中心主要做一些登录注册等基本信息的维护，通知中心则只做短信邮件以及APP推送相关的处理，这些都做完后，之前一个应用的压力被很多小应用分担。 我们可以对这些拆分后的应用做更精准的监控。不同应用的压力，我们可以看得特别的清楚，更容易做一些处理。哪些应用有风险了我们也可以尽早发现，提前做好应对。拆分之后其实也更适合团队合作，每个人可以重点参与到指定的应用开发中，而且随着组内开发人员越来越多，可以根据负责的应用将大组拆分成小组专门负责。比如我现在就主要负责行情中心这一块，其他的应用偶尔也会参与一下，但是会少很多。 当然应用拆分并不是只有好处而没有弊端的。我们简单说一下拆分完后不好的地方： 管理成本：一个应用被拆分成了多个，它必然会带来管理上的复杂性，之前管理好一个应用就可以了，拆分完可能是几个十几个甚至几十个，管理成本会提升很多 机器成本：这也带来了服务器成本的提升，比如一个大应用拆分成了十个小应用，在CPU内存以及硬盘上的花费，每个小应用肯定不会将成本降到之前的十分之一，这里也不排除拆分后的应用可能和拆分前的大应用使用相同的配置，甚至更高 网络开销增多：应用多了势必会带来更多的网络开销，任何一个系统之间的调用都避免不了相应的网络开销，但这并不代表着有额外的网络开销我们就不能这样用了。大家平时使用的redis、数据库等等，其实每次调用也有一定的网络开销,但一般这里都不是瓶颈，尤其是系统之间调用，基本都是在局域网里面的 拆分原则业务优先每个系统都会天然的按照业务功能分成多个模块，每个模块又包含许多业务相关的功能。在系统拆分时我们就可以优先考虑按照业务的边界进行切割，切割完成后再针对每个模块进行拆解，循序渐进，逐渐迭代深入，最终完成系统的拆解。这个过程类似庖丁解牛，要找到关键之处下刀方能事半功倍。 循序渐进系统拆分过程中包含两个非常重要的工作（拆分和测试），二者缺一不可。并且二者是并行进行的，一定要边拆分边测试，每一步拆分完成都要保证系统功能是完整的，保证系统的测试是完整的。拆分需要小步前进，如此一来可以减少累积错误的发生。 兼顾技术：重构、分层系统不能为了分布式而分布式，系统拆分的代价相当的昂贵。当然如果有了拆分的需要的话，我们也不能白白浪费这么好的学习机会。 首先第一个是重构，拆分过程中不仅仅是对业务梳理的过程，也是对系统进行重构的过程。通过系统的重构，我们可以使用一些设计模式让代码结构更加清晰。具有更好的可读性而且方便之后的修改。 第二个是分层，拆分可以让系统分成许多功能单一的系统，这些系统可以根据需要使用不同的技术和架构进行实现。可以让熟悉不同技术的人做不同的事情，工作更高效，产品质量也可以提高。比如那些熟悉UI技术的人可以专注用户体验方面的研发，那些JAVA、C++方面的专家就可以把精力放在服务器端程序的开发上。那些熟悉数据库技术的人就可以把精力放在数据库的优化上。术业有专攻，让合适的人去做合适的事情。 现在有些人为了分布式而分布式，网上有个词说的非常逗叫做面向简历编程，就是不管系统是不是真的需要使用某个框架，是不是真的需要拆分，反正他就是要用，要用最新的技术，哪怕成本高昂，应用根本还没到需要使用分布式的时候。希望大家能够根据具体的业务需求和场景信息选择合适的技术框架。 可靠测试拆分是在对系统进行一次大手术，每一次的改动都要保证系统保持原来的行为不变。测试使得我们能有足够的信心进行下一步的拆分或者重构。不至于在错误的道路上越走越远，以至于错误累积，测试与拆分是如影随形的，每一步都要有足够的测试。没有测试的拆分和重构我真的不敢想象结果会是什么样子。 事前分析在大家明确了拆分原则之后，我们在实际做应用拆分时，还需要做一些思考。 应用之间的通信应用之间通信是选择RPC（Dubbo等）这种远程调用，还是通过消息队列进行调用，甚至是使用HTTP请求的形式(REST)，都需要具体场景做出相应的选择。 通常消息通知适用于传输的数据包小，但是数据量大，对实时性要求不高的场景。比如下单成功之后需要通过短信通知一下用户这种的。而选择RPC框架的实时性更好一些。这里通常不会使用传统的HTTP或Webservice服务，原因是使用RPC调用远程的service方法无感知，在配置好以后，和本地调用方法很像，当然如果只是细微的服务提供其实HTTP可能会更合适。 应用之间的数据库设计通常每个应用都有自己独立的数据库，如果是共同使用的技术信息，可以考虑放在一个common库中一起来使用。 避免事务操作跨应用尽量避免事务操作跨应用，分布式事务是一个很消耗资源的问题。应当在设计的时候尽量避免。这样是有好处的，比如应用和应用之间的耦合度降低，在一个应用挂了的情况下，其他的应用可以继续服务。同时开发过程中应用之间独立开发定义好服务接口就可以了，应用之间开发也会互不影响。","categories":[],"tags":[{"name":"高并发","slug":"高并发","permalink":"https://blog.smilexin.cn/tags/高并发/"},{"name":"应用拆分","slug":"应用拆分","permalink":"https://blog.smilexin.cn/tags/应用拆分/"},{"name":"分布式","slug":"分布式","permalink":"https://blog.smilexin.cn/tags/分布式/"}]},{"title":"高并发场景解决方案-应用限流","slug":"高并发场景解决方案-应用限流","date":"2018-05-17T16:00:00.000Z","updated":"2021-04-30T02:44:33.323Z","comments":true,"path":"2018/05/18/高并发场景解决方案-应用限流.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/18/高并发场景解决方案-应用限流.html","excerpt":"","text":"限流说明限流字面上的意思就是限制流量，实际上它是限制一段时间内允许通过的流量。就像你的宽带包了1个G的流量用完就没了，但是这里的流量不是大家平时说的1M，1G的这种流量单位，而是某个函数或者某个代码块执行的次数。因此我这里介绍的限流从根本上来说它是控制一段时间内某段代码执行的次数。 举例说明之前我们介绍股票分时线的时候，说过开市期间所有股票的分时数据并没有把它们直接保存到数据库里，而是放在了Redis里面，主要是通过缓存来保证用户看到数据的准确性与实时性，这个应对在分时线处理上没有什么问题。但是分时线处理完了不代表没有其他问题了，因为我们还需要看最近几天的数据分析图，通常是5天，我们称为五日K线图。这个时候就需要使用当日的分时数据加上最近4个交易日的分时数据合在一起来作成趋势图，那么最近4个交易日的数据从哪里来呢？ 很显然历史数据从数据库里面来拿更合适一些，拿多少天都能拿到，这个时候就要求我们在每个闭市之后把当前这个交易日里的每支股票的分时数据全部存储到数据库中，我大致统计了一下一个交易日下来所有股票的分时数据大约在 130W~140W 之间，意思是我每天在盘后需要有130W~140W的数据需要插入到数据库里面，如果你没有做限流，直接将这些数据插入到数据库中会有以下问题出现： 数据库的主库将会突然接收到130W左右的插入操作，这个首先是网络上的开销，很可能直接把你的带宽打满，导致其他请求无法正常的传输和处理。 其次他可能带来数据库负载突然增高导致无法处理某些数据库操作，也可能出现没有足够的连接，导致某些数据插入失败或者查询失败，也就是影响其他服务正常运行。 还有一点就是我们现在的数据库都做了主从设计,插入到主库的数据还需要同步给从库，这时瞬间插入了大量的数据会带来从库和主库的延迟特别大，这时通过从库查询到的数据不准确的概率也会跟着提升 而如果我们使用特定的手段放慢插入数据库的速度，又会是怎么样呢？ 比如这里我们以一个数据库肯定可以接受的恒定速率（假设每秒400条进行插入），这个时候数据库插入到数据库主库的速率会很正常，这时候主库表现也会正常，同步到从库也很正常，网络消耗我们也可以接受，也不会影响到其他服务。这时我们可以计算出插入完成的大致时间。 这里我们约定了恒定速率最多每秒400条，那么每分钟它将会插入将近24000条，总共需要的时间可以算出 130W / 2.4W ≈ 54.17 分钟可以插入完成。 通过这个场景的分析处理我们可以看出来限流在高并发场景下使用合理的话可以解决很关键的问题，这里需要注意的是刚才我这里提到的每秒400条恒定速率是我和DBA根据系统情况确定好的值，也是经过实际数据的一些计算，实际中大家可以使用多大也是需要拿实际的场景和数据来说话的。 回顾一下，关于股票K线图这个高并发场景涉及到的解决方案，为了当前的高并发场景能够更好的运行不出问题，我在缓存、应用拆分、限流里分别从不同的角度对这个场景进行了优化，这些其实并不是全部，在数据插入数据库时我还引入了线程池来协助更好的调度进行插入。同时因为每天插入的数据量太大（每天插入的数据量是百万级别的）因此我还引入了数据库分表将8000多支股票的分时数据插入到相似的512张表中，来保证每张表的数据量增长都不是特别的快。这样在查询数据的时候才会更快，具体我将在后面分表的文章中详细介绍。 这里是希望大家能明白一个道理，高并发场景下并不是直接选择某个方案处理下就可以了，而是要深究各个细节，不同的小场景可能会使用不同的方案，也可能是多个方案的组合使用。因此大家需要能清楚的了解可以使用哪些解决方案，不同的解决方案要解决的是什么问题，然后分析你遇到的高并发场景它适合运用哪些解决方案。 限流总结一般开发高并发常用的限流大概包括以下几种： 限制总并发数 限制瞬时的并发数 限制时间窗口内的平均速率 缓存+限流来应付618、双11这些高并发流量，在处理高并发问题上可以说是如虎添翼，不用担心瞬间流量导致系统挂掉或者雪崩，最终做到有损服务而不是不服务。但是限流需要评估好，它不可以乱用，否则会使正常流量出现一些奇怪的问题而导致用户抱怨。","categories":[],"tags":[{"name":"高并发","slug":"高并发","permalink":"https://blog.smilexin.cn/tags/高并发/"},{"name":"分布式","slug":"分布式","permalink":"https://blog.smilexin.cn/tags/分布式/"},{"name":"限流","slug":"限流","permalink":"https://blog.smilexin.cn/tags/限流/"}]},{"title":"Java多线程并发最佳实践","slug":"Java多线程并发最佳实践","date":"2018-05-16T16:00:00.000Z","updated":"2021-04-30T02:44:33.311Z","comments":true,"path":"2018/05/17/Java多线程并发最佳实践.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/17/Java多线程并发最佳实践.html","excerpt":"","text":"前言编写并发代码是比较难，尽管Java语言提供了许多同步和并发支持，但是最终写出没有Bug的Java并发代码还是需要依靠个人的勤奋与专业知识。Java多线程并发最佳实践是一组实践的好点子，有助于你快速开发出优质的并发代码。如果你是新手，需要熟悉一些基本概念，再来阅读本文会更有针对性。 使用本地变量(局部变量)应该总是使用本地变量，而不是创建一个类或实例变量，通常情况下，开发人员使用对象实例作为变量可以节省内存并可以重用，因为他们认为每次在方法中创建本地变量会消耗很多内存。下面代码的run()方法被多线程调用，为了实现一个新功能，你需要一个临时集合Collection，代码中这个临时集合作为静态类变量使用，然后在run方法的尾部清除这个集合以便下次重用，编写这段代码的人可能认为这是线程安全的，因为 CopyOnWriteArrayList是线程安全的，但是他没有意识到，这个方法run()是被多线程调用，那么可能多线程中一个线程看到另外一个线程的临时数据，即使使用Collections.synchronizedList也不能保证run()方法内的逻辑不变性，这个不变性是：这个集合是临时集合，只用来在每个线程执行内部可见即可，不能暴露给其他线程知晓。 1234567891011121314public class Example1 implements Runnable&#123; private static List&lt;Integer&gt; temp = new CopyOnWriteArrayList(); @Override public void run() &#123; // If need a temporary ArrayList here, should use local variable // List&lt;Integer&gt; temp = new ArrayList(); temp.add(55); temp.add(12); temp.clear(); &#125; &#125; 要保证这段代码的不可变应该使用本地变量1234567891011public class Example1 implements Runnable&#123; @Override public void run() &#123; // If need a temporary ArrayList here, should use local variable List&lt;Integer&gt; temp = new ArrayList(); temp.add(55); temp.add(12); &#125; &#125; 使用不可变类不可变类比如String Integer等一旦创建，不再改变，不可变类可以降低代码中需要的同步数量。 最小化锁的作用域范围任何在锁中的代码将不能被并发执行，如果你有5%代码在锁中，那么根据阿姆达尔定律，你的应用程序就不可能提高超过20倍，因为锁中这些代码只能顺序执行，降低锁的涵括范围，上锁和解锁之间的代码越少越好。 使用线程池的Excutor，而不是直接new Thread执行创建一个线程的代价是昂贵的，如果你要得到一个可伸缩的Java应用，那么你需要使用线程池，使用线程池管理线程。JDK提供了各种ThreadPool线程池和Executor。 宁可使用同步也不要使用线程的wait notify从Java 1.5以后增加了许多的同步工具，比如CycicBariier, CountDownLatch 和 Sempahore，你应当优先使用这些同步工具，而不是去思考如何使用线程的wait和notify方法，通过BlockingQueue实现生产-消费的设计比使用线程的wait和notify要好得多，也可以使用CountDownLatch实现多个线程的等待等等… 使用BlockingQueue实现生产消费模式大部分并发问题都可以使用producer-consumer生产-消费设计实现，而BlockingQueue是最好的实现方式，阻塞的队列不只可以处理单个生产单个消费，也可以处理多个生产和消费。 使用并发集合Collection而不是加了同步锁的集合Java提供了 ConcurrentHashMap CopyOnWriteArrayList 和 CopyOnWriteArraySet以及BlockingQueue Deque and BlockingDeque五大并发集合，宁可使用这些集合，也不要使用Collections.synchronizedList之类加了同步锁的集合。 CopyOnWriteArrayList 特别适合读很多写很少的应用场景 ConcurrentHashMap更是经常使用的并发集合 使用Semaphore创建有界的访问为了建立可靠的稳定的系统，对于数据库 文件系统和socket等资源必须要做有界的访问。Semaphore是一个可以限制这些资源开销的选择，如果某个资源需要控制并发的访问，使用Semaphore可以以最低代价实现线程的等待 宁可使用同步的代码块，也不要使用同步的方法 使用synchronized 同步代码块只会锁定一个对象，而不会将整个方法锁定 如果更改共同的变量或类的字段，首先选择原子性变量，然后使用volatile 如果你需要互斥锁，可以考虑使用ReentrantLock。 避免使用静态变量 静态变量在并发执行环境会制造很多问题，如果你必须使用静态变量，那么优先让它成为final 常量 如果用来保存集合Collection，那么考虑使用只读集合。否则的话一定要做同步处理以及并发处理","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"java","slug":"java","permalink":"https://blog.smilexin.cn/tags/java/"}]},{"title":"Executor 线程池详解","slug":"Executor 线程池详解","date":"2018-05-15T16:00:00.000Z","updated":"2021-04-30T02:44:33.308Z","comments":true,"path":"2018/05/16/Executor 线程池详解.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/16/Executor 线程池详解.html","excerpt":"","text":"new Thread的弊端 每次 new Thread 都会新建对象，性能差 通过 new Thread 创建的线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多的系统资源导致死机或者OOM（out of memory 内存溢出），这种问题的原因不是因为单纯的new一个Thread，而是可能因为程序的bug或者设计上的缺陷导致不断new Thread造成的 缺少更多功能，如更多执行、定期执行、线程中断 线程池的好处 重用存在的线程，减少对象创建、消亡的开销，性能好 可有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 提供定时执行、定期执行、单线程、并发数控制等功能 线程池核心类-ThreadPoolExecutorThreadPoolExecutor一共有七个参数，这七个参数配合起来，构成了线程池强大的功能 corePoolSize：核心线程数量 maximumPoolSize：线程最大线程数 workQueue：阻塞队列，存储等待执行的任务，非常重要，会对线程池运行过程产生重大影响 keepAliveTime：线程没有任务执行时最多保持多久时间终止（当线程中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交核心线程外的线程不会立即销毁，而是等待，直到超过keepAliveTime） unit：keepAliveTime的时间单位 threadFactory：线程工厂，用来创建线程，有一个默认的工场来创建线程，这样新创建出来的线程有相同的优先级，是非守护线程、同时也设置了线程名称 rejectHandler：如果workQueue满了并且没有空闲的线程时，这时还继续提交任务，我们就需要采取一种策略来处理这个任务。线程池主要提供了4种策略。 AbortPolicy：直接抛出异常（默认策略） CallerRunsPolicy：用调用者所在的线程执行任务 DiscardOldestPolicy：丢弃队列中最靠前的任务并执行当前任务 DiscardPolicy：直接丢弃当前任务 如果运行的线程数少于corePoolSize的话就会直接创建新线程来处理任务，即时线程池之中的其他线程是空闲的。如果线程池中的线程数量 &gt;= corePoolSize 且 &lt; maximumPoolSize的时候，只有当workQueue队列满了的时候才创建新线程去处理任务。如果设置的corePoolSize和maximumPoolSize是相同的话，那么创建的线程池大小是固定的，这时候如果有新任务提交，workQueue还没满的时候就会放进workQueue等待有空闲的线程来执行，这时如果workQueue也已经满了，那么它就通过后面配置的拒绝策略来处理这个任务。 所以判断的顺序主要为3个，第一个是corePoolSize，第二个是workQueue，第三个是maximumPoolSize。了解了这三个参数的关系之后，再来具体的介绍一下workQueue。 workQueueworkQueue是保存等待执行的任务的一个阻塞队列，当我们提交一个任务到线程池以后，线程池会根据当前线程池之中正在运行的线程数量来决定该任务的处理方式。处理方式主要有以下三种 直接切换（SynchronusQueue） 无界队列（LinkedBlockingQueue）：如果使用这种方式，那能够创建的最大线程数为corePoolSize,这时maximumPoolSize就不会起作用了。当线程池中所有的核心线程都是运行状态的时候，新的任务提交就会放入等待队列中 有界队列（ArrayBlockingQueue）：使用这种方式，可以将线程池的最大线程数量控制为maximumPoolSize，能够降低资源消耗，但是这种方式使得线程池对线程调度变的更困难。因为线程池与队列容量都是有限的。所以想让线程池的吞吐率和处理任务达到一个合理的范围，又想使我们的线程调度相对简单，并且还尽可能降低资源的消耗，我们就需要合理的限制这两个数量 分配技巧： [如果想降低资源的消耗包括降低cpu使用率、操作系统资源的消耗、上下文切换的开销等等，可以设置一个较大的队列容量和较小的线程池容量，这样会降低线程池的吞吐量。如果我们提交的任务经常发生阻塞，我们可以调整maximumPoolSize。如果我们的队列容量较小，通常需要把线程池大小设置的大一些，这样cpu的使用率相对来说会高一些。但是如果线程池的容量设置的过大，提高任务的数量过多的时候，并发量会增加，那么线程之间的调度就是一个需要考虑的问题。这样反而可能会降低处理任务的吞吐量。] ThreadPoolExecutor-方法概述初始化方法：由七个参数组合成四个初始化方法 其他方法： 序号 方法名 描述 1 execute() 提交任务，交给线程池执行 2 submit() 提交任务，能够返回执行结果 execute+Future 3 shutdown() 关闭线程池，等待任务都执行完 4 shutdownNow() 立刻关闭线程池，不等待任务执行完 5 getTaskCount() 线程池已执行和未执行的任务总数 6 getCompleteTaskCount() 已完成的任务数量 7 getPoolSize() 线程池当前的线程数量 8 getActiveCount() 当前线程池中正在执行任务的线程数量 线程池生命周期 RUNNING 状态说明：线程池处在RUNNING状态时，能够接收新任务，也能处理阻塞队列中的任务 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0! SHUTDOWN 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但是会继续处理阻塞队列中任务 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN STOP 状态说明：线程池处在STOP状态时，不接收新任务，也不处理阻塞队列中的任务，并且会中断正在处理的任务 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP TIDYING 状态说明：当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是没有任何内容的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING TERMINATED 状态说明：线程池彻底终止，就变成TERMINATED状态 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED 使用 Executor 创建线程池使用Executor可以创建四种线程池，都是使用的ThreadPoolExecutor的构造函数，只是参数的不同而已。使用Executor创建线程池只是使用比较方便，但是缺少了许多ThreadPoolExecutor实用的功能。比如以下函数的返回值是ExecutorService类型，该类型只包含基础的线程池方法，但却不包含线程监控相关方法，因此在使用返回值为ExecutorService的线程池类型创建新线程时要考虑到具体情况。 Executors.newCachedThreadPool() Executors.newFixedThreadPool() Executors.newSingleThreadExecutor() newCachedThreadPool创建一个可缓存的线程池，如果线程池的长度超过了处理的需要，可以灵活回收空闲线程。如果没有可回收的就新建线程。 源码实现12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; newFixedThreadPool创建一个定长线程池，可以固定线程池的最大并发数，处理不及的任务在队列中排队。 源码实现12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; newSingleThreadExecutor单线程化的线程池，线程池之中只有一个线程执行任务，可以保证所有任务按指定顺序执行（FIFO、优先级…） 源码实现123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newScheduledThreadPool定长线程池，支持定时和周期任务执行，当线程数设置为1时，功能就与Timer类似 源码实现123456789101112131415public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; // 此处super指的是ThreadPoolExecutor super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; ScheduledExecutorService使用方法ScheduledExecutorService提供了与Timer类似的方法，具体有兴趣的可以自己去了解，我这里就不具体介绍了 线程池配置推荐线程池在配置的时候需要根据任务的类型来配置线程池的核心线程数，当然这里只是给出参考值，具体的设置还需要根据实际情况进行调整。比如我们可以先将线程池设置为参考的值，然后根据运行情况、系统负载、资源利用率等等作出相应调整。 CPU密集型任务：需要尽量压榨CPU，参考值可以设为 CPU数量+1 IO密集型任务：参考值可以设置为 2 * CPU数量 总结我们使用线程池主要是为了重用已存在的线程，减少对象创建消亡，能有效的控制最大并发线程数，可以避免过多的资源竞争，避免阻塞，它也可以定时执行任务等控制线程的执行，性能比较好。当然这不代表我们就需要随时随地的使用线程池，一定要根据自己的实际场景来分析使用以及它的参数配置。 之前学习线程池的时候有一个同学尝试去用线程池优化一个比较简单的ID算法，他的大致想法是因为线程池可以允许多个线程一起计算，理应就会加快算法的效率。但在实际中他使用1W的量级去验证时却发现使用线程池耗费的时间还没有直接计算结果快。主要原因如下： 当线程池里的任务粒度很小时，小到任务计算的时间和任务调度的时间已经很接近的时候，这时候如果你使用线程池，反而会变得效率低下。因为他的任务调度和任务管理的时间将会更多。线程池好用也很容易使用，但是需要根据具体场景来使用","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"线程池","slug":"线程池","permalink":"https://blog.smilexin.cn/tags/线程池/"}]},{"title":"ReentrantLock与synchronized的区别","slug":"ReentrantLock与synchronized的区别","date":"2018-05-09T16:00:00.000Z","updated":"2021-04-30T02:44:33.314Z","comments":true,"path":"2018/05/10/ReentrantLock与synchronized的区别.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/10/ReentrantLock与synchronized的区别.html","excerpt":"","text":"ReentrantLockjava中有两类锁，一类是Synchronized，而另一类就是J.U.C中提供的锁。ReentrantLock与Synchronized都是可重入锁,本质上都是lock与unlock的操作。接下来介绍三种J.U.C中的锁，其中使用ReentrantLock与使用synchronized对比介绍。 ReentrantLock与synchronized的区别 可重入性：两者的锁都是可重入的，差别不大，有线程进入锁，锁的计数器自增1，等下降为0时才可以释放锁 锁的实现：synchronized是基于JVM实现的（用户很难见到，无法了解其实现），ReentrantLock是JDK代码实现的 性能区别：在最初的时候，synchronized比ReentrantLock差很多，当synchronized引入了偏向锁、轻量级锁（自选锁）后，现在二者的性能差别不大，官方推荐synchronized（写法更容易、在优化时其实是借用了ReentrantLock的CAS技术，试图在用户态就把问题解决，避免进入内核态造成线程阻塞） 功能区别： 便利性：synchronized更便利，它是由编译器保证加锁与释放。而ReentrantLock是需要手动释放锁，所以为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁 锁的细粒度和灵活度，ReentrantLock优于synchronized ReentrantLock独有的功能 可以指定是公平锁还是非公平锁，sync只能是非公平锁。（所谓公平锁就是先等待的线程先获得锁） 提供了一个Condition类，可以用来实现分组唤醒需要唤醒的线程。而不是像synchronized要么随机唤醒一个线程，要么唤醒全部线程 提供能够中断等待锁的线程的机制，通过 lock.lockInterruptibly() 实现这种机制。 ReentrantLock是一种自选锁，通过循环调用CAS操作来实现加锁。性能比较好的原因是避免了进入内核态的阻塞状态 是否放弃synchronized？从上边的介绍，看上去ReentrantLock不仅拥有synchronized的所有功能，而且有一些功能synchronized无法实现的特性。性能方面，ReentrantLock也不比synchronized差，那么到底我们要不要放弃使用synchronized呢？ 个人认为不要放弃synchronized J.U.C包中的锁定类是用于高级情况和高级用户的工具，一般来说除非你对Lock的某个高级特性有明确的需要或者有明确的证据（不包括怀疑）表明同步已经成为可伸缩性的瓶颈的时候，否则我建议还是继续使用synchronized。 原因如下： 相比较这些高级的锁定类，synchronized还是有一些优势的，比如synchronized不可能忘记释放锁。在退出synchronized块的时候，JVM会为你做这件事情。而使用lock锁需要自己释放。当你的程序能够通过测试，但是在实际工作时会出现死锁，那时候就会很难找出原因，这也是为什么不建议初级开发人员使用lock的理由。 当JVM使用synchronized管理锁定请求和释放时，JVM在生成线程转储时能够包括锁定信息，这些信息对调试非常有价值，因为它们可以标识死锁以及其他异常行为的来源。 几乎每个开发人员都熟悉synchronized，它可以在JVM的所有版本中进行工作，在JDK5.0成为标准之前，用lock类将意味着要利用特性，而不是每个JVM都有的，而且不是每个开发人员都熟悉的。在实际的项目中大家遇到需要加锁的场景，其实大部分都可以使用synchronized来解决，那种特别高级的比较复杂的情况其实还是很少的。 如何使用ReentrantLock？1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import lombok.extern.slf4j.Slf4j;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2018/5/10 13:16. **/@Slf4jpublic class LockExample &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static int count = 0; private final static Lock lock = new ReentrantLock(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count); &#125; private static void add() &#123; lock.lock(); try &#123; count++; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 分析源码123456789//初始化方面：//在new ReentrantLock的时候默认给了一个不公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//也可以加参数来初始化指定使用公平锁还是不公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 部分内置函数基础特性： tryLock()：仅在调用时锁定未被另一个线程保持的情况下才获取锁定 tryLock(long timeout, TimeUnit unit)：如果锁定在给定的等待时间内没有被另一个线程保持且当前线程没有被中断，则获取这个锁定 lockInterruptbily()：如果当前线程没有被中断的话，那么就获取锁定。如果中断了就抛出异常 isLocked()：查询此锁定是否由任意线程保持 isHeldByCurrentThread()：查询当前线程是否保持锁定状态 isFair()：判断是不是公平锁… Condition相关特性： hasQueuedThread(Thread)：查询指定线程是否在等待获取此锁定 hasQueuedThreads()：查询是否有线程在等待获取此锁定 getHoldCount()：查询当前线程保持锁定的个数，也就是调用lock()方法的个数… 读写锁：ReentrantReadWriteLock读写锁在没有任何读写锁的时候才可以取得写入锁(悲观读取，容易造成写线程饥饿)，也就是说如果一直存在读操作，那么写锁一直在等待没有读的情况出现，这样我的写锁就永远也获取不到，就会造成等待获取写锁的线程饥饿。 平时使用的场景并不多。123456789101112131415161718192021222324252627282930313233343536373839404142public class LockExample2 &#123; private final Map&lt;String, Data&gt; map = new TreeMap&lt;&gt;(); private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); private final Lock readLock = lock.readLock(); //读锁 private final Lock writeLock = lock.writeLock(); //写锁 public Data get(String key) &#123; readLock.lock(); try &#123; return map.get(key); &#125; finally &#123; readLock.unlock(); &#125; &#125; public Set&lt;String&gt; getAllKeys() &#123; readLock.lock(); try &#123; return map.keySet(); &#125; finally &#123; readLock.unlock(); &#125; &#125; public Data put(String key, Data value) &#123; writeLock.lock(); try &#123; return map.put(key, value); &#125; finally &#123; writeLock.unlock(); &#125; &#125; class Data &#123; &#125;&#125; 票据锁：StempedLockStempedLock控制锁有三种模式（写、读、乐观读）。一个StempedLock的状态是由版本和模式两个部分组成。锁获取方法返回一个数字作为票据（stamp），他用相应的锁状态表示并控制相关的访问。数字0表示没有写锁被授权访问，在读锁上分为悲观锁和乐观锁。 乐观读： 如果读的操作很多写的很少，我们可以乐观的认为读的操作与写的操作同时发生的情况很少，因此不悲观的使用完全的读取锁定。程序可以查看读取资料之后检查是否遭到写入资料的变更，再采取之后的措施。 如何使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import lombok.extern.slf4j.Slf4j;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;import java.util.concurrent.locks.StampedLock;/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2018/5/10 13:46. **/@Slf4jpublic class LockExample4 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static int count = 0; private final static StampedLock lock = new StampedLock(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count); &#125; private static void add() &#123; long stamp = lock.writeLock(); try &#123; count++; &#125; finally &#123; lock.unlock(stamp); &#125; &#125;&#125; StampedLock 源码例子StampedLock 源码里面给了一个例子，这个例子大家自己看可能比较麻烦，我这里翻译了下放出来。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class LockExample3 &#123; class Point &#123; private double x, y; private final StampedLock sl = new StampedLock(); void move(double deltaX, double deltaY) &#123; // an exclusively locked method long stamp = sl.writeLock(); try &#123; x += deltaX; y += deltaY; &#125; finally &#123; sl.unlockWrite(stamp); &#125; &#125; //下面看看乐观读锁案例 double distanceFromOrigin() &#123; // A read-only method long stamp = sl.tryOptimisticRead(); //获得一个乐观读锁 double currentX = x, currentY = y; //将两个字段读入本地局部变量 if (!sl.validate(stamp)) &#123; //检查发出乐观读锁后同时是否有其他写锁发生？ stamp = sl.readLock(); //如果没有，我们再次获得一个读悲观锁 try &#123; currentX = x; // 将两个字段读入本地局部变量 currentY = y; // 将两个字段读入本地局部变量 &#125; finally &#123; sl.unlockRead(stamp); &#125; &#125; return Math.sqrt(currentX * currentX + currentY * currentY); &#125; //下面是悲观读锁案例 void moveIfAtOrigin(double newX, double newY) &#123; // upgrade // Could instead start with optimistic, not read mode long stamp = sl.readLock(); try &#123; while (x == 0.0 &amp;&amp; y == 0.0) &#123; //循环，检查当前状态是否符合 long ws = sl.tryConvertToWriteLock(stamp); //将读锁转为写锁 if (ws != 0L) &#123; //这是确认转为写锁是否成功 stamp = ws; //如果成功 替换票据 x = newX; //进行状态改变 y = newY; //进行状态改变 break; &#125; else &#123; //如果不能成功转换为写锁 sl.unlockRead(stamp); //我们显式释放读锁 stamp = sl.writeLock(); //显式直接进行写锁 然后再通过循环再试 &#125; &#125; &#125; finally &#123; sl.unlock(stamp); //释放读锁或写锁 &#125; &#125; &#125;&#125; Condition的使用Condition可以非常灵活的操作线程的唤醒，下面是一个线程等待与唤醒的例子，其中用1234序号标出了日志输出顺序 示例代码123456789101112131415161718192021222324252627282930313233public class LockExample5 &#123; public static void main(String[] args) &#123; ReentrantLock reentrantLock = new ReentrantLock(); Condition condition = reentrantLock.newCondition(); new Thread(() -&gt; &#123;// 线程1 try &#123; reentrantLock.lock(); log.info(&quot;wait signal&quot;); // 1 condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info(&quot;get signal&quot;); // 4 reentrantLock.unlock(); &#125;).start(); new Thread(() -&gt; &#123; // 线程2 reentrantLock.lock(); log.info(&quot;get lock&quot;); // 2 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; condition.signalAll(); log.info(&quot;send signal ~ &quot;); // 3 reentrantLock.unlock(); &#125;).start(); &#125;&#125; 执行结果12342018-05-10 13:49:55.509 INFO [ Thread-0] com.hejx.tes.lock.LockExample5 29 : wait signal2018-05-10 13:49:55.512 INFO [ Thread-1] com.hejx.tes.lock.LockExample5 40 : get lock2018-05-10 13:49:58.512 INFO [ Thread-1] com.hejx.tes.lock.LockExample5 47 : send signal ~ 2018-05-10 13:49:58.512 INFO [ Thread-0] com.hejx.tes.lock.LockExample5 34 : get signal 分析代码线程1调用了reentrantLock.lock()方法，线程就加入到了AQS的等待队列里面去，线程1这时候会输出wait signal，一旦我们调用了condition.await();方法之后这个线程就从正常的AQS队列中移除了，对应的操作其实就是锁的释放。接着线程1马上就会加入到condition的等待队列里面去等待信号，线程2因为线程1释放锁的关系被唤醒，并判断它是否可以取到锁，于是线程2获取锁，也加入到了AQS的等待队列中，线程2在执行完之后调用了发送信号的方法condition.signalAll()，这时候condition队列里面有一个线程1的节点，于是它就被取出来了加入到AQS的等待队列里面去，需要注意的是这时候线程1并没有被唤醒，只是加到了AQS的等待队列里面去，当线程2发送完信号之后执行了unlock()方法释放锁，释放锁之后AQS中目前只有线程1，于是AQS释放锁按照从头到尾的顺序唤醒队列中的元素，线程1就被唤醒了继续开始执行condition.await();下面的语句，接着线程1释放锁reentrantLock.unlock();整个过程执行完毕。 我们可以看到整个结构过程是靠线程节点在AQS的等待队列和condition的等待队列中来回移动来实现的，condition作为一个条件类很好的维护了一个等待信号的队列的，并在适时的时候将节点加入到AQS的等待队列中实现唤醒操作。 通过我们代码执行的结果以及以上的分析可以看出来，condition也是一个多线程之间协调通讯的工具类，使得某个或者多个线程一起等待某个条件，只有该条件具备这些等待的线程才会被唤醒，这个条件就是信号。我们这里使用的是signalAll()也可以使用signal()来单个唤醒，这些等待的线程被唤醒之后重新争夺锁。condition主要是做这个事情。 总结 当只有少量竞争者，使用synchronized 竞争者不少但是线程增长的趋势是能预估的，使用ReetrantLock StampedLock对吞吐量有巨大的改进，特别是在读线程越来越多的场景下，StampedLock有一个巨大的api，对于加锁操作它很容易利用其它的方法使用锁不是看哪个高级用哪一个，适合使用场景的才是最好的，尤其需要注意的是synchronized不会造成死锁，jvm会自动释放死锁，而其他的锁如果你使用不当是可能造成死锁的，一旦有lock就一定要有unlock","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"同步锁","slug":"同步锁","permalink":"https://blog.smilexin.cn/tags/同步锁/"}]},{"title":"synchronized 使用详解","slug":"synchronized_使用详解","date":"2018-05-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.318Z","comments":true,"path":"2018/05/03/synchronized_使用详解.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/03/synchronized_使用详解.html","excerpt":"","text":"synchronized 是什么？线程安全是并发编程中的重要关注点，应该注意到的是，造成线程安全问题的主要诱因有两点，一是存在共享数据(也称临界资源)，二是存在多条线程共同操作共享数据。因此为了解决这个问题，我们可能需要这样一个方案，当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行，这种方式有个高尚的名称叫互斥锁，即能达到互斥访问目的的锁，也就是说当一个共享数据被当前正在访问的线程加上互斥锁后，在同一个时刻，其他线程只能处于等待的状态，直到当前线程处理完毕释放该锁。在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，可以替代Volatile功能），这点确实也是很重要的。 synchronized修饰的对象主要有4种。 修饰代码块：被修饰的代码称为同步代码块，线程开始执行同步代码块之前，必须先获得对同步监视器的锁定。任何时刻只能有一个线程可以获得对同步监视器的锁定，当同步代码块执行完成后，该线程会释放对该同步监视器的锁定。虽然java程序允许使用任何对象作为同步监视器，但 是同步监视器的目的就是为了阻止两个线程对同一个共享资源进行并发访问，因此通常推荐使用可能被并发访问的共享资源充当同步监视器。 修饰方法：被修饰的方法称为同步方法，它作用的范围是整个方法，同步监视器的作用对象是调用这个方法的对象 修饰静态方法：作用范围是整个静态方法，同步监视器的作用对象是这个类的所有对象 修饰类：作用的范围是synchronized后面括号括起来的部分，同步监视器的作用对象是这个类的所有对象 同步代码块为了解决并发操作可能造成的异常，java的多线程支持引入了同步监视器来解决这个问题，使用同步监视器的通用方法就是同步代码块。其语法如下：123synchronized(obj)&#123; //同步代码块&#125; 其中obj就是同步监视器，它的含义是：线程开始执行同步代码块之前，必须先获得对同步监视器的锁定。任何时刻只能有一个线程可以获得对同步监视器的锁定，当同步代码块执行完成后，该线程会释放对该同步监视器的锁定。虽然java程序允许使用任何对象作为同步监视器，但是同步监视器的目的就是为了阻止两个线程对同一个共享资源进行并发访问，因此通常推荐使用可能被并发访问的共享资源充当同步监视器。 代码示例示例代码同步监视器指定的是this，也就是调用该方法的对象 使用同一个对象进行调用代码12345678910111213141516171819202122232425262728293031@Slf4jpublic class SynchronizedExample1 &#123; public void test1()&#123; /** * 修饰一个代码块 * 作用范围：大括号括起的代码 * 作用对象：调用同步代码块的对象 **/ synchronized (this)&#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test1 &#123;&#125;&quot;, i); &#125; &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); /** * 为了达到演示效果这里使用线程池来执行 **/ ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test1(); &#125;); executorService.execute(() -&gt; &#123; example1.test1(); &#125;); &#125; &#125; 运行结果12345678910111213141516171819202018-05-03 11:08:47.791 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 02018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 12018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 22018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 32018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 42018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 52018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 62018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 72018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 82018-05-03 11:08:47.795 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 92018-05-03 11:08:47.795 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 02018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 12018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 22018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 32018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 42018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 52018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 62018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 72018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 82018-05-03 11:08:47.796 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 9 使用不同对象进行调用代码123456789101112131415161718192021222324@Slf4jpublic class SynchronizedExample1 &#123; public void test1(int objN)&#123; synchronized (this)&#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test1 &#123;&#125; - &#123;&#125;&quot;, objN, i); &#125; &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test1(1); &#125;); executorService.execute(() -&gt; &#123; example2.test1(2); &#125;); &#125;&#125; 运行结果12345678910111213141516171819202018-05-03 11:13:37.957 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 02018-05-03 11:13:37.957 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 02018-05-03 11:13:37.961 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 12018-05-03 11:13:37.962 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 12018-05-03 11:13:37.962 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 22018-05-03 11:13:37.962 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 22018-05-03 11:13:37.962 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 32018-05-03 11:13:37.962 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 32018-05-03 11:13:37.962 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 42018-05-03 11:13:37.962 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 42018-05-03 11:13:37.962 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 52018-05-03 11:13:37.963 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 52018-05-03 11:13:37.963 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 62018-05-03 11:13:37.963 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 62018-05-03 11:13:37.963 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 72018-05-03 11:13:37.963 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 72018-05-03 11:13:37.963 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 82018-05-03 11:13:37.963 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 82018-05-03 11:13:37.964 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 20 : test1 1 - 92018-05-03 11:13:37.964 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 20 : test1 2 - 9 结论结果正如我所料，因为这里同步监视器指定的是this，也就是调用该方法的对象，所以如果使用不同的对象调用同步代码块的时候，不同调用对象之间是相互不影响的 同步方法同步方法就是使用synchronized关键字修饰某个方法，这个方法就是同步方法。这个同步方法(非static方法)无须显式指定同步监视器，同步方法的同步监视器是this，也就是调用该方法的对象。通过同步方法可以非常方便的实现线程安全的类，线程安全的类有如下特征： 属于该类的共享对象可以方便的被多个线程安全的访问 每个线程调用该对象的任意方法之后都能得到正确的结果 每个线程调用该对象的任意方法之后，该对象状态依然能保持合理状态 代码示例使用同一对象进行调用代码12345678910111213141516171819202122@Slf4jpublic class SynchronizedExample1 &#123; public synchronized void test2()&#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test2 &#123;&#125;&quot;, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(); &#125;); executorService.execute(() -&gt; &#123; example1.test2(); &#125;); &#125;&#125; 运行结果12345678910111213141516171819202018-05-03 11:41:11.313 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 02018-05-03 11:41:11.316 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 12018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 22018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 32018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 42018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 52018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 62018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 72018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 82018-05-03 11:41:11.317 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 92018-05-03 11:41:11.317 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 02018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 12018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 22018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 32018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 42018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 52018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 62018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 72018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 82018-05-03 11:41:11.318 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 9 使用不同对象进行调用代码12345678910111213141516171819202122@Slf4jpublic class SynchronizedExample1 &#123; public synchronized void test2(int objN)&#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test2 &#123;&#125; - &#123;&#125;&quot;, objN, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; example2.test2(2); &#125;); &#125;&#125; 运行结果12345678910111213141516171819202018-05-03 11:40:17.423 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 02018-05-03 11:40:17.425 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 02018-05-03 11:40:17.433 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 12018-05-03 11:40:17.433 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 12018-05-03 11:40:17.433 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 22018-05-03 11:40:17.433 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 22018-05-03 11:40:17.433 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 32018-05-03 11:40:17.433 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 32018-05-03 11:40:17.433 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 42018-05-03 11:40:17.434 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 42018-05-03 11:40:17.434 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 52018-05-03 11:40:17.434 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 52018-05-03 11:40:17.434 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 62018-05-03 11:40:17.434 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 62018-05-03 11:40:17.434 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 72018-05-03 11:40:17.434 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 72018-05-03 11:40:17.434 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 82018-05-03 11:40:17.434 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 82018-05-03 11:40:17.434 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 92018-05-03 11:40:17.435 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 9 结论同步方法的同步监视器是作用于调用方法的对象，多个调用对象之间是互相不影响的。 synchronized修饰静态方法代码示例12345678910111213141516171819202122@Slf4jpublic class SynchronizedExample1 &#123; public static synchronized void test2(int objN)&#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test2 &#123;&#125; - &#123;&#125;&quot;, objN, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; example2.test2(2); &#125;); &#125;&#125; 运行结果12345678910111213141516171819202018-05-03 14:08:29.922 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 02018-05-03 14:08:29.927 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 12018-05-03 14:08:29.927 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 22018-05-03 14:08:29.927 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 32018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 42018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 52018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 62018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 72018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 82018-05-03 14:08:29.928 INFO [pool-2-thread-1] com.hejx.tes.sync.SynchronizedExample1 19 : test2 1 - 92018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 02018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 12018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 22018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 32018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 42018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 52018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 62018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 72018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 82018-05-03 14:08:29.929 INFO [pool-2-thread-2] com.hejx.tes.sync.SynchronizedExample1 19 : test2 2 - 9 结论因为synchronized修饰静态方法的时候，同步监视器的作用对象是这个类的所有对象，所以同一时刻只会有一个线程调用synchronized修饰的静态方法。 synchronized修饰类synchronized修饰类的同步监视器的作用对象也是这个类的所有对象,所以其造成的效果同synchronized修饰静态方法的效果是相同的，这里我偷下懒就写下相应的语法123456789101112131415161718192021222324@Slf4jpublic class SynchronizedExample1 &#123; public void test2(int objN)&#123; synchronized(SynchronizedExample1.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info(&quot;test2 &#123;&#125; - &#123;&#125;&quot;, objN, i); &#125; &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; example2.test2(2); &#125;); &#125;&#125; synchronized关键字的继承问题我发现许多地方提及synchronized的关键字不能被继承，但是通过实验发现synchronized的关键字是能够被继承的。 其实真相是这样的，“synchronized不能被继承”，这句话有2种不同意思，一种是比较正常的、很容易让人想到的意思；另一种是“不正常的”或者说是“java中文界”广泛认同了的意思。 第一种理解方式（错误的）：父类中有个synchronized方法，子类继承了父类，但子类没覆写该方法。通过子类实例来使用该方法时，按“synchronized不能被继承”，意思就为：该子类的该方法就变成了非synchronized方法。 第二种理解方式：synchronized并不属于方法定义的一部分，不能被继承。子类覆写了该方法，如果在覆写时不明确写上synchronized，那这个方法就不是synchronized。换句话说，虽然继承了，但是没把synchronized继承下来，也就意味着“synchronized不能被继承”。 总的来说：synchronized方法，一定要显示标明，它是不能隐式标明的 释放同步监视器的锁定任何线程进入同步代码块，同步方法之前，必须先获得对同步监视器的锁定，那么如何释放对同步监视器的锁定呢，线程会在一下几种情况下释放同步监视器： 当前线程的同步方法、同步代码块执行结束，当前线程即释放同步监视器； 当前线程在同步代码块、同步方法中遇到break,return终止了该代码块、方法的继续执行； 当前线程在同步代码块、同步方法中出现了未处理的Error或Exception，导致了该代码块、方法的异常结束； 当前线程执行同步代码块或同步方法时，程序执行了同步监视器对象的wait()方法，则当前线程暂停，并释放同步监视器； 以下几种情况，线程不会释放同步监视器： 线程执行同步代码块或同步方法时，程序调用Thread.sleep(),Thread.yield()方法来暂停当前线程的执行，当前线程不会释放同步监视器 线程执行同步代码块时，其他线程调用了该线程的suspend()方法将该线程挂起，该线程不会释放同步监视器，当然，程序应尽量避免使用suspend()和resume()方法来控制线程 synchronized 可见性synchronized 可见性主要依靠JMM关于synchronized的两条规定 线程解锁前，必须把共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁是同一把锁） 原子性对比 synchronized是不可中断的锁，当代码执行到synchronized作用范围之内的时候是必须等待代码执行完的。 lock是可中断的锁，只要调用了unlock就可以解锁了。 synchronized在竞争激烈的时候性能下降会特别的快，synchronized适合竞争不激烈的时候进行使用，可读性较好。 lock在竞争激烈的时候依然能保持常态，编码时需要注意lock与unlock的一一对应关系。 Atomic：竞争激烈的时候也能维持常态，性能比lock还要好，但是只能维护一个值。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"同步锁","slug":"同步锁","permalink":"https://blog.smilexin.cn/tags/同步锁/"}]},{"title":"单例模式详解","slug":"单例模式详解","date":"2018-05-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.320Z","comments":true,"path":"2018/05/03/单例模式详解.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/03/单例模式详解.html","excerpt":"","text":"单例模式是什么？单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式。 意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 主要解决问题：一个全局使用的类频繁地创建与销毁。 何时使用：当你想控制实例数目，节省系统资源的时候。 实现方式：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 关键代码：构造函数是私有的，对外提供访问唯一实例的静态方法 注意事项 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 单例模式的几种实现方式单例模式的实现有多种方式，如下所示： 懒汉模式基本写法-线程不安全12345678910111213141516171819202122/** * 懒汉模式-线程不安全 * 单例实例在第一次使用时进行创建 */public class SingletonExample1 &#123; // 私有构造函数 private SingletonExample1() &#123; &#125; // 单例对象 private static SingletonExample1 instance = null; // 静态的工厂方法 public static SingletonExample1 getInstance() &#123; if (instance == null) &#123; //a1 instance = new SingletonExample1(); //a2 &#125;//a3 return instance; &#125; &#125; 以上代码在单线程下运行没有问题，但是在多线程环境下这段代码就会出现问题。问题发生在 a1~a3 行代码：123if (instance == null) &#123; instance = new SingletonExample1();&#125; 比如2个线程同时访问这个方法，都访问到a1行代码的时候，分别拿到instance实例的值都是null，都去做 is null 判断，都去做一次实例化，这样的话就会生成2个不同的实例对象。有些朋友可能会说，我这个方法里面就为了拿一个实例，以上代码就算实例化2次也不会影响最后的结果。但是如果私有构造函数在实现的时候会做很多的操作，且包含只能做一次的操作（资源的处理，运算…），这个时候如果执行2次就会出现错误。这里我只是表明这样写是线程不安全的。 synchronized修饰工厂方法-线程安全-不推荐12345678910111213141516171819202122/** * 懒汉模式-线程安全 * 单例实例在第一次使用时进行创建 */public class SingletonExample3 &#123; // 私有构造函数 private SingletonExample3() &#123; &#125; // 单例对象 private static SingletonExample3 instance = null; // 静态的工厂方法 public synchronized static SingletonExample3 getInstance() &#123; if (instance == null) &#123; instance = new SingletonExample3(); &#125; return instance; &#125;&#125; 获取实例的静态工厂方法在添加了synchronized修饰后，它里面的代码在同一时间内只允许一个线程访问，因此它可以保证是线程安全的。这种写法并不推荐，因为用上synchronized修饰方法后，它通过同一时间内只允许一个线程访问来保证了线程安全，但是它却带来了性能的严重开销 双重同步锁单例模式-线程安全这种方式采用双锁机制，安全且在多线程情况下能保持高性能。1234567891011121314151617181920212223242526/** * 懒汉模式 -》 双重同步锁单例模式 * 单例实例在第一次使用时进行创建 */public class SingletonExample4 &#123; // 私有构造函数 private SingletonExample4() &#123; &#125; // 单例对象 volatile &gt; 禁止指令重排 private volatile static SingletonExample4 instance = null; // 静态的工厂方法 public static SingletonExample4 getInstance() &#123; if (instance == null) &#123; // 双重检测机制 // B synchronized (SingletonExample4.class) &#123; // 同步锁 if (instance == null) &#123; instance = new SingletonExample4(); // A - 3 &#125; &#125; &#125; return instance; &#125;&#125; 注意事项1private volatile static SingletonExample4 instance = null; 这里注意静态变量 instance 必须使用 volatile 修饰，不然会出现线程安全问题。 原因如下：12345synchronized (SingletonExample4.class) &#123; // 同步锁 if (instance == null) &#123; instance = new SingletonExample4(); // A - 3 &#125;&#125; 以上代码在同一时间内只能有一个线程进行访问，而一个线程访问之后，当前这个instance已经被实例化了，当第二个线程再访问的时候发现instance已经有值了就不会再进行实例化了，就直接返回实例了。 那么问题究竟出在哪呢？这个要从CPU的指令说起。1instance = new SingletonExample4(); 当我们执行上面这行代码，它要执行以下操作： memory = allocate() 分配对象的内存空间 ctorInstance() 初始化对象 instance = memory 设置instance指向刚分配的内存 在完成了这3步之后，instance就指向了它实际分配的内存地址了。 在单线程下这3步执行完了这时候直接返回没有任何问题，指令重排对单线程是没有任何影响的，因为这3步随意调换不会对这个返回的instance发生任何影响。但是在多线程情况下就不一定了。 JVM和cpu优化，对以上3步发生了指令重排： memory = allocate() 分配对象的内存空间 instance = memory 设置instance指向刚分配的内存 ctorInstance() 初始化对象 因为第二步和第三步本质上没有前后依赖的关系，因此CPU和JVM的指令优化是可以让它们产生顺序变化的。在这个前提下我们再来看这里的双重检测机制：12345678910public static SingletonExample4 getInstance() &#123; if (instance == null) &#123; // 双重检测机制 // B synchronized (SingletonExample4.class) &#123; // 同步锁 if (instance == null) &#123; instance = new SingletonExample4(); // A &#125; &#125; &#125; return instance;&#125; 如果AB两个线程同时执行到这个方法，A已经走到了 instance = new SingletonExample4(); 这行代码，而B才走到if (instance == null)第一个判断代码。且A已经设置instance指向刚分配的内存，但是还没有进行初始化对象，这时候B线程进行判断instance的值就会不等于null，直接返回。而线程B拿到这个还没有做初始化对象的instance之后一旦调用就会出现问题。虽然这个发生的概率不大但是它也是有线程安全问题的。上面这个问题是由指令重排造成的，而volatile可以限制指令重排。这就是为什么必须使用volatile修饰instance变量。 当我们使用volatile之后就不会出现指令重排带来的对象未初始化的线程安全问题，它就变成线程安全的了。 饿汉模式饿汉模式的单一实例不是在第一次使用时进行创建的，而是在类装载的时候进行创建。由于是在类装载的时候进行创建，因此它能够保证是线程安全的。如果单例类的构造方法中没有包含过多的操作处理，饿汉模式其实是可以接受的不足之处： 如果单例类的构造方法包含过多的操作处理，就会使类加载的时候特别的慢，因此可能会引起性能问题。 如果使用饿汉模式的话，只进行类的加载却没有进行实际的调用的话，它会造成资源的浪费。 因此我们使用饿汉模式需要考虑两个问题： 它的私有构造函数在实现的时候没有进行过多的处理 这个类在实际的过程中肯定会被使用，这样的话就不会造成资源的浪费12345678910111213141516171819/** * 饿汉模式-线程安全 * 单例实例在类装载时进行创建 */public class SingletonExample2 &#123; // 私有构造函数 private SingletonExample2() &#123; &#125; // 单例对象 private static SingletonExample2 instance = new SingletonExample2(); // 静态的工厂方法 public static SingletonExample2 getInstance() &#123; return instance; &#125;&#125; 枚举单例模式-比较推荐可能很多人没见过使用枚举定义的这种写法，首先枚举的构造函数是JVM来保证这个方法只被调用一次，因此当我们通过枚举里面的一个值来调用getInstance()方法的时候它可以保证实例对象只被生成一次且在这个类被调用之前初始化的。 对比懒汉模式：相比于懒汉模式在线程安全性方面更容易保证 对比饿汉模式：它是在实际调用的时候才做实际对象的初始化不会造成资源的浪费1234567891011121314151617181920212223242526/** * 枚举模式：最安全 */public class SingletonExample5 &#123; // 私有构造函数 private SingletonExample5() &#123; &#125; public static SingletonExample5 getInstance() &#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton &#123; INSTANCE; private SingletonExample5 singleton; // JVM保证这个方法绝对只调用一次 Singleton() &#123; singleton = new SingletonExample5(); &#125; public SingletonExample5 getInstance() &#123; return singleton; &#125; &#125;&#125; 总结综合各点，个人比较推荐使用双重同步锁单例模式和枚举单例模式。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.smilexin.cn/tags/设计模式/"}]},{"title":"深入剖析volatile关键字","slug":"深入剖析volatile关键字","date":"2018-05-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.320Z","comments":true,"path":"2018/05/03/深入剖析volatile关键字.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/03/深入剖析volatile关键字.html","excerpt":"","text":"volatile关键字的两层语义一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的 禁止进行指令重排序 先看一段代码，假如线程1先执行，线程2后执行：12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 volatile保证原子性吗？从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子：12345678910111213141516171819202122232425262728293031323334353637@Slf4jpublic class CountExample &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static volatile int count = 0; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count); &#125; private static void add() &#123; count++; &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是5000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于5000的数字。 这里因为count++实际上执行了3步操作 读取count的最新值 执行+1操作 写入+1后的值 因为使用volatile修饰了count变量，第一步操作没有问题每次都是读取的最新的值，但是线程A读取最新的值为2在线程A写回主内存前,线程B读取的最新的值还是为2， 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); double check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 共享变量在线程间不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"}]},{"title":"AtomicLong与LongAdder的区别","slug":"AtomicLong与LongAdder的区别","date":"2018-05-01T16:00:00.000Z","updated":"2021-04-30T02:44:33.304Z","comments":true,"path":"2018/05/02/AtomicLong与LongAdder的区别.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/02/AtomicLong与LongAdder的区别.html","excerpt":"","text":"AtomicLongAtomicLong是依靠Unsafe通过CAS来保证Long类型操作的原子性。 LongAdderLongAdder的核心思想是将AtomicLong的内部核心数据value分离成一个数组，每个线程访问时通过hash等算法映射到其中一个数字进行计数，而最终的计数结果则为这个数组的求和累加。 其中热点数据value会被分离成多个单元的cell，每个cell独自维护内部的值，当前对象的实际值由所有的cell累计合成。 这样就将热点进行了有效的分离并提高了并行度，这样一来LongAdder就相当于在AtomicLong的基础上将单点的更新压力分散到各个节点上。在低并发的时候通过对base的直接更新也可以很好的保障和AtomicLong性能基本一致，而在高并发的时候则通过热点分散提高了性能。 LongAdder的缺点是在统计的时候如果有并发更新，也就是说我这边在统计各个单元cell的总值，你那边又在做更新操作，就可能导致统计的数据有所误差。 总结 AtomicLong还有compareAndSet一类的CAS方法，需要精确控制某个值的并发增减的场景都要用AtomicLong。 LongAdder 个人认为只能作为一个累加器来使用，它的类名已经说明了这个事实。 总的来说：AtomicLong相对于LongAdder来说应用场景更为广泛。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"高并发","slug":"高并发","permalink":"https://blog.smilexin.cn/tags/高并发/"},{"name":"Atomic","slug":"Atomic","permalink":"https://blog.smilexin.cn/tags/Atomic/"},{"name":"计数器","slug":"计数器","permalink":"https://blog.smilexin.cn/tags/计数器/"}]},{"title":"并发与高并发的基本概念","slug":"并发与高并发的基本概念","date":"2018-05-01T16:00:00.000Z","updated":"2021-04-30T02:44:33.320Z","comments":true,"path":"2018/05/02/并发与高并发的基本概念.html","link":"","permalink":"https://blog.smilexin.cn/2018/05/02/并发与高并发的基本概念.html","excerpt":"","text":"并发同时拥有两个或者多个线程，如果程序在单核处理器上运行，多个线程将交替地换入或者换出内存，这些线程是同时“存在”的，只是每个线程都处于执行过程中的某个状态，如果程序运行在多核处理器上，此时程序中的每个线程都将分配到一个处理器核上，因此它们可以同时运行。 高并发高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，通常它是指，通过设计保证系统能够同时并行处理很多请求。 并发与高并发的区别当我们说多线程并发时，其实我们更多的是讨论多个线程操作了相同的资源，这时我们讨论点更多的是落在保证线程安全以及合理分配和使用资源上。而高并发主要指系统运行过程中遇到“短时间内遇到大量操作请求”的情况，主要发生在系统集中收到大量请求（例如：12306的抢票情况；天猫双十一活动）。当我们说高并发时，我们谈的是是如何提高现有程序的性能，更多的是对高并发场景的一些解决方案，思路啦、手段等等。如果高并发处理不好，不仅仅降低了用户的体验度（请求响应时间过长），同时可能导致系统宕机，严重的甚至导致OOM异常，系统停止工作等。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://blog.smilexin.cn/tags/并发/"},{"name":"高并发","slug":"高并发","permalink":"https://blog.smilexin.cn/tags/高并发/"}]},{"title":"RSA的公钥和私钥的使用详解","slug":"RSA的公钥和私钥的使用详解","date":"2018-04-26T16:00:00.000Z","updated":"2021-04-30T02:44:33.313Z","comments":true,"path":"2018/04/27/RSA的公钥和私钥的使用详解.html","link":"","permalink":"https://blog.smilexin.cn/2018/04/27/RSA的公钥和私钥的使用详解.html","excerpt":"","text":"什么是RSARSA算法是一种非对称密码算法，所谓非对称，就是指该算法需要一对密钥，使用其中一个加密，则需要用另一个才能解密。公钥和私钥是对等的，使用其中一个加密数据另外一个都能够进行解密操作。 这个时候我们就需要思考个问题什么时候使用公钥加密，什么时候使用私钥加密。 使用场景 签名 使用私钥加密，公钥解密，用于让所有的公钥所有者验证私钥所有者的身份并且用来防止私钥所有者发布的内容被篡改。但是不能用来保证内容不被他人获得。 加密 用公钥进行加密，私钥进行解密，用于向公钥所有者发布信息，这个信息可能被他人篡改，但是无法被他人获得 如果甲想给乙发一个安全的保密的数据,那么应该甲乙各自有一个私钥,甲先用乙的公钥加密这段数据,再用自己的私钥加密这段加密后的数据.最后再发给乙,这样确保了内容即不会被读取,也不会被篡改. 甲用乙方的公钥进行加密，是为了只有乙方能够解密，保证了数据的安全性； 甲用自己的私钥进行加密，发送给乙方后，乙方用甲方的公钥进行解密，可以唯一识别这是甲方发过来的数据，且甲方不能抵赖。因为一对公钥和私钥是唯一的。 这样既保证了安全性，也保证了唯一性。 总结你只要想：既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"https://blog.smilexin.cn/tags/网络安全/"}]},{"title":"混合加密算法(RSA和DES)","slug":"混合加密算法(RSA和DES)","date":"2018-04-26T16:00:00.000Z","updated":"2021-04-30T02:44:33.320Z","comments":true,"path":"2018/04/27/混合加密算法(RSA和DES).html","link":"","permalink":"https://blog.smilexin.cn/2018/04/27/混合加密算法(RSA和DES).html","excerpt":"","text":"混合加密的理由 由于随着计算机系统能力的不断发展，DES的安全性比它刚出现时会弱得多，追溯历史破解DES的案例层出不穷，一台实际的机器可以在数天内破解DES是让某些人相信他们不能依赖DES的安全性的唯一方法。而相对于DES，RSA的安全性则相对高些，虽然破解RSA的案例也有，但其所付出的代价是相对大的(相对DES)，如今RSA的密钥也在升级，这说明破解RSA的难度也在增大。 在RSA加解密算法中提及到RSA加密明文会受密钥的长度限制，这就说明用RSA加密的话明文长度是有限制的，而在实际情况我们要进行加密的明文长度或许会大于密钥长度，这样一来我们就不得不舍去RSA加密了。对此，DES加密则没有此限制。 鉴于以上两点(个人观点)，单独的使用DES或RSA加密可能没有办法满足实际需求，所以就采用了RSA和DES加密方法相结合的方式来实现数据的加密。 实现方式 发送方使用DES密钥加密信息(明文)。 发送方使用接收方的RSA公钥加密前面的DES密钥串信息。 最终将混合信息进行传递。 而接收方接收到信息后： 接收方自己的用RSA私钥解密DES密钥信息。 再用RSA解密获取到的密钥信息解密密文信息。 最终就可以得到我们要的信息(明文)。 实现例子12345678910111213141516171819202122232425262728293031323334353637383940/// &lt;summary&gt;/// RSA和DES混合加密/// &lt;/summary&gt;/// &lt;param name=&quot;data&quot;&gt;待加密数据&lt;/param&gt;/// &lt;param name=&quot;publicKey&quot;&gt;RSA公钥&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;public Param Encrypt(string data, string publicKey)&#123; //加密数据 DESSecurity DES = new DESSecurity(); string DESKey = DES.GenerateKey(); string encryptData = DES.Encrypt(data, DESKey); //加密DESkey RSASecurity RSA = new RSASecurity(); string encryptDESKey = RSA.Encrypt(DESKey, publicKey); Param mixParam = new Param(); mixParam.DESKey = encryptDESKey; mixParam.Data = encryptData; return mixParam;&#125;/// &lt;summary&gt;/// RSA和DES混合解密/// &lt;/summary&gt;/// &lt;param name=&quot;data&quot;&gt;待解密数据&lt;/param&gt;/// &lt;param name=&quot;key&quot;&gt;带解密的DESKey&lt;/param&gt;/// &lt;param name=&quot;privateKey&quot;&gt;RSA私钥&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;public string Decrypt(string data, string key, string privateKey)&#123; //解密DESKey RSASecurity RSA = new RSASecurity(); string DESKey = RSA.Decrypt(key, privateKey); //解密数据 DESSecurity DES = new DESSecurity(); return DES.Decrypt(data, DESKey);&#125;","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"https://blog.smilexin.cn/tags/网络安全/"}]},{"title":"IDEA将已有项目添加到git","slug":"IDEA将已有项目添加到git","date":"2018-04-09T16:00:00.000Z","updated":"2021-04-30T02:44:33.309Z","comments":true,"path":"2018/04/10/IDEA将已有项目添加到git.html","link":"","permalink":"https://blog.smilexin.cn/2018/04/10/IDEA将已有项目添加到git.html","excerpt":"","text":"场景介绍将本地正在开发的项目添加到远程Git仓库 详细步骤 在远程仓库创建项目,拿到项目的HTTP链接 进入到项目目录（IDEA使用Terminal窗口直接就是项目根目录），通过git shell （可以安装git for window） 执行 以下命令 123456789101112# 若本地项目不是git项目,则需要执行init进行初始化git项目git init# 给项目设置远程Git仓库git remote add origin https://gitee.com/***/***.git# 抓取远程仓库数据，并自动合并远程分支git pull origin master# 将项目所有文件添加到git管理git add .# 提交到本地git commit -m &quot;提交信息&quot;# 推送到远程仓库git push origin master","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://blog.smilexin.cn/tags/IDEA/"},{"name":"git","slug":"git","permalink":"https://blog.smilexin.cn/tags/git/"}]},{"title":"IDEA中使用Protobuf的正确姿势","slug":"IDEA使用protobuf的正确姿势","date":"2018-03-11T16:00:00.000Z","updated":"2021-04-30T02:44:33.309Z","comments":true,"path":"2018/03/12/IDEA使用protobuf的正确姿势.html","link":"","permalink":"https://blog.smilexin.cn/2018/03/12/IDEA使用protobuf的正确姿势.html","excerpt":"","text":"protobuf 简介protocolbuffer(以下简称PB)是google 的一种数据交换的格式，它独立于语言，独立于平台。google 提供了多种语言的实现：java、c#、c++、go 和 python，每一种实现都包含了相应语言的编译器以及库文件。由于它是一种二进制的格式，比使用 xml 进行数据交换快许多。可以把它用于分布式应用之间的数据通信或者异构环境下的数据交换。作为一种效率和兼容性都很优秀的二进制数据传输格式，可以用于诸如网络传输、配置文件、数据存储等诸多领域。 安装 Protobuf Support 插件依次点击IDEA中的“Preferences”–&gt;”Plugins”–&gt;”Browse repositories”，输入Protobuf 进行查找安装，也可以下载离线安装包，如图所示： IDEA plugins地址：IDEA plugins 搜索 Protobuf Support 插件，进行下载，下载完成后点击 Install plugin from disk 进行安装，如图所示： 安装完后，重启Intellij IDEA，查看.proto文件，会发现已经支持语法高亮显示。 将 .proto 文件转成 Java 类一般的做法是执行protoc命令,依次将.proto文件转成Java类 1protoc.exe -I=d:/tmp --java_out=d:/tmp d:/tmp/monitor_data.proto 也可以写个批处理文件进行处理，具体如下: 1234567891011121314151617181920212223@echo offset Path=Path;%cd%set PATH_DEST=H:\\server\\gamehall\\protocol\\src\\main\\javaset PATH_PO1=H:\\server\\Protocol\\ClientProtoset PATH_PO2=H:\\server\\Protocol\\ServerProtocd %PATH_PO1%pushd %PATH_PO1% for %%a in (*.proto) do ( echo %%a protoc --java_out=%PATH_DEST% -I=. %%a)cd %PATH_PO2%pushd %PATH_PO2% for %%a in (*.proto) do ( echo %%a protoc --java_out=%PATH_DEST% -I=. %%a)pause 不过gRPC官方推荐了一种更优雅的使用姿势，可以通过maven轻松搞定 pom.xml 增加依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;properties&gt; &lt;protobuf.version&gt;2.5.0&lt;/protobuf.version&gt; &lt;grpc.version&gt;1.6.1&lt;/grpc.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;$&#123;protobuf.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.0&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:$&#123;protobuf.version&#125;:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:$&#123;grpc.version&#125;:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 注意事项：.proto文件需要放置在src/main/proto包下 最后使用maven进行编译,如图所示: 现在我们就可以愉快的使用protobuf了。","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://blog.smilexin.cn/tags/IDEA/"},{"name":"protobuf","slug":"protobuf","permalink":"https://blog.smilexin.cn/tags/protobuf/"}]},{"title":"websocket 应用示例","slug":"websocket应用示例","date":"2018-03-11T16:00:00.000Z","updated":"2021-04-30T02:44:33.319Z","comments":true,"path":"2018/03/12/websocket应用示例.html","link":"","permalink":"https://blog.smilexin.cn/2018/03/12/websocket应用示例.html","excerpt":"","text":"websocket 应用这篇文章主要来介绍一下在java项目中，特别是java web项目中websocket的应用。 场景：我做了一个商城系统，跟大多数商城系统，分为客户端和后台，客户端供客户浏览，下单，购买，后台主要管理商品，处理订单，发货等。我现在要实现的功能是，当客户端有客户下单，并且支付完成以后，主动推送消息给后台，让后台的人知道，好去处理发货等事宜。 首先，我们要知道websocket是一个连接，这个连接是客户端（页面）与服务端之间的连接，所以我们要分两部分来完成这个连接，服务端代码和客户端代码。 引入依赖首先，在pom.xml引入如下jar包 123456&lt;!-- websocket --&gt;&lt;dependency&gt; &lt;groupId&gt;org.java-websocket&lt;/groupId&gt; &lt;artifactId&gt;Java-WebSocket&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt; 构建websocket连接池然后我们要知道的是，websocket是客户端和服务端之间建立了一个连接，建立完连接以后，会生成一个websocket对象，我们可以用这个对象来执行发送，接收等操作。但是这只是一个存在于客户端与服务器之间的链接，换句话说，系统只能识别到这个websocket连接是对应于哪个页面（浏览器），而这个页面在系统中是对应哪个用户（数据库中的用户，或者根本就没有对应任何用户，即未登录，只是一个游客），我们是无法从这个websocket对象中获取的。所以我们需要创建一个Map对象，用于将websocket对象和实际的user对象进行关联，这样为我们后续向特定的用户推送消息做铺垫。 为此，我们创建一个WsPool，即websocket连接池的类，该类用于管理现实中的用户和websocket对象之间的关联。代码如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.xdx.websocket;import java.util.ArrayList;import java.util.Collection;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Set;import org.java_websocket.WebSocket;public class WsPool &#123; private static final Map&lt;WebSocket, String&gt; wsUserMap = new HashMap&lt;WebSocket, String&gt;(); /** * 通过websocket连接获取其对应的用户 * * @param conn * @return */ public static String getUserByWs(WebSocket conn) &#123; return wsUserMap.get(conn); &#125; /** * 根据userName获取WebSocket,这是一个list,此处取第一个 * 因为有可能多个websocket对应一个userName（但一般是只有一个，因为在close方法中，我们将失效的websocket连接去除了） * * @param user */ public static WebSocket getWsByUser(String userName) &#123; Set&lt;WebSocket&gt; keySet = wsUserMap.keySet(); synchronized (keySet) &#123; for (WebSocket conn : keySet) &#123; String cuser = wsUserMap.get(conn); if (cuser.equals(userName)) &#123; return conn; &#125; &#125; &#125; return null; &#125; /** * 向连接池中添加连接 * * @param inbound */ public static void addUser(String userName, WebSocket conn) &#123; wsUserMap.put(conn, userName); // 添加连接 &#125; /** * 获取所有连接池中的用户，因为set是不允许重复的，所以可以得到无重复的user数组 * * @return */ public static Collection&lt;String&gt; getOnlineUser() &#123; List&lt;String&gt; setUsers = new ArrayList&lt;String&gt;(); Collection&lt;String&gt; setUser = wsUserMap.values(); for (String u : setUser) &#123; setUsers.add(u); &#125; return setUsers; &#125; /** * 移除连接池中的连接 * * @param inbound */ public static boolean removeUser(WebSocket conn) &#123; if (wsUserMap.containsKey(conn)) &#123; wsUserMap.remove(conn); // 移除连接 return true; &#125; else &#123; return false; &#125; &#125; /** * 向特定的用户发送数据 * * @param user * @param message */ public static void sendMessageToUser(WebSocket conn, String message) &#123; if (null != conn &amp;&amp; null != wsUserMap.get(conn)) &#123; conn.send(message); &#125; &#125; /** * 向所有的用户发送消息 * * @param message */ public static void sendMessageToAll(String message) &#123; Set&lt;WebSocket&gt; keySet = wsUserMap.keySet(); synchronized (keySet) &#123; for (WebSocket conn : keySet) &#123; String user = wsUserMap.get(conn); if (user != null) &#123; conn.send(message); &#125; &#125; &#125; &#125;&#125; websocket 主程序类接下来我们编写websocket的主程序类，该类用于管理websocket的生命周期。该类继承自WebSocketServer ，这是一个实现了runnable接口的类，他的构造函数需要传入一个端口，所以我们需要为websocket服务指定一个端口，该类有四个要重载的方法，onOpen()方法在连接创建成功以后调用，onClose在连接关闭以后调用，onError方法在连接发生错误的时候调用（一般连接出错以后触发了onError，也会紧接着触发onClose方法）。onMessage方法在收到客户端发来消息的时候触发。我们可以在这个方法中处理客户端所传递过来的消息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.xdx.websocket;import java.net.InetSocketAddress;import org.java_websocket.WebSocket;import org.java_websocket.handshake.ClientHandshake;import org.java_websocket.server.WebSocketServer;public class WsServer extends WebSocketServer &#123; public WsServer(int port) &#123; super(new InetSocketAddress(port)); &#125; public WsServer(InetSocketAddress address) &#123; super(address); &#125; @Override public void onOpen(WebSocket conn, ClientHandshake handshake) &#123; // ws连接的时候触发的代码，onOpen中我们不做任何操作 &#125; @Override public void onClose(WebSocket conn, int code, String reason, boolean remote) &#123; //断开连接时候触发代码 userLeave(conn); System.out.println(reason); &#125; @Override public void onMessage(WebSocket conn, String message) &#123; System.out.println(message); if(null != message &amp;&amp;message.startsWith(&quot;online&quot;))&#123; String userName=message.replaceFirst(&quot;online&quot;, message);//用户名 userJoin(conn,userName);//用户加入 &#125;else if(null != message &amp;&amp; message.startsWith(&quot;offline&quot;))&#123; userLeave(conn); &#125; &#125; @Override public void onError(WebSocket conn, Exception ex) &#123; //错误时候触发的代码 System.out.println(&quot;on error&quot;); ex.printStackTrace(); &#125; /** * 去除掉失效的websocket链接 * @param conn */ private void userLeave(WebSocket conn)&#123; WsPool.removeUser(conn); &#125; /** * 将websocket加入用户池 * @param conn * @param userName */ private void userJoin(WebSocket conn,String userName)&#123; WsPool.addUser(userName, conn); &#125;&#125; 上述onMessage()方法中，我们接收到客户端传过来的一个message（消息），而这个客户端对应的websocket连接也被当成一个参数一起传递过来，我们通过message中携带的信息来判定这条信息对应是什么操作，如果是以online开头，则说明它是一条上线的是信息，我们就把该websocket和其对应的userName存入ws连接池中，如果是以offline开头，则说明websocket断开了，我们也没有必要维护这个websocket对应的map键值对，把它去除掉就好了。 开启 websocket如何在服务端开启这个socket呢。我们上面有说到WsServer的父类WebSocketServer 实现了一个runnable方法，由此可见我们需要在一个线程中运行这个WsServer，事实上，WebSocketServer 有个start()方法，其源码如下。 12345public void start() &#123; if( selectorthread != null ) throw new IllegalStateException( getClass().getName() + &quot; can only be started once.&quot; ); new Thread( this ).start();;&#125; 很显然，它开了一个线程。所以我们可以用下面这样的方法来开启一个websocket线程。（该方法只是针对普通的java项目，如果是web项目需要在项目启动的时候运行websocket线程，后面第7点会讲） 123456public static void main(String args[])&#123; WebSocketImpl.DEBUG = false; int port = 8887; // 端口 WsServer s = new WsServer(port); s.start();&#125; 我们运行这个main方法，就开启了websocket的服务端。 到目前为止，我们还没有编写任何客户端的代码。我们如何测试已经开启了websocket服务端呢？网上有一个免费的测试工具。 测试地址如下：测试websocket 点击进去，写上我们的websocket服务地址。点击连接。如图所示。 如果连接成功，他就会显示“连接已建立，正在等待数据……” 我们再文本框中输入onlinexdx，然后点回车试试。 这就是模拟客户端向服务端发送onlinexdx请求，按前面的介绍，它会触发服务端的onMessage方法，我们看一下服务端控制台。除了我们希望看到的onlinexdx这个message,还有一些@heart,果然触发了这个方法。 @heart是这个免费页面发送过来的心跳检测包，目的是让websocket一直处于连接状态。 客户端好了，接下来我们要来完成客户端部分的功能。我想要实现的是后台用户登录以后，进入到后台主页的时候，执行websocket连接工作（就类似于上一步在免费页面点击连接按钮），然后向服务端发送“online+userName”这条消息，用以触发服务端的onMessage方法，就可以将该userName加入到连接池了。我们将这些代码封装到js中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104var websocket = &apos;&apos;;var ajaxPageNum = 1;var last_health;var health_timeout = 10;var tDates = [], tData = [];var rightIndex;if ($(&apos;body&apos;).attr(&apos;userName&apos;) != &apos;&apos; &amp;&amp; $(&apos;body&apos;).attr(&apos;ws&apos;) == &apos;yes&apos;) &#123; var userName = $(&apos;body&apos;).attr(&apos;userName&apos;); if (window.WebSocket) &#123; websocket = new WebSocket( encodeURI(&apos;ws://&apos; + document.domain + &apos;:8887&apos;)); websocket.onopen = function() &#123; console.log(&apos;已连接&apos;); websocket.send(&quot;online&quot;+userName); heartbeat_timer = setInterval(function() &#123; keepalive(websocket) &#125;, 60000); &#125;; websocket.onerror = function() &#123; console.log(&apos;连接发生错误&apos;); &#125;; websocket.onclose = function() &#123; console.log(&apos;已经断开连接&apos;); initWs(); &#125;; // 消息接收 websocket.onmessage = function(message) &#123; console.log(message) showNotice(&quot;新订单&quot;, &quot;您有新的逸品订单，请及时处理！&quot;) &#125;; &#125; else &#123; alert(&quot;该浏览器不支持下单提醒。&lt;br/&gt;建议使用高版本的浏览器，&lt;br/&gt;如 IE10、火狐 、谷歌 、搜狗等&quot;); &#125;&#125;var initWs = function() &#123; if (window.WebSocket) &#123; websocket = new WebSocket( encodeURI(&apos;ws://&apos; + document.domain + &apos;:8887&apos;)); websocket.onopen = function() &#123; console.log(&apos;已连接&apos;); websocket.send(&quot;online&quot;+userName); heartbeat_timer = setInterval(function() &#123; keepalive(websocket) &#125;, 60000); &#125;; websocket.onerror = function() &#123; console.log(&apos;连接发生错误&apos;); &#125;; websocket.onclose = function() &#123; console.log(&apos;已经断开连接&apos;); initWs(); &#125;; // 消息接收 websocket.onmessage = function(message) &#123; console.log(message) showNotice(&quot;新订单&quot;, &quot;您有新的逸品订单，请及时处理！&quot;) &#125;; &#125; else &#123; alert(&quot;该浏览器不支持下单提醒。&lt;br/&gt;建议使用高版本的浏览器，&lt;br/&gt;如 IE10、火狐 、谷歌 、搜狗等&quot;); &#125;&#125;var vadioTimeOut;function showNotice(title, content) &#123; if (!title &amp;&amp; !content) &#123; title = &quot;新订单&quot;; content = &quot;您有新的订单,请及时处理！&quot;; &#125; var iconUrl = &quot;http://www.wonyen.com/favicon.ico&quot;; $(&quot;#myaudio&quot;)[0].play();// 消息播放语音 var playTime = 1; var audio = document.createElement(&quot;myaudio&quot;); clearTimeout(vadioTimeOut); audio.addEventListener(&apos;ended&apos;, function() &#123; vadioTimeOut = setTimeout(function() &#123; playTime = playTime + 1; playTime &lt; 3 ? audio.play() : clearTimeout(vadioTimeOut); &#125;, 500); &#125;) if (Notification.permission == &quot;granted&quot;) &#123; var notification = new Notification(title, &#123; body : content, icon : iconUrl &#125;); notification.onclick = function() &#123; notification.close(); &#125;; &#125;&#125;// 心跳包function keepalive(ws) &#123; var time = new Date(); if (last_health != -1 &amp;&amp; (time.getTime() - last_health &gt; health_timeout)) &#123; // ws.close(); &#125; else &#123; if (ws.bufferedAmount == 0) &#123; ws.send(&apos;~HC~&apos;); &#125; &#125;&#125; 页面的主要代码如下。首先是引入上述js.这个js必须放在页面最后，因为它需要加载完页面以获取body的attr。 12&lt;!-- websocket --&gt;&lt;script src=&quot;./static/js/OtherJs/ws.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; 其次是在页面的body处加入userName和ws属性。作为参数传递到js里面。还需要加入语音附件。 123&lt;body userName=$&#123;adminName&#125; ws=&quot;yes&quot;&gt;&lt;!-- 消息提示音 --&gt;&lt;audio id=&quot;myaudio&quot; src=&quot;./static/new_order.wav&quot;&gt;&lt;/audio&gt; 上述js代码清楚地展示了websocket在页面端的生命周期，需要注意的是，我们在onopen()方法中，先是向服务端发送online+userName进行上线处理，紧接着开始调用心跳包，避免websocket长时间闲置而失效。 onmessage方法中，我们处理收到服务端推送过来的消息，然后以语音和弹出窗的形式提醒客户端。当然，我们在服务端可以通过封装message这个参数，把它变成一个json对象，给这个json对象一个msgType属性，这样就可以根据msgType的不同来执行不同的前端代码，比如msgType=newOrder表示有新的订单，就执行新订单到来的代码，msgType=newUser表示有新的用户注册，就执行新用户注册的代码。这边我没做区分，因为我在服务端只发送用户购买订单的消息，所以所有的消息，我都执行showNotice(“新订单”, “您有新的逸品订单，请及时处理！”)这个方法。 广播消息最后一步，我们来编写从服务端向客户端发送消息的方法。一旦有订单到来，我们就向所有的后台用户发送消息。我们可以模拟一下这个动作，写一个controller方法，调用WsPool的sendMessageToAll方法。 123456@ResponseBody@RequestMapping(&quot;sendWs&quot;)public String sendWs(String message) &#123; WsPool.sendMessageToAll(message); return message;&#125; web项目自动启动websocket对了，如果是web项目，我们还需要在项目启动的时候开启websocket服务端线程，可以把启动的动作放在一个filter中，然后在web.xml里面配置这个filter，使它在项目启动时候运行。 1234567891011121314151617181920212223242526272829303132333435363738394041package com.xdx.filter;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import org.java_websocket.WebSocketImpl;import com.xdx.websocket.WsServer;public class StartFilter implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain arg2) throws IOException, ServletException &#123; &#125; public void init(FilterConfig arg0) throws ServletException &#123; this.startWebsocketInstantMsg(); &#125; /** * 启动即时聊天服务 */ public void startWebsocketInstantMsg() &#123; WebSocketImpl.DEBUG = false; WsServer s; s = new WsServer(8887); s.start(); &#125;&#125; 在web.xml配置。 12345&lt;!-- filter --&gt;&lt;filter&gt; &lt;filter-name&gt;startFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.xdx.filter.StartFilter&lt;/filter-class&gt;&lt;/filter&gt; 至此，我们完成了所有的代码。 测试代码测试，先运行起项目。然后登陆以后，进入后台主页，可以看到，已经连接成功了。 然后我们从服务端向后台发送一条消息，执行sendWs这个方法。在浏览器输入http://192.168.1.185:8080/warrior/sendWs?message=xxx 会播放语音，并且弹出提示。证明成功了。 上述只是websocket的一个简单的应用，在此基础上，我们还可以做很多扩展的工作，比如做聊天室，股票实时价格显示等，只要掌握了原理就好做了。 参考链接：https://www.cnblogs.com/roy-blog/p/7211761.html","categories":[],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://blog.smilexin.cn/tags/websocket/"}]},{"title":"websocket 简介","slug":"websocket简介","date":"2018-03-11T16:00:00.000Z","updated":"2021-04-30T02:44:33.319Z","comments":true,"path":"2018/03/12/websocket简介.html","link":"","permalink":"https://blog.smilexin.cn/2018/03/12/websocket简介.html","excerpt":"","text":"websocket 简介在我们做web项目的过程中，经常需要做的一个模块是消息模块。典型的场景：一个商城系统的后台管理，我想实现如果前台有客户下单，后台就会接到消息，以便尽快发货处理。 要实现上述的功能，我们有几种备选的方案。 方案1.使用ajax短轮询，比如每隔1分钟去请求一次服务器，让服务器去数据库去查询，看看有无新的未处理的订单，然后返回给客户端。 方案2.长轮询，长轮询的原理与上述类似，只不过采取了阻塞响应（response）的方法，也就是说只要服务器没有响应，这个请求就不断开，一直等到服务器有响应为止。 ajax短轮询好比客户端每隔一段时间打一个电话给服务器，服务器不管有没有数据都要响应给客户端，响应完以后就挂掉电话，然后周而复始； 长轮询则是客户端打一个电话，开始一直等，直到服务器有响应，如果服务器一直不响应，这个请求就一直挂在那边。 很显然，这两种方案都有各自弊端。 方案1：每隔一定时间去轮询服务器，这个时间的设置很关键，太长了，即时性得不到保证，太短了，有可能会造成服务器性能的浪费（主要是cpu）,假设在一个小时之内都没有一个订单，但是客户端还是不间断的每分钟发一次请求，这些请求就是浪费。 方案2：方案2的出现本来是为了解决方案1这种盲目不确定地发送请求造成浪费的弊端，但是它自己同样也有弊端，首先，它采取阻塞的方式来强迫连接长时间保持，而对于服务器而言，在同一个时间里面能处理的连接数（我们称之为程序的并发数）是有限的，而长轮询方式很容易造成服务端达到并发的限制，因为它不像短轮询一样会很快释放掉连接。 它们的共同的缺点是，每一次请求和响应，处理处理真正有用的数据，服务器和客户端还要交换一堆请求头，响应头等东西，信息交换的效率不高。事实上可以说，长轮询是一种伪长连接，它还是需要遵循http连接的规则：客户端请求–服务器响应–释放连接，顺便交换了一些相同的无用的信息。（造成带宽浪费） websocket的原理网上有很多人也介绍了，简单来说，它就是html5中的一种协议，我的理解是，他是对html的长连接的一种升级。你也可以将它理解成一种长连接。只不过这种长连接相对于方案2的长轮询有以下优越之处。 1.首先，websocket连接只需要建立一次，在第一次连接的时候，客户端和服务器会交换必要的信息，如下所示： 可以看到，websocket连接成功后返回的状态码是101.在请求头处，传递过来的connection类型是keep_alive，upgrade。也就是说是keep_alive的升级版。首先keep_alive是属于http1.1协议的范畴。大概的意思就是，在http1.0时代，我建立一个连接就是对应一次request–response的过程。而在1.1时代，新增加了keep-alive，我们可以保持这个连接的生命周期（可以通过nginx等服务器设置keepalive-timeout这个参数来实现），这样做的好处是可以自定义一个连接的存活时间，使得一个连接可以处理多个请求，而不是单单一次请求。设置了keepalive-timeout以后，当一个请求结束以后，我们在等keepalive-timeout这么长的时间，如果没有新的请求，就关闭这个连接。 说到http1.1，我们来看一个http的连接的请求头和响应头。 看到了吧，不一样的地方就在于那个upgrade。所以我们可以这么说，websocket也是一个长连接。但是因为它是升级版，所以它有个好处，就是它只需要建立一次连接，传递一次必要的请求头和响应头信息，之后再传递数据的时候就不需要在交换这些信息了。节省了带宽。 2.websocket是双向的，这也是他跟另外两种方法最大的不同，不管是ajax还是长轮询，他们都是通过客户端发送请求，服务器响应的形式完成信息的交换，这种模式下服务器处于一种被动的角色。而websocket不存在这个问题，websocket的链接一旦建立，服务器和客户端都可以互推信息。 有了这两个优点，在做一些需要即时通信的功能时候，我们首选就是用websocket。 参考链接：http://www.cnblogs.com/roy-blog/p/7210484.html","categories":[],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://blog.smilexin.cn/tags/websocket/"}]},{"title":"Mysql 数据库死锁问题处理方案","slug":"Mysql_数据库死锁问题处理","date":"2017-12-22T16:00:00.000Z","updated":"2021-04-30T02:44:33.312Z","comments":true,"path":"2017/12/23/Mysql_数据库死锁问题处理.html","link":"","permalink":"https://blog.smilexin.cn/2017/12/23/Mysql_数据库死锁问题处理.html","excerpt":"","text":"先查找死锁病因1show engine innodb status; 把内容复制出来,里面有查询id 拿着query id,去查相应的sql语句 Info里就是sql 红线框选的就是造成死锁的sql语句 总结根据此sql可以查出死锁的表，如果死锁在这个表，那么就需要去审查这张表相关的业务逻辑的代码。查明死锁的原因！","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"}]},{"title":"Mysql 使用自增id和uuid作为主键的优劣比较","slug":"Mysql_使用自增id和uuid的优劣比较","date":"2017-12-18T16:00:00.000Z","updated":"2021-04-30T02:44:33.312Z","comments":true,"path":"2017/12/19/Mysql_使用自增id和uuid的优劣比较.html","link":"","permalink":"https://blog.smilexin.cn/2017/12/19/Mysql_使用自增id和uuid的优劣比较.html","excerpt":"","text":"测试缘由一个开发同事做了一个框架，里面主键是uuid，我跟他建议说mysql不要用uuid用自增主键，自增主键效率高，他说不一定高，我说innodb的索引特性导致了自增id做主键是效率最好的，为了拿实际的案例来说服他，所以准备做一个详细的测试。 作为互联网公司，一定有用户表，而且用户表UC_USER基本会有百万记录，所以在这个表基础上准测试数据来进行测试 ​ 测试过程是目前我想到的多方位的常用的几种类型的sql进行测试，当然可能不太完善，欢迎大家留言提出更加完善的测试方案或者测试sql语句。 准备表以及数据创建自增id数据表UC_USER，自增ID为主键，表结构类似如下： 123456789101112131415161718192021222324252627282930313233343536CREATE TABLE `UC_USER` ( `ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `USER_NAME` varchar(100) DEFAULT NULL COMMENT &apos;用户名&apos;, `USER_PWD` varchar(200) DEFAULT NULL COMMENT &apos;密码&apos;, `BIRTHDAY` datetime DEFAULT NULL COMMENT &apos;生日&apos;, `NAME` varchar(200) DEFAULT NULL COMMENT &apos;姓名&apos;, `USER_ICON` varchar(500) DEFAULT NULL COMMENT &apos;头像图片&apos;, `SEX` char(1) DEFAULT NULL COMMENT &apos;性别, 1:男，2:女，3：保密&apos;, `NICKNAME` varchar(200) DEFAULT NULL COMMENT &apos;昵称&apos;, `STAT` varchar(10) DEFAULT NULL COMMENT &apos;用户状态，01:正常，02:冻结&apos;, `USER_MALL` bigint(20) DEFAULT NULL COMMENT &apos;当前所属MALL&apos;, `LAST_LOGIN_DATE` datetime DEFAULT NULL COMMENT &apos;最后登录时间&apos;, `LAST_LOGIN_IP` varchar(100) DEFAULT NULL COMMENT &apos;最后登录IP&apos;, `SRC_OPEN_USER_ID` bigint(20) DEFAULT NULL COMMENT &apos;来源的联合登录&apos;, `EMAIL` varchar(200) DEFAULT NULL COMMENT &apos;邮箱&apos;, `MOBILE` varchar(50) DEFAULT NULL COMMENT &apos;手机&apos;, `IS_DEL` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否删除&apos;, `IS_EMAIL_CONFIRMED` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否绑定邮箱&apos;, `IS_PHONE_CONFIRMED` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否绑定手机&apos;, `CREATER` bigint(20) DEFAULT NULL COMMENT &apos;创建人&apos;, `CREATE_DATE` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;注册时间&apos;, `UPDATE_DATE` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;修改日期&apos;, `PWD_INTENSITY` char(1) DEFAULT NULL COMMENT &apos;密码强度&apos;, `MOBILE_TGC` char(64) DEFAULT NULL COMMENT &apos;手机登录标识&apos;, `MAC` char(64) DEFAULT NULL COMMENT &apos;mac地址&apos;, `SOURCE` char(1) DEFAULT &apos;0&apos; COMMENT &apos;1:WEB,2:IOS,3:ANDROID,4:WIFI,5:管理系统, 0:未知&apos;, `ACTIVATE` char(1) DEFAULT &apos;1&apos; COMMENT &apos;激活，1：激活，0：未激活&apos;, `ACTIVATE_TYPE` char(1) DEFAULT &apos;0&apos; COMMENT &apos;激活类型，0：自动，1：手动&apos;, PRIMARY KEY (`ID`), UNIQUE KEY `USER_NAME` (`USER_NAME`), KEY `MOBILE` (`MOBILE`), KEY `IDX_MOBILE_TGC` (`MOBILE_TGC`,`ID`), KEY `IDX_EMAIL` (`EMAIL`,`ID`), KEY `IDX_CREATE_DATE` (`CREATE_DATE`,`ID`), KEY `IDX_UPDATE_DATE` (`UPDATE_DATE`)) ENGINE=InnoDB AUTO_INCREMENT=7122681 DEFAULT CHARSET=utf8 COMMENT=&apos;用户表&apos; 创建uuid数据表UC_USER_PK_VARCHAR表，字符串ID为主键，采用uuid 123456789101112131415161718192021222324252627282930313233343536CREATE TABLE `UC_USER_PK_VARCHAR_1` ( `ID` varchar(36) CHARACTER SET utf8mb4 NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;主键&apos;, `USER_NAME` varchar(100) DEFAULT NULL COMMENT &apos;用户名&apos;, `USER_PWD` varchar(200) DEFAULT NULL COMMENT &apos;密码&apos;, `BIRTHDAY` datetime DEFAULT NULL COMMENT &apos;生日&apos;, `NAME` varchar(200) DEFAULT NULL COMMENT &apos;姓名&apos;, `USER_ICON` varchar(500) DEFAULT NULL COMMENT &apos;头像图片&apos;, `SEX` char(1) DEFAULT NULL COMMENT &apos;性别, 1:男，2:女，3：保密&apos;, `NICKNAME` varchar(200) DEFAULT NULL COMMENT &apos;昵称&apos;, `STAT` varchar(10) DEFAULT NULL COMMENT &apos;用户状态，01:正常，02:冻结&apos;, `USER_MALL` bigint(20) DEFAULT NULL COMMENT &apos;当前所属MALL&apos;, `LAST_LOGIN_DATE` datetime DEFAULT NULL COMMENT &apos;最后登录时间&apos;, `LAST_LOGIN_IP` varchar(100) DEFAULT NULL COMMENT &apos;最后登录IP&apos;, `SRC_OPEN_USER_ID` bigint(20) DEFAULT NULL COMMENT &apos;来源的联合登录&apos;, `EMAIL` varchar(200) DEFAULT NULL COMMENT &apos;邮箱&apos;, `MOBILE` varchar(50) DEFAULT NULL COMMENT &apos;手机&apos;, `IS_DEL` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否删除&apos;, `IS_EMAIL_CONFIRMED` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否绑定邮箱&apos;, `IS_PHONE_CONFIRMED` char(1) DEFAULT &apos;0&apos; COMMENT &apos;是否绑定手机&apos;, `CREATER` bigint(20) DEFAULT NULL COMMENT &apos;创建人&apos;, `CREATE_DATE` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;注册时间&apos;, `UPDATE_DATE` datetime DEFAULT CURRENT_TIMESTAMP COMMENT &apos;修改日期&apos;, `PWD_INTENSITY` char(1) DEFAULT NULL COMMENT &apos;密码强度&apos;, `MOBILE_TGC` char(64) DEFAULT NULL COMMENT &apos;手机登录标识&apos;, `MAC` char(64) DEFAULT NULL COMMENT &apos;mac地址&apos;, `SOURCE` char(1) DEFAULT &apos;0&apos; COMMENT &apos;1:WEB,2:IOS,3:ANDROID,4:WIFI,5:管理系统, 0:未知&apos;, `ACTIVATE` char(1) DEFAULT &apos;1&apos; COMMENT &apos;激活，1：激活，0：未激活&apos;, `ACTIVATE_TYPE` char(1) DEFAULT &apos;0&apos; COMMENT &apos;激活类型，0：自动，1：手动&apos;, PRIMARY KEY (`ID`), UNIQUE KEY `USER_NAME` (`USER_NAME`), KEY `MOBILE` (`MOBILE`), KEY `IDX_MOBILE_TGC` (`MOBILE_TGC`,`ID`), KEY `IDX_EMAIL` (`EMAIL`,`ID`), KEY `IDX_CREATE_DATE` (`CREATE_DATE`,`ID`), KEY `IDX_UPDATE_DATE` (`UPDATE_DATE`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;用户表&apos;; 500w数据测试 录入500w数据,自增id节省一半磁盘空间 确定两个表数据量 123456789101112131415161718192021## 自增id为主键的表mysql&gt; select count(1) from UC_USER;+----------+| count(1) |+----------+| 5720112 |+----------+1 row in set (0.00 sec) mysql&gt; ## uuid为主键的表mysql&gt; select count(1) from UC_USER_PK_VARCHAR_1;+----------+| count(1) |+----------+| 5720112 |+----------+1 row in set (1.91 sec) 空间容量从占据的空间容量来看，自增ID比UUID小一半左右。 主键类型 数据文件大小 占据容量 自增ID -rw-rw—- 1 mysql mysql 2.5G Aug 11 18:29 UC_USER.ibd 2.5 G UUID -rw-rw—- 1 mysql mysql 5.4G Aug 15 15:11 UC_USER_PK_VARCHAR_1.ibd 5.4 G 单个数据走索引查询单个数据走索引查询，自增id和uuid相差不大 主键类型 SQL语句 执行时间 (秒) 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.MOBILE =’14782121512’; 0.118 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE =’14782121512’; 0.117 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.MOBILE IN( ‘14782121512’,’13761460105’); 0.049 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE IN(‘14782121512’,’13761460105’); 0.040 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.CREATE_DATE=’2013-11-24 10:26:36’ ; 0.139 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE=’2013-11-24 10:26:43’ ; 0.126 范围like查询范围like查询，自增ID性能优于UUID 主键类型 SQL语句 执行时间 (秒) （1）模糊范围查询1000条数据，自增ID性能要好于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.MOBILE LIKE ‘147%’ LIMIT 1000; 1.784 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE LIKE ‘147%’ LIMIT 1000; 3.196 （2）日期范围查询20条数据，自增ID稍微弱于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.CREATE_DATE &gt; ‘2016-08-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 20; 0.601 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-08-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 20; 0.543 （3）范围查询200条数据，自增ID性能要好于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 200; 2.314 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 200; 3.229 范围查询总数量，自增ID要好于UUID 自增ID SELECT SQL_NO_CACHE COUNT(1) FROM test.UC_USER t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ; 0.514 UUID SELECT SQL_NO_CACHE COUNT(1) FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ; 1.092 PS：在有缓存的情况下，两者执行效率相差很小。 写入测试写入测试，自增ID是UUID的4倍 主键类型 SQL语句 执行时间 (秒) 自增ID UPDATE test.UC_USER t SET t.MOBILE_TGC=’T2’ WHERE t.CREATE_DATE &gt; ‘2016-05-03 10:26:36’ AND t.CREATE_DATE &lt;’2016-05-04 00:00:00’ ; 1.419 UUID UPDATE test.UC_USER_PK_VARCHAR_1 t SET t.MOBILE_TGC=’T2’ WHERE t.CREATE_DATE &gt; ‘2016-05-03 10:26:36’ AND t.CREATE_DATE &lt;’2016-05-04 00:00:00’ ; 5.639 自增ID INSERT INTO test.UC_USER( ID, USER_NAME, USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, MOBILE, IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE ) SELECT NULL, CONCAT(‘110’,USER_NAME,8), USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, CONCAT(‘110’,TRIM(MOBILE)), IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE FROM test.UC_USER_1 LIMIT 100; 0.105 UUID INSERT INTO test.UC_USER_PK_VARCHAR_1( ID, USER_NAME, USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, MOBILE, IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE ) SELECT UUID(), CONCAT(‘110’,USER_NAME,8), USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, CONCAT(‘110’,TRIM(MOBILE)), IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE FROM test.UC_USER_1 LIMIT 100; 0.424 备份和恢复备份和恢复，自增ID性能优于UUID 主键类型 SQL语句 执行时间 (秒) Mysql dump备份 自增ID time mysqldump -utim -ptimgood -h192.168.121.63 test UC_USER_500&gt; UC_USER_500.sql 28.59秒 UUID time mysqldump -utim -ptimgood -h192.168.121.63 test UC_USER_PK_VARCHAR_500&gt; UC_USER_PK_VARCHAR_500.sql 31.08秒 MySQL恢复 自增ID time mysql -utim -ptimgood -h192.168.121.63 test &lt; UC_USER_500.sql 7m36.601s UUID time mysql -utim -ptimgood -h192.168.121.63 test &lt; UC_USER_PK_VARCHAR_500.sql 9m42.472s 500W总结在500W记录表的测试下： 普通单条或者20条左右的记录检索，uuid为主键的相差不大几乎效率相同； 但是范围查询特别是上百成千条的记录查询，自增id的效率要大于uuid； 在范围查询做统计汇总的时候，自增id的效率要大于uuid； 在存储上面，自增id所占的存储空间是uuid的1/2； 在备份恢复上，自增ID主键稍微优于UUID。 1000W数据测试空间容量录入1000W条数据记录，查看存储空间 123456789101112131415161718192021## 自增id为主键的表mysql&gt; use test;Database changedmysql&gt; select count(1) from UC_USER_1;+----------+| count(1) |+----------+| 10698102 |+----------+1 row in set (27.42 sec) ## uuid为主键的表mysql&gt; select count(1) from UC_USER_PK_VARCHAR_1;+----------+| count(1) |+----------+| 10698102 |+----------+1 row in set (0.00 sec) mysql&gt; 占据的空间容量来看，自增ID比UUID小一半左右： 主键类型 数据文件大小 占据容量 自增ID -rw-rw—- 1 mysql mysql 4.2G Aug 20 23:08 UC_USER_1.ibd 4.2 G UUID -rw-rw—- 1 mysql mysql 8.8G Aug 20 18:20 UC_USER_PK_VARCHAR_1.ibd 8.8 G 单个数据走索引查询单个数据走索引查询，自增id和 uuid效率比是：(2~3):1 主键类型 SQL语句 执行时间 (秒) 单条记录查询 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_1 t WHERE t.MOBILE =’14782121512’; 0.069 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE =’14782121512’; 0.274 小范围查询 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_1 t WHERE t.MOBILE IN( ‘14782121512’,’13761460105’); 0.050 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE IN(‘14782121512’,’13761460105’); 0.151 根据日期查询 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_1 t WHERE t.CREATE_DATE=’2013-11-24 10:26:36’ ; 0.269 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE=’2013-11-24 10:26:43’ ; 0.810 范围like查询范围like查询，自增ID性能优于UUID，比值(1.5~2)：1 主键类型 SQL语句 执行时间 (秒) （1）模糊范围查询1000条数据，自增ID性能要好于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER t WHERE t.MOBILE LIKE ‘147%’ LIMIT 1000; 2.398 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.MOBILE LIKE ‘147%’ LIMIT 1000; 5.872 （2）日期范围查询20条数据，自增ID稍微弱于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_1 t WHERE t.CREATE_DATE &gt; ‘2016-08-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 20; 0.765 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-08-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 20; 1.090 （3）范围查询200条数据，自增ID性能要好于UUID 自增ID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 200; 1.569 UUID SELECT SQL_NO_CACHE t.* FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ORDER BY t.UPDATE_DATE DESC LIMIT 200; 2.597 范围查询总数量，自增ID要好于UUID 自增ID SELECT SQL_NO_CACHE COUNT(1) FROM test.UC_USER_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ; 1.129 UUID SELECT SQL_NO_CACHE COUNT(1) FROM test.UC_USER_PK_VARCHAR_1 t WHERE t.CREATE_DATE &gt; ‘2016-07-01 10:26:36’ ; 2.302 写入测试写入测试，自增ID比UUID效率高，比值(3~10)：1 主键类型 SQL语句 执行时间 (秒) 修改一天的记录 自增ID UPDATE test.UC_USER_1 t SET t.MOBILE_TGC=’T2’ WHERE t.CREATE_DATE &gt; ‘2016-05-03 10:26:36’ AND t.CREATE_DATE &lt;’2016-05-04 00:00:00’ ; 2.685 UUID UPDATE test.UC_USER_PK_VARCHAR_1 t SET t.MOBILE_TGC=’T2’ WHERE t.CREATE_DATE &gt; ‘2016-05-03 10:26:36’ AND t.CREATE_DATE &lt;’2016-05-04 00:00:00’ ; 26.521 录入数据 自增ID INSERT INTO test.UC_USER_1( ID, USER_NAME, USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, MOBILE, IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE ) SELECT NULL, CONCAT(‘110’,USER_NAME,8), USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, CONCAT(‘110’,TRIM(MOBILE)), IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE FROM test.UC_USER_1 LIMIT 100; 0.534 UUID INSERT INTO test.UC_USER_PK_VARCHAR_1( ID, USER_NAME, USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, MOBILE, IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE ) SELECT UUID(), CONCAT(‘110’,USER_NAME,8), USER_PWD, BIRTHDAY, NAME, USER_ICON, SEX, NICKNAME, STAT, USER_MALL, LAST_LOGIN_DATE, LAST_LOGIN_IP, SRC_OPEN_USER_ID, EMAIL, CONCAT(‘110’,TRIM(MOBILE)), IS_DEL, IS_EMAIL_CONFIRMED, IS_PHONE_CONFIRMED, CREATER, CREATE_DATE, UPDATE_DATE, PWD_INTENSITY, MOBILE_TGC, MAC, SOURCE, ACTIVATE, ACTIVATE_TYPE FROM test.UC_USER_1 LIMIT 100; 1.716 备份和恢复备份和恢复，自增ID性能优于UUID 主键类型 SQL语句 执行时间 (秒) Mysql dump备份 自增ID time mysqldump -utim -ptimgood -h192.168.121.63 test UC_USER_1&gt; UC_USER_1.sql 0m50.548s UUID time mysqldump -utim -ptimgood -h192.168.121.63 test UC_USER_PK_VARCHAR_1&gt; UC_USER_PK_VARCHAR_1.sql 0m58.590s MySQL恢复 自增ID time mysql -utim -ptimgood -h192.168.121.63 test &lt; UC_USER_1.sql 17m30.822s UUID time mysql -utim -ptimgood -h192.168.121.63 test &lt; UC_USER_PK_VARCHAR_1.sql 23m6.360s 1000W总结在1000W记录表的测试下： 普通单条或者20条左右的记录检索，自增主键效率是uuid主键的2到3倍； 但是范围查询特别是上百成千条的记录查询，自增id的效率要大于uuid； 在范围查询做统计汇总的时候，自增id主键的效率是uuid主键1.5到2倍； 在存储上面，自增id所占的存储空间是uuid的1/2； 在写入上面，自增ID主键的效率是UUID主键的3到10倍，相差比较明显，特别是update小范围之内的数据上面。 在备份恢复上，自增ID主键稍微优于UUID。 MySQL分布式架构的取舍分布式架构，意味着需要多个实例中保持一个表的主键的唯一性。这个时候普通的单表自增ID主键就不太合适，因为多个mysql实例上会遇到主键全局唯一性问题。 自增ID主键+步长，适合中等规模的分布式场景在每个集群节点组的master上面，设置（auto_increment_increment），让目前每个集群的起始点错开 1，步长选择大于将来基本不可能达到的切分集群数，达到将 ID 相对分段的效果来满足全局唯一的效果。 优点是：实现简单，后期维护简单，对应用透明。 缺点是：第一次设置相对较为复杂，因为要针对未来业务的发展而计算好足够的步长; 规划： 比如计划总共N个节点组，那么第i个节点组的my.cnf的配置为： auto_increment_offset i auto_increment_increment N 假如规划48个节点组，N为48，现在配置第8个节点组，这个i为8，第8个节点组的my.cnf里面的配置为： auto_increment_offset 8 auto_increment_increment 48 UUID，适合小规模的分布式环境对于InnoDB这种聚集主键类型的引擎来说，数据会按照主键进行排序，由于UUID的无序性，InnoDB会产生巨大的IO压力，而且由于索引和数据存储在一起，字符串做主键会造成存储空间增大一倍。 在存储和检索的时候，innodb会对主键进行物理排序，这对auto_increment_int是个好消息，因为后一次插入的主键位置总是在最后。但是对uuid来说，这却是个坏消息，因为uuid是杂乱无章的，每次插入的主键位置是不确定的，可能在开头，也可能在中间，在进行主键物理排序的时候，势必会造成大量的 IO操作影响效率，在数据量不停增长的时候，特别是数据量上了千万记录的时候，读写性能下降的非常厉害。 优点：搭建比较简单，不需要为主键唯一性的处理。 缺点：占用两倍的存储空间（在云上光存储一块就要多花2倍的钱），后期读写性能下降厉害。 雪花算法自造全局自增ID，适合大数据环境的分布式场景由twitter公布的开源的分布式id算法snowflake（Java版本） IdWorker.java: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.demo.elk;import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class IdWorker &#123; protected static final Logger LOG = LoggerFactory.getLogger(IdWorker.class); private long workerId; private long datacenterId; private long sequence = 0L; private long twepoch = 1288834974657L; private long workerIdBits = 5L; private long datacenterIdBits = 5L; private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long lastTimestamp = -1L; public IdWorker(long workerId, long datacenterId) &#123; // sanity check for workerId if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; LOG.info(String.format(&quot;worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d&quot;, timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId)); &#125; public synchronized long nextId() &#123; long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; LOG.error(String.format(&quot;clock is moving backwards. Rejecting requests until %d.&quot;, lastTimestamp)); throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0L; &#125; lastTimestamp = timestamp; return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; protected long timeGen() &#123; return System.currentTimeMillis(); &#125;&#125; 测试生成ID的测试类，IdWorkerTest.java： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.demo.elk; import java.util.HashSet;import java.util.Set; public class IdWorkerTest &#123; static class IdWorkThread implements Runnable &#123; private Set&lt;Long&gt; set; private IdWorker idWorker; public IdWorkThread(Set&lt;Long&gt; set, IdWorker idWorker) &#123; this.set = set; this.idWorker = idWorker; &#125; public void run() &#123; while (true) &#123; long id = idWorker.nextId(); System.out.println(&quot; real id:&quot; + id); if (!set.add(id)) &#123; System.out.println(&quot;duplicate:&quot; + id); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Set&lt;Long&gt; set = new HashSet&lt;Long&gt;(); final IdWorker idWorker1 = new IdWorker(0, 0); final IdWorker idWorker2 = new IdWorker(1, 0); Thread t1 = new Thread(new IdWorkThread(set, idWorker1)); Thread t2 = new Thread(new IdWorkThread(set, idWorker2)); t1.setDaemon(true); t2.setDaemon(true); t1.start(); t2.start(); try &#123; Thread.sleep(30000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 总结（1）单实例或者单节点组： 经过500W、1000W的单机表测试，自增ID相对UUID来说，自增ID主键性能高于UUID，磁盘存储费用比UUID节省一半的钱。所以在单实例上或者单节点组上，使用自增ID作为首选主键。 （2）分布式架构场景： 20个节点组下的小型规模的分布式场景，为了快速实现部署，可以采用多花存储费用、牺牲部分性能而使用UUID主键快速部署； 20到200个节点组的中等规模的分布式场景，可以采用自增ID+步长的较快速方案。 200以上节点组的大数据下的分布式场景，可以借鉴类似twitter雪花算法构造的全局自增ID作为主键。 参考链接：http://blog.csdn.net/mchdba/article/details/52336203","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"},{"name":"uuid","slug":"uuid","permalink":"https://blog.smilexin.cn/tags/uuid/"},{"name":"自增id","slug":"自增id","permalink":"https://blog.smilexin.cn/tags/自增id/"}]},{"title":"Mysql 留存用户统计","slug":"留存用户统计","date":"2017-12-04T16:00:00.000Z","updated":"2021-04-30T02:44:33.321Z","comments":true,"path":"2017/12/05/留存用户统计.html","link":"","permalink":"https://blog.smilexin.cn/2017/12/05/留存用户统计.html","excerpt":"","text":"需求统计用户的留存率，用户留存率可以得知用户的忠诚度的多少。 留存率：从用户开始使用应用，经过一段时间后仍然继续使用应用的用户，被认为是留存用户；这部分用户占当时新增用户的比例则为留存率 本次需要统计次日、7日、30日留存率 实现方案建立留存率表，每天凌晨使用存储过程更新此表。 已知元素: login_info: 登录日志表 login_info.create_time:用户的注册时间 login_info.login_time:用户的登陆时间 创建留存统计表1234567891011DROP TABLE IF EXISTS `remain_info`;CREATE TABLE `remain_info` ( `date` datetime NOT NULL COMMENT &apos;日期&apos;, `add_num` int(11) DEFAULT NULL COMMENT &apos;新增玩家&apos;, `second_day` float NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;次日留存&apos;, `seventh_day` float NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;7日留存率&apos;, `thirtieth_day` float NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;30日留存率&apos;, `create_time` datetime DEFAULT NULL COMMENT &apos;创建时间&apos;, `update_time` datetime DEFAULT NULL COMMENT &apos;修改时间&apos;, PRIMARY KEY (`date`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 创建相关存储过程insert_remainData:用于处理历史数据 12345678910111213141516171819DROP PROCEDURE IF EXISTS `insert_remainData`;DELIMITER ;;CREATE DEFINER=`root`@`%` PROCEDURE `insert_remainData`(IN `beginDate` date,IN `endDate` date) COMMENT &apos;生产beginDate~endDate时间段的留存数据&apos;BEGIN DECLARE nowdate date DEFAULT NOW(); DECLARE endtmp date DEFAULT NOW(); set nowdate = DATE_FORMAT(beginDate,&apos;%Y%m%d&apos;); set endtmp = DATE_FORMAT(endDate,&apos;%Y%m%d&apos;); WHILE nowdate&lt;=endtmp DO CALL save_remain_data_by_date(nowdate);set nowdate = DATE_ADD(nowdate,INTERVAL 1 DAY); END WHILE; END;;DELIMITER ; save_remain_data:定时执行的存储过程,处理昨天的留存率数据 123456789101112131415161718192021222324252627282930313233343536373839404142DROP PROCEDURE IF EXISTS `save_remain_data`;DELIMITER ;;CREATE DEFINER=`root`@`%` PROCEDURE `save_remain_data`()BEGIN DECLARE today DATE DEFAULT CURDATE(); DECLARE yesterday DATE DEFAULT DATE_SUB(today, INTERVAL 1 DAY); DECLARE days_ago_2 DATE DEFAULT DATE_SUB(today, INTERVAL 2 DAY); DECLARE days_ago_6 DATE DEFAULT DATE_SUB(today, INTERVAL 6 DAY); DECLARE days_ago_7 DATE DEFAULT DATE_SUB(today, INTERVAL 7 DAY); DECLARE days_ago_29 DATE DEFAULT DATE_SUB(today, INTERVAL 29 DAY); DECLARE days_ago_30 DATE DEFAULT DATE_SUB(today, INTERVAL 30 DAY); -- 统计昨天一天的注册人数 INSERT INTO remain_info(add_num, date, create_time) SELECT COUNT(DISTINCT role_uid) , DATE_SUB(CURDATE(), INTERVAL 1 DAY), NOW() FROM login_info WHERE create_time BETWEEN DATE_SUB(CURDATE(), INTERVAL 1 DAY) AND CURDATE();-- 修改前天的2日留存率 UPDATE remain_info SET second_day = FORMAT(( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_2 AND yesterday) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_2 AND yesterday)) ),2),update_time=today WHERE date = days_ago_2; -- 7日留存率 UPDATE remain_info SET seventh_day = FORMAT(( SELECT( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_7 AND days_ago_6) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_7 AND days_ago_6)) ) ),2),update_time=today WHERE date = days_ago_7; -- 30日留存率 UPDATE remain_info SET thirtieth_day = FORMAT(( SELECT( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_30 AND days_ago_29) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_30 AND days_ago_29)) ) ),2),update_time=today WHERE date = days_ago_30; END;;DELIMITER ; save_remain_data_by_date:根据目标日期处理留存率 1234567891011121314151617181920212223242526272829303132333435363738394041DROP PROCEDURE IF EXISTS `save_remain_data_by_date`;DELIMITER ;;CREATE DEFINER=`root`@`%` PROCEDURE `save_remain_data_by_date`(IN `today` date)BEGIN DECLARE yesterday DATE DEFAULT DATE_SUB(today, INTERVAL 1 DAY); DECLARE days_ago_2 DATE DEFAULT DATE_SUB(today, INTERVAL 2 DAY); DECLARE days_ago_6 DATE DEFAULT DATE_SUB(today, INTERVAL 6 DAY); DECLARE days_ago_7 DATE DEFAULT DATE_SUB(today, INTERVAL 7 DAY); DECLARE days_ago_29 DATE DEFAULT DATE_SUB(today, INTERVAL 29 DAY); DECLARE days_ago_30 DATE DEFAULT DATE_SUB(today, INTERVAL 30 DAY); -- 统计昨天一天的注册人数INSERT INTO remain_info(add_num, date, create_time) SELECT COUNT(DISTINCT role_uid) , DATE_SUB(today, INTERVAL 1 DAY), NOW() FROM login_info WHERE create_time BETWEEN DATE_SUB(today, INTERVAL 1 DAY) AND today;-- 修改前天的2日留存率 UPDATE remain_info SET second_day = FORMAT(( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_2 AND yesterday) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_2 AND yesterday)) ),2),update_time=today WHERE date = days_ago_2; -- 7日留存率 UPDATE remain_info SET seventh_day = FORMAT(( SELECT( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_7 AND days_ago_6) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_7 AND days_ago_6)) ) ),2),update_time=today WHERE date = days_ago_7; -- 30日留存率 UPDATE remain_info SET thirtieth_day = FORMAT(( SELECT( (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_30 AND days_ago_29) AND (login_time BETWEEN yesterday AND today)) / (SELECT COUNT(DISTINCT role_uid) FROM login_info WHERE (create_time BETWEEN days_ago_30 AND days_ago_29)) ) ),2),update_time=today WHERE date = days_ago_30; END;;DELIMITER ; 创建事件并启动（event）1234567drop event if EXISTS upload_remain;# 创建计划任务，设置第一次的执行时间为&apos;2017-12-06 01:00:00&apos;,并且每天执行一次create event upload_remain on schedule every 1 day starts timestamp &apos;2017-12-06 01:00:00&apos; do CALL save_remain_data;SET GLOBAL event_scheduler = 1; -- 开启定时器ALTER EVENT upload_remain ON COMPLETION PRESERVE ENABLE; -- 开启事件 注意：若遇到mysql服务重启或者机房断电的情况，则会自动关闭事件调度器，所有事件都不再起作用。 解决方案：在 mysql.ini 文件中加入以下语句 1event_scheduler = ON; 需求奖励mysql 存储过程+1; mysql 事件使用+1;","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"},{"name":"统计分析","slug":"统计分析","permalink":"https://blog.smilexin.cn/tags/统计分析/"}]},{"title":"装饰者模式","slug":"装饰者模式","date":"2017-11-06T16:00:00.000Z","updated":"2021-04-30T02:44:33.321Z","comments":true,"path":"2017/11/07/装饰者模式.html","link":"","permalink":"https://blog.smilexin.cn/2017/11/07/装饰者模式.html","excerpt":"","text":"装饰者模式我们即将再度探讨典型的继承滥用问题。你将在本文学到如何使用对象组合的方式，做到在运行时装饰类。为什么呢？一旦你熟悉了装饰的技巧，你将能够在不修改任何底层代码的情况下,给你的（或别人的）对象赋予新的职责。 动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 认识装饰者模式我们已经了解利用继承无法完全解决问题，在星巴兹遇到的问题有：类数量爆炸、设计死板，以及基类加入的新功能并不适用于所有的子类。所以，在这里要采用不一样的做法：我们要以饮料为主体，然后在运行时以调料来“装饰”（decorate）饮料。比方说，如果顾客想要摩卡和奶泡深焙咖啡，那么，要做的是： 拿一个深焙咖啡（DarkRoast）对象 以摩卡（Mocha）对象装饰它 以奶泡（Whip）对象装饰它 调用cost()方法，并依赖委托（delegate）将调料的价钱加上去。 好了！但是如何“装饰”一个对象，而“委托”又要如何与此搭配使用呢？给一个暗示：把装饰者对象当成“包装者”。让我们看看这是如何工作的…… 装饰者和被装饰对象有相同的超类型。 你可以用一个或多个装饰者包装一个对象。 既然装饰者和被装饰对象有相同的超类型，所以在任何需要原始对象（被包装的）的场合，可以用装饰过的对象代替它。 装饰者可以在所委托被装饰者的行为之前 (与/或) 之后，加上自己的行为，以达到特定的目的。 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。 以装饰者模式构造饮料订单创建基类BeverageBeverage（饮料）是一个抽象类，店内所提供的饮料都必须继承自此类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package hejx.demo.starbuzz;/** * Created by 追风少年 * Beverage（饮料）是一个抽象类，店内所提供的饮料都必须继承自此类。 * Beverage是一个抽象类，有两个方法：getDescription()及cost()。 * @email doubihah@foxmail.com * @create 2017/11/7 11:47 **/public abstract class Beverage &#123; protected String description = &quot;Unknown Beverage&quot;; protected int cupSize = Beverage.TALL; /** * 大杯 */ public static final int TALL = 1; /** * 超大杯 */ public static final int GRANDE = 2; /** * 超超大杯 */ public static final int VENTI = 3; /** * 设置杯量 * @param cupSize */ public void setCupSize(int cupSize)&#123; this.cupSize = cupSize; &#125; public int getCupSize() &#123; return cupSize; &#125; /** * getDescription()已经在此实现了，但是cost()必须在子类中实现。 * @return */ public String getDescription() &#123; return description; &#125; /** * 计算价钱 * @return */ public abstract double cost();&#125; CondimentDecoratorCondiment（调料） 抽象类，也就是装饰者类吧12345678910111213141516171819202122package hejx.demo.starbuzz.condiment;import hejx.demo.starbuzz.Beverage;/** * Created by 追风少年 * Condiment（调料） 抽象类，也就是装饰者类吧 * @email doubihah@foxmail.com * @create 2017/11/7 12:05 **/public abstract class CondimentDecorator extends Beverage&#123; /** * 饮料变量 */ protected Beverage beverage; @Override public int getCupSize() &#123; return beverage.getCupSize(); &#125; public abstract String getDescription();&#125; 实现饮料Espresso先从浓缩咖啡（Espresso）开始。别忘了，我们需要为具体的饮料设置描述，而且还必须实现cost()方法。1234567891011121314151617181920212223242526272829package hejx.demo.starbuzz.drink;import hejx.demo.starbuzz.Beverage;/** * Created by 追风少年 * 浓咖啡 * 让Espresso扩展自 Beverage类，因为Espresso是一种饮料。 * @email doubihah@foxmail.com * @create 2017/11/7 12:07 **/public class Espresso extends Beverage&#123; /** * 为了要设置饮料的描述，我们写了一个构造器。记住，description实例变量继承自 Beverage。 */ public Espresso() &#123; description = &quot;Espresso&quot;; &#125; /** * 最后，需要计算Espresso的价钱，现在不需要管调料的价钱，直接把Espresso的价格$1.99返回即可。 */ @Override public double cost() &#123; return 1.99; &#125;&#125; 实现调料装饰Mocha摩卡 Mocha1234567891011121314151617181920212223242526272829303132333435363738394041424344package hejx.demo.starbuzz.condiment;import hejx.demo.starbuzz.Beverage;/** * Created by 追风少年 * 摩卡是一个装饰者，所以让它扩展自CondimentDecorator。 * 要让Mocha能够引用一个Beverage，做法如下： (1)用一个实例变量记录饮料，也就是被装饰者。 (2)想办法让被装饰者（饮料）被记录到实例变量中。这里的做法是：把 饮料当作构造器的参数，再由构造器将此饮料记录在实例变量中。 * @email doubihah@foxmail.com * @create 2017/11/7 12:14 **/public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public String getDescription() &#123; return beverage.getDescription() + &quot;, Mocha&quot;; &#125; /** * 要计算带Mocha饮料的价钱。 * 首先把调用委托给被装饰对象，以计算价钱，然后再加上Mocha的价钱，得到最后结果。 */ @Override public double cost() &#123; double cost = beverage.cost(); if(getCupSize() == Beverage.TALL)&#123; cost += 0.10; &#125;else if(getCupSize() == Beverage.GRANDE)&#123; cost += 0.15; &#125;else if(getCupSize() == Beverage.VENTI)&#123; cost += 0.20; &#125; System.out.println(&quot;Mocha $ &quot; + cost); return cost; &#125;&#125; Whip奶泡 Whip1234567891011121314151617181920212223242526272829303132package hejx.demo.starbuzz.condiment;import hejx.demo.starbuzz.Beverage;/** * Created by 追风少年 * 奶泡 * @email doubihah@foxmail.com * @create 2017/11/7 12:19 **/public class Whip extends CondimentDecorator &#123; public Whip(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public String getDescription() &#123; return beverage.getDescription() + &quot;, Whip&quot;; &#125; @Override public double cost() &#123; System.out.println(&quot;Whip $ 0.16&quot;); /** * 要计算带Whip饮料的价钱。 * 首先把调用委托给被装饰对象，以计算价钱，然后再加上Whip的价钱，得到最后结果。 */ return beverage.cost() + .16; &#125;&#125; 供应咖啡恭喜你，是时候舒服地坐下来，点一些咖啡，看看你利用装饰者模式设计出的灵活系统是多么神奇了。 这是用来下订单的一些测试代码12345678910111213141516171819202122232425262728293031package hejx.demo.starbuzz;import hejx.demo.starbuzz.condiment.Mocha;import hejx.demo.starbuzz.condiment.Whip;import hejx.demo.starbuzz.drink.DarkRoast;import hejx.demo.starbuzz.drink.Espresso;/** * Created by 追风少年 * 这是用来下订单的一些测试代码 * @email doubihah@foxmail.com * @create 2017/11/7 12:21 **/public class StarbuzzCoffee &#123; public static void main(String[] args) &#123; // 先来一杯浓咖啡,不需要调料,打印它的描述和价钱 Beverage beverage = new Espresso(); System.out.println(beverage.getDescription() + &quot; $&quot; + beverage.cost()); System.out.println(&quot;===========================&quot;); // 再来一杯焦炒（深色）咖啡 Beverage beverage2 = new DarkRoast(); beverage2.setCupSize(Beverage.TALL); beverage2 = new Mocha(beverage2); // 加一点摩卡 beverage2 = new Mocha(beverage2); // 再加一点摩卡 beverage2 = new Whip(beverage2); // 还来点奶泡 System.out.println(beverage2.getDescription() + &quot; $&quot; + beverage2.cost()); &#125;&#125;","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.smilexin.cn/tags/设计模式/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2017-11-06T16:00:00.000Z","updated":"2021-04-30T02:44:33.321Z","comments":true,"path":"2017/11/07/观察者模式.html","link":"","permalink":"https://blog.smilexin.cn/2017/11/07/观察者模式.html","excerpt":"","text":"观察者模式有一个模式可以帮你的对象知悉现况，不会错过该对象感兴趣的事。对象甚至在运行时可决定是否要继续被通知。观察者模式是JDK中使用最多的模式之一，非常有用。我们也会一并介绍一对多关系，以及松耦合（对，没错,我们说耦合）。有了观察者，你将会消息灵通。 认识观察者模式我们看看报纸和杂志的订阅是怎么回事： 报社的业务就是出版报纸。 向某家报社订阅报纸，只要他们有新报纸出版，就会给你送来。只要你是他们的订户，你就会一直收到新报纸。 当你不想再看报纸的时候，取消订阅，他们就不会再送新报纸来。 只要报社还在运营，就会一直有人（或单位）向他们订阅报纸或取消订阅报纸。 出版者 + 订阅者 = 观察者模式 如果你了解报纸的订阅是怎么回事，其实就知道观察者模式是怎么回事，只是名称不太一样：出版者改称为“主题”（Subject），订阅者改称为“观察者”（Observer）。 定义观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 主题和观察者定义了一对多的关系。观察者依赖于此主题，只要主题状态一有变化，观察者就会被通知。根据通知的风格，观察者可能因此新值而更新。稍后你会看到，实现观察者模式的方法不只一种，但是以包含Subject与Observer接口的类设计的做法最常见。 例子: Internet气象观测站需求恭喜贵公司获选为敝公司建立下一代Internet气象观测站！该气象站必须建立在我们专利申请中的WeatherData对象上，由WeatherData对象负责追踪目前的天气状况（温度、湿度、气压）。 我们希望贵公司能建立一个应用，有三种布告板，分别显示目前的状况、气象统计及简单的预报。当WeatherObject对象获得最新的测量数据时，三种布告板必须实时更新。而且，这是一个可以扩展的气象站，Weather-O-Rama气象站希望公布一组API，好让其他开发人员可以写出自己的气象布告板，并插入此应用中。我们希望贵公司能提供这样的API。 瞧一瞧刚送到的WeatherData类 getTemperature() getHumidity() getPressure() mentsChanged() WeatherObject的开发人员留了一个线索 123456/* * 一旦气象测量更新，此方法会被调用 */public void measurementsChanged() &#123; // 你的代码加在这里&#125; 实现需求Java为观察者模式提供了内置的支持，但是，我们暂时不用它，而是先自己动手。虽然，某些时候可以利用Java内置的支持，但是有许多时候，自己建立这一切会更具弹性（况且建立这一切并不是很麻烦）。所以，让我们从建立接口开始吧。 主题接口 Subject123456789101112131415161718192021222324252627282930313233343536/** * Created by 追风少年 * 这是主题接口,对象使用此接口注册为观察者,或者把自己从观察者中删除 * @email doubihah@foxmail.com * @create 2017-09-26 16:26 **/public interface Subject &#123; /** * 注册观察者 * @param observer 观察者 */ void registerObserver(Observer observer); /** * 移除观察者 * @param observer 观察者 */ void removeObserver(Observer observer); /** * 主题改变时通知所有观察者 */ void notifyObservers(); /** * 需要通知观察者 */ void setChanged(); /** * clear changed to false */ void clearChanged();&#125; 观察者接口 Observer12345678910111213/** * Created by 追风少年 * 观察者接口 * 所有潜在的观察者必须实现观察者接口,这个接口只有update()一个方法 * 当主题状态改变时它被调用 * @email doubihah@foxmail.com * @create 2017-09-26 16:32 **/public interface Observer &#123; void update(float temp, float humidity, float pressure);&#125; 展示板接口 DisplayElement1234567891011/** * Created by 追风少年 * 展示板接口 * @email doubihah@foxmail.com * @create 2017-09-26 17:15 **/public interface DisplayElement &#123; void display();&#125; 在WeatherData中实现主题接口12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2017-09-26 16:14 **/public class WeacherData extends Subject &#123; /** * 我们加上一个ArrayList来纪录观察者，此ArrayList是在构造器中建立的。 */ private ArrayList observers; private float temperature; private float humidity; private float pressure; public WeacherData() &#123; observers = new ArrayList(); &#125; /** * setChanged() 方法用来标记状态已经改变的事实，好让notifyObservers()知道当它被调 用时应该更新观察者。如果调用notifyObservers()之前没有先调用setChanged()，观察者 就“不会”被通知。 */ @Override public void setChanged() &#123; changed = true; &#125; @Override public void clearChanged() &#123; changed = false; &#125; /** * 当注册观察者时，我们只要把它加到ArrayList的后面即可。 * @param observer 观察者 */ @Override public void registerObserver(Observer observer) &#123; observers.add(observer); &#125; /** * 同样地，当观察者想取消注册，我们把它从ArrayList中删除即可。 * @param observer 观察者 */ @Override public void removeObserver(Observer observer) &#123; observers.remove(observer); &#125; /** * 有趣的地方来了！在这里，我们把状态告诉每一个观察者。因为观察者都实现了update()，所以我们知道如何通知它们。 */ @Override public void notifyObservers() &#123; if(!changed) return ; for (int i = 0; i &lt; observers.size(); i++) &#123; Observer observer = (Observer)observers.get(i); observer.update(temperature, humidity, pressure); &#125; clearChanged(); &#125; /** * 当从气象站得到更新观测值时,通知观察者 */ private void measurementsChanged()&#123; setChanged(); notifyObservers(); &#125; /** * 我们想要每本书随书赠送一个小型气象站，但是出版社不肯。 * 所以，和从装置中读取实际的气象数据相比，我们宁愿利用这个方法来测试布告板。 * 或者，为了好玩，你也可以写代码从网站上抓取观测值。 * @param temperature * @param humidity * @param pressure */ public void setMeasurements(float temperature, float humidity, float pressure)&#123; this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; this.measurementsChanged(); &#125; //... WeatherData的其他方法&#125; 现在，我们来建立布告板12345678910111213141516171819202122232425public class CurrentConditionsDisplay implements Observer, DisplayElement &#123; private float temperature; private float humidity; private Subject weatherData; public CurrentConditionsDisplay(Subject weatherData) &#123; this.weatherData = weatherData; weatherData.registerObserver(this); &#125; /** * 当update()被调用时，我们把温度和湿度保存起来，然后调用display()。 * @param temperature 温度 * @param humidity 湿度 * @param pressure 气压 */ public void update(float temperature, float humidity, float pressure) &#123; this.temperature = temperature; this.humidity = humidity; display(); &#125; public void display() &#123; System.out.println(&quot;Current conditions: &quot; + temperature + &quot;F degrees and &quot; + humidity + &quot;% humidity&quot;); &#125;&#125; 启动气象站1234567891011121314public class WeatherStation &#123; public static void main(String[] args) &#123; WeatherData weatherData = new WeatherData(); CurrentConditionsDisplay currentDisplay = new CurrentConditionsDisplay(weatherData); StatisticsDisplay statisticsDisplay = new StatisticsDisplay(weatherData); ForecastDisplay forecastDisplay = new ForecastDisplay(weatherData); weatherData.setMeasurements(80, 65, 30.4f); weatherData.setMeasurements(82, 70, 29.2f); weatherData.setMeasurements(78, 90, 29.2f); &#125;&#125; 使用Java内置的观察者模式到目前为止，我们已经从无到有地完成了观察者模式，但是，Java API有内置的观察者模式。java.util包（package）内包含最基本的Observer接口与Observable类，这和我们的Subject接口与Observer接口很相似。Observer接口与Observable类使用上更方便，因为许多功能都已经事先准备好了。你甚至可以使用推（push）或拉（pull）的方式传送数据，稍后就会看到这样的例子。为了更了解java.uitl.Observer和java.util.Observable，看看下面的图，这是修改后的气象站OO设计。 重做气象站1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.Observable;/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2017-09-26 16:14 **/public class WeacherData extends Observable&#123; private float temperature; private float humidity; private float pressure; public WeacherData() &#123;&#125; /** * 当从气象站得到更新观测值时,通知观察者 */ private void measurementsChanged()&#123; /** * setChanged() 方法用来标记状态已经改变的事实，好让notifyObservers()知道当它被调 用时应该更新观察者。如果调用notifyObservers()之前没有先调用setChanged()，观察者 就“不会”被通知。 * setChanged() 方法可以让你在更新观察者时，有更多的弹性，你可以更 适当地通知观察者。比方说，如果没有setChanged()方法，我们的气象站测量是如此敏锐， 以致于温度计读数每十分之一度就会更新，这会造成WeatherData对象持续不断地通知观察 者，我们并不希望看到这样的事情发生。如果我们希望半度以上才更新，就可以在温度差 距到达半度时，调用setChanged()，进行有效的更新。 */ super.setChanged(); notifyObservers(); // 通知观察者的时候没有传递变量,这里采用的是&quot;拉&quot;的做法不是推 &#125; public void setMeasurements(float temperature, float humidity, float pressure)&#123; this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; this.measurementsChanged(); &#125; public float getTemperature() &#123; return temperature; &#125; public float getHumidity() &#123; return humidity; &#125; public float getPressure() &#123; return pressure; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536import java.util.Observable;import java.util.Observer;/** * Created by 追风少年 * 布告板 * @email doubihah@foxmail.com * @create 2017-09-26 17:36 **/public class CurrentConditionsDisplay implements Observer,DisplayElement &#123; private float temperature; private float humidity; private Observable observable; public CurrentConditionsDisplay(Observable weacherData) &#123; this.observable = weacherData; this.observable.addObserver(this); &#125; @Override public void display() &#123; System.out.println(&quot;CurrentConditionsDisplay: &quot; + &quot;temperature=&quot; + temperature + &quot;,humidity=&quot; + humidity); &#125; @Override public void update(Observable obs, Object arg) &#123; if(obs instanceof WeacherData)&#123; WeacherData weacherData = (WeacherData) obs; this.temperature = weacherData.getTemperature(); this.humidity = weacherData.getHumidity(); display(); &#125; &#125;&#125; java.util.Observable的黑暗面是的，你注意到了！如同你所发现的，可观察者是一个“类”而不是一个“接口”，更糟的是，它甚至没有实现一个接口。不幸的是，java.util.Observable的实现有许多问题，限制了它的使用和复用。这并不是说它没有提供有用的功能，我们只是想提醒大家注意一些事实。 Observable是一个类 你已经从我们的原则中得知这不是一件好事，但是，这到底会造成什么问题呢？首先，因为Observable是一个“类”，你必须设计一个类继承它。如果某类想同时具有Observable类和另一个超类的行为，就会陷入两难，毕竟Java不支持多重继承。这限制了Observable的复用潜力（而增加复用潜力不正是我们使用模式最原始的动机吗？）。再者，因为没有Observable接口，所以你无法建立自己的实现，和Java内置的Observer API搭配使用，也无法将java.util的实现换成另一套做法的实现 比方说，Observable将关键的方法保护起来。如果你看看Observable API，你会发现setChanged()方法被保护起来了（被定义成protected）。那又怎么样呢？这意味着：除非你继承自Observable，否则你无法创建Observable实例并组合到你自己的对象中来。这个设计违反了第二个设计原则：“多用组合，少用继承”。 做什么呢？ 如果你能够扩展java.util.Observable，那么Observable“可能”可以符合你的需求。否则，你可能需要像本文开头的做法那样自己实现这一整套观察者模式。不管用哪一种方法，只要你熟悉观察者模式了，应该都能善用它们。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.smilexin.cn/tags/设计模式/"}]},{"title":"MongoDB 简介","slug":"MongoDB 简介","date":"2017-10-27T16:00:00.000Z","updated":"2021-05-14T12:23:54.116Z","comments":true,"path":"2017/10/28/MongoDB 简介.html","link":"","permalink":"https://blog.smilexin.cn/2017/10/28/MongoDB 简介.html","excerpt":"","text":"MongoDB简介 MongoDB是一个开源的，基于分布式的，面向文档存储的非关系型数据库。是非关系型数据库当中功能最丰富、最像关系数据库的。 MongoDB由C++编写，其名字来源于”humongous”这个单词，其宗旨在于处理大量数据。 MongoDB可以运行在Windows、unix、OSX、Solaris系统上，支持32位和64位应用，提供多种编程语言的驱动程序。 MongoDB支持的数据结构非常松散，是类似json的BSON格式，通过键值对的形式存储数据，可以存储复杂的数据类型。 MongoDB支持的数据类型有：null、boolean、String、objectId、32位整数、64位整数、64位浮点数、日期、正则表达式、js代码、二进制数据、数组、内嵌文档、最大值、最小值、未定义类型。 其中，内嵌文档我理解的并不是.doc.txt等文件，这里所指的文档是MongoDB的一个存储单元(相当于关系型数据当中的记录)，在MongoDB中的表现形式为{key1:value1，key2：value2}，而内嵌文档则是这样的形式{key1:value1,key2:{key2.1:value2.1,key2.2:value2.2}}。mongoDB最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。 MongoDB的特性 面向集合存储。数据被分组到若干集合，每个集合可以包含无限个文档，可以将集合想象成RDBMS的表，区别是集合不需要进行模式定义。 模式自由。集合中没有行和列的概念，每个文档可以有不同的key，key的值不要求一致的数据类型。 支持动态查询。MongoDB支持丰富的查询表达式，查询指令使用json形式表达式。 完整的索引支持。MongoDB的查询优化器会分析查询表达式，并生成一个高效的查询计划。 高效的数据存储，支持二进制数据及大型对象（图片、视频等）。 支持复制和故障恢复。 自动分片以支持云级别的伸缩性，支持水平的数据库集群，可动态添加额外的服务器。 MongoDB的适用场景 适合作为信息基础设施的持久化缓存层 适合实时的插入、更新与查询，并具备应用程序实时数据存储所需的复制及高度伸缩性 适合文档化格式的存储及查询 适合由数十或数百台服务器组成的数据库 MongoDB不适用场景 要求高度事务性的系统。例如对于银行或会计等需要大量原子性复杂事物的应用程序来说，还是需要关系型数据库的。 传统的商业智能应用 复杂的表级联查询","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.smilexin.cn/tags/MongoDB/"}]},{"title":"Redis中的事务","slug":"Redis中的事务","date":"2017-10-01T16:00:00.000Z","updated":"2021-04-30T02:44:33.313Z","comments":true,"path":"2017/10/02/Redis中的事务.html","link":"","permalink":"https://blog.smilexin.cn/2017/10/02/Redis中的事务.html","excerpt":"","text":"Redis中的事务Redis支持简单的事务 操作MysqlRedis开启start transactionmuitl语句普通sql普通命令失败rollback 回滚discard 取消成功commitexec 注: rollback与discard 的区别如果已经成功执行了2条语句, 第3条语句出错.Rollback后,前2条的语句影响消失.Discard只是结束本次事务,前2条语句造成的影响仍然还在 注: 在mutil后面的语句中, 语句出错可能有2种情况 语法就有问题, 这种,exec时,报错, 所有语句得不到执行 语法本身没错,但适用对象有问题. 比如 zadd 操作list对象 Exec之后,会执行正确的语句,并跳过有不适当的语句. (如果zadd操作list这种事怎么避免? 这一点,由程序员负责) 思考我正在买票Ticket -1 , money -100而票只有1张, 如果在我multi之后,和exec之前, 票被别人买了—即ticket变成0了.我该如何观察这种情景,并不再提交 悲观的想法:世界充满危险,肯定有人和我抢, 给 ticket上锁, 只有我能操作. [悲观锁] 乐观的想法:没有那么人和我抢,因此,我只需要注意, 有没有人更改ticket的值就可以了 [乐观锁] Redis的事务中,启用的是乐观锁,只负责监测key没有被改动 具体场景一个人正在买票, ticket-1, money-100, 而票只有一张, 如果在我multi之后, exec之前票被别人买走, 即ticket变为0了, 怎么办? 1234567891011121314127.0.0.1:6379&gt; set ticket 1 #加入只有1张票OK127.0.0.1:6379&gt; set lisi 300 #lisi有300OK127.0.0.1:6379&gt; set wang 300 #wang有300OK127.0.0.1:6379&gt; 127.0.0.1:6379&gt; multi #开启事务OK127.0.0.1:6379&gt; decr ticket #票数-1QUEUED127.0.0.1:6379&gt; decrby lisi 100 #lisi准备买-100QUEUED127.0.0.1:6379&gt; #此处还没有exec 假如就在exec之前票被别人买走，打开另一个终端 12345127.0.0.1:6379&gt; decr ticket #票-1(integer) 0127.0.0.1:6379&gt; get ticket #此时票数为0&quot;0&quot;127.0.0.1:6379&gt; 此时提交lisi 1234127.0.0.1:6379&gt; exec1) (integer) -1 #票变为-12) (integer) 200 #钱-100127.0.0.1:6379&gt; 因此上面的过程不合理,要解决上面的情况,要采用监视 12345678910111213141516127.0.0.1:6379&gt; set ticket 1 #票数为1OK127.0.0.1:6379&gt; set lisi 200 #lisi钱是100OK127.0.0.1:6379&gt; set wang 300 #wang是300OK127.0.0.1:6379&gt; 127.0.0.1:6379&gt; watch ticket #监控ticket有没有变动, 有变动的话则事务取消OK127.0.0.1:6379&gt; multi #开启事务OK127.0.0.1:6379&gt; decr ticket #ticket-1QUEUED127.0.0.1:6379&gt; decrby lisi 100 #钱-100QUEUED127.0.0.1:6379&gt; 在exec前票又被另一个人买走了 12345127.0.0.1:6379&gt; decr ticket(integer) 0127.0.0.1:6379&gt; get ticket&quot;0&quot;127.0.0.1:6379&gt; 此时票数为0, lisi提交 1234567127.0.0.1:6379&gt; 127.0.0.1:6379&gt; exec #失败(nil)127.0.0.1:6379&gt; 127.0.0.1:6379&gt; get lisi #钱并没有减少&quot;200&quot;127.0.0.1:6379&gt;","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.smilexin.cn/tags/Redis/"}]},{"title":"设计模式之设计原则","slug":"设计模式_设计原则","date":"2017-09-19T16:00:00.000Z","updated":"2021-04-30T02:44:33.322Z","comments":true,"path":"2017/09/20/设计模式_设计原则.html","link":"","permalink":"https://blog.smilexin.cn/2017/09/20/设计模式_设计原则.html","excerpt":"","text":"设计模式之六大设计原则单一职责原则（Single Responsibility Principle - SRP） 原文：There should never be more than one reason for a class to change. 译文：永远不应该有多于一个原因来改变某个类。 理解：对于一个类而言，应该仅有一个引起它变化的原因。说白了就是，不同的类具备不同的职责，各施其责。这就好比一个团队，大家分工协作，互不影响，各做各的事情。 应用：当我们做系统设计时，如果发现有一个类拥有了两种的职责，那就问自己一个问题：可以将这个类分成两个类吗？如果真的有必要，那就分吧。千万不要让一个类干的事情太多！ 开放封闭原则（Open Closed Principle - OCP） 原文：Software entities like classes, modules and functions should be open for extension but closed for modifications. 译文：软件实体，如：类、模块与函数，对于扩展应该是开放的，但对于修改应该是封闭的。 理解：简言之，对扩展开放，对修改封闭。换句话说，可以去扩展类，但不要去修改类。 应用：当需求有改动，要修改代码了，此时您要做的是，尽量用继承或组合的方式来扩展类的功能，而不是直接修改类的代码。当然，如果能够确保对整体架构不会产生任何影响，那么也没必要搞得那么复杂了，直接改这个类吧。 里氏替换原则（Liskov Substitution Principle - LSP） 原文：Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it. 译文：使用基类的指针或引用的函数，必须是在不知情的情况下，能够使用派生类的对象。 理解：父类能够替换子类，但子类不一定能替换父类。也就是说，在代码中可以将父类全部替换为子类，程序不会报错，也不会在运行时出现任何异常，但反过来却不一定成立。 应用：在继承类时，务必重写（Override）父类中所有的方法，尤其需要注意父类的 protected 方法（它们往往是让您重写的），子类尽量不要暴露自己的 public 方法供外界调用。 迪米特法则（Law of Demeter）又叫作最少知道原则（Least Knowledge Principle） 原文：Only talk to you immediate friends. 译文：只与你最直接的朋友交流。 理解：尽量减少对象之间的交互，从而减小类之间的耦合。简言之，一定要做到：低耦合，高内聚。 应用：在做系统设计时，不要让一个类依赖于太多的其他类，需尽量减小依赖关系，否则，您死都不知道自己怎么死的。 接口隔离原则（Interface Segregation Principle - ISP） 原文：The dependency of one class to another one should depend on the smallest possible interface. 译文：一个类与另一个类之间的依赖性，应该依赖于尽可能小的接口。 理解：不要对外暴露没有实际意义的接口。也就是说，接口是给别人调用的，那就不要去为难别人了，尽可能保证接口的实用性吧。她好，我也好。 应用：当需要对外暴露接口时，需要再三斟酌，如果真的没有必要对外提供的，就删了吧。一旦您提供了，就意味着，您将来要多做一件事情，何苦要给自己找事做呢。 依赖倒置原则（Dependence Inversion Principle - DIP） 原文：High level modules should not depends upon low level modules. Both should depend upon abstractions. Abstractions should not depend upon details. Details should depend upon abstractions. 译文：高层模块不应该依赖于低层模块，它们应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 理解：应该面向接口编程，不应该面向实现类编程。面向实现类编程，相当于就是论事，那是正向依赖（正常人思维）；面向接口编程，相当于通过事物表象来看本质，那是反向依赖，即依赖倒置（程序员思维）。 应用：并不是说，所有的类都要有一个对应的接口，而是说，如果有接口，那就尽量使用接口来编程吧。 将以上六大原则的英文首字母拼在一起就是 SOLID（稳定的），所以也称之为 SOLID 原则。 只有满足了这六大原则，才能设计出稳定的软件架构！但它们毕竟只是原则，只是四人帮给我们的建议，有些时候我们还是要学会灵活应变，千万不要生搬硬套，否则只会把简单问题复杂化，切记！ 补充设计原则组合/聚合复用原则（Composition/Aggregation Reuse Principle - CARP） 当要扩展类的功能时，优先考虑使用组合，而不是继承。这条原则在 23 种经典设计模式中频繁使用，如：代理模式、装饰模式、适配器模式等。可见江湖地位非常之高！ 无环依赖原则（Acyclic Dependencies Principle - ADP） 当 A 模块依赖于 B 模块，B 模块依赖于 C 模块，C 依赖于 A 模块，此时将出现循环依赖。在设计中应该避免这个问题，可通过引入“中介者模式”解决该问题。 共同封装原则（Common Closure Principle - CCP） 应该将易变的类放在同一个包里，将变化隔离出来。该原则是“开放-封闭原则”的延生。 共同重用原则（Common Reuse Principle - CRP） 如果重用了包中的一个类，那么也就相当于重用了包中的所有类，我们要尽可能减小包的大小。 好莱坞原则（Hollywood Principle - HP） 好莱坞明星的经纪人一般都很忙，他们不想被打扰，往往会说：Don’t call me, I’ll call you. 翻译为：不要联系我，我会联系你。对应于软件设计而言，最著名的就是“控制反转”（或称为“依赖注入”），我们不需要在代码中主动的创建对象，而是由容器帮我们来创建并管理这些对象。 其他设计原则不要重复你自己（Don’t repeat yourself - DRY） 不要让重复的代码到处都是，要让它们足够的重用，所以要尽可能地封装。 保持它简单与傻瓜（Keep it simple and stupid - KISS） 不要让系统变得复杂，界面简洁，功能实用，操作方便，要让它足够的简单，足够的傻瓜。 高内聚与低耦合（High Cohesion and Low Coupling - HCLC） 模块内部需要做到内聚度高，模块之间需要做到耦合度低。 惯例优于配置（Convention over Configuration - COC） 尽量让惯例来减少配置，这样才能提高开发效率，尽量做到“零配置”。很多开发框架都是这样做的。 命令查询分离（Command Query Separation - CQS） 在定义接口时，要做到哪些是命令，哪些是查询，要将它们分离，而不要揉到一起。 关注点分离（Separation of Concerns - SOC） 将一个复杂的问题分离为多个简单的问题，然后逐个解决这些简单的问题，那么这个复杂的问题就解决了。难就难在如何进行分离。 契约式设计（Design by Contract - DBC） 模块或系统之间的交互，都是基于契约（接口或抽象）的，而不要依赖于具体实现。该原则建议我们要面向契约编程。 你不需要它（You aren’t gonna need it - YAGNI） 不要一开始就把系统设计得非常复杂，不要陷入“过度设计”的深渊。应该让系统足够的简单，而却又不失扩展性，这是其中的难点。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.smilexin.cn/tags/设计模式/"}]},{"title":"Dubbo 简介","slug":"Dubbo_简介","date":"2017-08-31T16:00:00.000Z","updated":"2021-04-30T02:44:33.307Z","comments":true,"path":"2017/09/01/Dubbo_简介.html","link":"","permalink":"https://blog.smilexin.cn/2017/09/01/Dubbo_简介.html","excerpt":"","text":"Dubbo简介Dubbo是一个分布式服务框架，以及SOA治理方案。 其功能主要包括： 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo适用场景当网站变大后，不可避免的需要拆分应用进行服务化，以提高开发效率，调优性能，节省关键竞争资源等。 当服务越来越多时，服务的URL地址信息就会爆炸式增长，配置管理变得非常困难，F5硬件负载均衡器的单点压力也越来越大。 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？等等…… 在遇到这些问题时，都可以用Dubbo来解决。 Dubbo依赖情况Dubbo运行JDK1.5之上，缺省依赖javassist、netty、spring等包，但不是必须依赖，通过配置Dubbo可不依赖任何三方库运行。 Dubbo性能Dubbo通过长连接减少握手，通过NIO及线程池在单连接上并发拼包处理消息，通过二进制流压缩数据，比常规HTTP等短连接协议更快。在阿里巴巴内部，每天支撑2000多个服务，30多亿访问量，最大单机支撑每天近1亿访问量。 Dubbo安全机制Dubbo主要针对内部服务，对外的服务，阿里有开放平台来处理安全和流控，所以Dubbo在安全方面实现的功能较少，基本上只防君子不防小人，只防止误调用。 Dubbo通过Token令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。Dubbo还提供服务黑白名单，来控制服务所允许的调用方。 Dubbo应用情况在阿里内部，除淘系以外的其它阿里子公司，都在使用Dubbo，包括：中文主站，国际主站，AliExpress，阿里云，阿里金融，阿里学院，良无限，来往等等。 开源后，已被：去哪儿，京东，吉利汽车，方正证劵，海尔，焦点科技，中润四方，华新水泥，海康威视，等公司广泛使用，并不停的有新公司加入，社区讨论及贡献活跃，得到用户很高的评价。 Dubbo现今维护情况Dubbo 在2017年8月重新开始得到官方的维护了","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Redis 持久化","slug":"Redis_持久化","date":"2017-07-30T16:00:00.000Z","updated":"2021-04-30T02:44:33.313Z","comments":true,"path":"2017/07/31/Redis_持久化.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/31/Redis_持久化.html","excerpt":"","text":"Redis 持久化Redis 提供了多种不同级别的持久化方式:一种是RDB,另一种是AOF RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照(point-in-time snapshot) AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在 RDB 快照持久化RDB的工作原理每隔N分钟或者N次写操作后，从内存dump数据形成rdb文件，压缩放在备份目录 注：黄色标注的部分可以通过参数配置 12345678save 900 1 #刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少1个关键字发生变化。save 300 10 #必须是300秒之后至少10个关键字发生变化。save 60 10000 #必须是60秒之后至少10000个关键字发生变化。stop-writes-on-bgsave-error yes #后台存储错误停止写。rdbcompression yes #使用LZF压缩rdb文件。rdbchecksum yes #存储和加载rdb文件时校验。dbfilename dump.rdb #设置rdb文件名。dir ./ #设置工作目录，rdb文件会写入该目录。 RDB的优点 RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集。这种文件非常适合用于进行备份和灾难恢复。 生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB缺点 如果你需要尽量避免在服务器故障时丢失数据，那么RDB 不适合你。 虽然Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF 日志持久化1234appendonly no #是否开启aof日志appendfsync no # 系统缓冲,统一写,速度快appendfsync always # 系统不缓冲,直接写,慢,丢失数据少appendfsync everysec #折衷,每秒写1次 AOF 重写123no-appendfsync-on-rewrite no #为yes,则其他线程的数据放内存里,合并写入(速度快,容易丢失的多)auto-AOF-rewrite-percentage 100 #当前aof文件大小比起上次重写时的大小,增长率100%时,重写auto-AOF-rewrite-min-size 64mb # aof超过64MB的时候才允许进行重写操作 Redis 执行 fork() ，现在同时拥有父进程和子进程。子进程开始将新 AOF 文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 总结如果rdb文件和aof文件都存在，优先使用aof恢复数据","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.smilexin.cn/tags/Redis/"}]},{"title":"Redis 集群概念","slug":"Redis集群概念","date":"2017-07-30T16:00:00.000Z","updated":"2021-04-30T02:44:33.314Z","comments":true,"path":"2017/07/31/Redis集群概念.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/31/Redis集群概念.html","excerpt":"","text":"Redis集群redis集群叫作redis-cluster,每个节点可以相互通信的,每个节点都是同等地位 redis-clusterredis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护nodeslotvalue Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。 redis-cluster投票:容错当某一个节点向目标节点（这里假设目标节点为B节点）发送ping命令而没有得到响应则会对B节点产生怀疑,并将此怀疑广播给集群中的其他节点,其他节点都会向B节点发送ping命令检测B节点是否挂掉,只要集群中有半数以上认为B节点挂掉则就会认为B节点挂掉,若B节点没有备机则集群挂掉,因为槽不完整了，所以为了集群的高可用性,每个节点都应该有主备设施。 投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉. 什么时候整个集群不可用(cluster_state:fail)? a:如果集群任意master挂掉,且当前master没有slave（备机）.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完成时进入fail状态. ps : redis-3.0.0.rc1加入cluster-require-full-coverage参数,默认关闭,打开集群兼容部分失败. b:如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态. ps:当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.smilexin.cn/tags/Redis/"}]},{"title":"memcached 过期数据删除机制","slug":"memcached_过期数据删除机制","date":"2017-07-30T16:00:00.000Z","updated":"2021-04-30T02:44:33.317Z","comments":true,"path":"2017/07/31/memcached_过期数据删除机制.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/31/memcached_过期数据删除机制.html","excerpt":"","text":"memcached过期数据删除机制 当某一个值过期后，并没有从内存删除，因此stats统计时,curr_items有其信息 当某个新值去占用它的位置时，当成空chunk来占用 当 get 值时，判断是否过期，如果过期返回空，并且删除其信息，curr_items就减少了 即：这个过期只是让用户看不到这个数据而已，并没有在过期的瞬间立即从内存删除。这个称为 lazy expiration，惰性失效。 好处：节省 CPU 时间和检测的成本 LRU如果以 122Byte 大小的 chunk 举例，122 的chunk都满了，又有新的值（长度为120byte）要加入，要挤掉谁？memcached 此处使用的 LRU 删除机制 （操作系统的内存管理，常用 FIFO,LRU 删除） LRU：Least Recently Used 最近最少使用 FIFO：first in first out 原理：当某个单元被请求时，维护一个计数器，通过计数器来判断最近谁最少被使用。 注：即使某个key是设置的永久有效期，也一样会被踢出来！ 即：老数据被踢现象","categories":[],"tags":[{"name":"memcached","slug":"memcached","permalink":"https://blog.smilexin.cn/tags/memcached/"}]},{"title":"memcached 内存分配机制","slug":"memcached_内存分配机制","date":"2017-07-30T16:00:00.000Z","updated":"2021-04-30T02:44:33.317Z","comments":true,"path":"2017/07/31/memcached_内存分配机制.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/31/memcached_内存分配机制.html","excerpt":"","text":"内存的碎片化如果用C语言直接malloc,free 来向操作系统申请和释放内存时，在不断的申请和释放过程中，形成了一些很小的内存片段，无法再利用。 这种空闲且无法再利用的内存现象，称为++内存的碎片化++ memcached是如何缓解内存的碎片化的？memcached 用 Slab Allocation 机制来管理内存 Slab Allocation 首先，像一般的内存池一样, 从操作系统分配到一大块内存。 将分配的内存分割成各种尺寸的块（chunk），并把尺寸相同的块分成组（chunk的集合），chunk的大小按照一定比例逐渐递增（图1）。 而且，slab allocator还有重复使用已分配的内存的目的。也就是说，分配到的内存不会释放，而是重复利用。 Slab Allocation的主要术语 Page ：分配给Slab的内存空间，默认是1MB。分配给Slab之后根据slab的大小切分成chunk。 Chunk：用于缓存记录的内存空间。 Slab Class：特定大小的chunk的组。 注意项如果有 100byte 的内容要存，但122byte大小的仓库中的chunk满了，并不会寻找更大的，如144byte的仓库来存储，防止内存浪费的现象。而是把122仓库中的旧数据踢掉！","categories":[],"tags":[{"name":"memcached","slug":"memcached","permalink":"https://blog.smilexin.cn/tags/memcached/"}]},{"title":"JAVA位运算符的应用积累","slug":"JAVA位运算符的应用积累","date":"2017-07-25T16:00:00.000Z","updated":"2021-04-30T02:44:33.309Z","comments":true,"path":"2017/07/26/JAVA位运算符的应用积累.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/26/JAVA位运算符的应用积累.html","excerpt":"","text":"概述位运算是以二进制位为单位进行的运算，其操作数和运算结果都是整型值。位与’&amp;’，位或’|’，位非’~’，位异或’^’，右移’&gt;&gt;’，左移’&lt;&lt;’，0填充的右移’&gt;&gt;&gt;’位运算的位与’&amp;’，位或’|’，位非’~’，位异或’^’与逻辑运算的相应操作的真值表完全相同，其差别只是位运算操作的操作数和运算结果都是二进制整数，而逻辑运算相应操作的操作数和运算结果都是逻辑值boolean型。 应用积累类型集合当某一个对象拥有多种权限或行为时,我们常规的做法是在对象里建立一个集合来存储对象的多种权限或行为。其实这里我们可以使用位运算符的”位与”来实现这种需求。具体代码如下： 需要注意的是我这里使用的int存储行为值，因为int的最大值为2的32次方，所以我的行为类型值得大小不能超过1 &lt;&lt; 32 Activity 123456789101112131415161718192021/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2017-07-26 17:45 **/public abstract class Activity &#123; /** * 是否具有指定类型 * @param activitys 所有行为 * @param activity 要检查拥有的行为 * @return */ public static boolean checkHasActivityType(int activitys,int activity) &#123; // 位与( &amp; ) // 位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0 return (activitys &amp; activity) != 0; &#125;&#125; MaJiangActivity 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Created by 追风少年 * 麻将行为 * @email doubihah@foxmail.com * @create 2017-07-26 17:30 **/public class MaJiangActivity extends Activity&#123; /** * 过 * 需要注意的是因为我这里使用的是int所以最大行为值不能超过 1 &lt;&lt; 32 */ public static int Pass = 1; /** * 碰牌 */ public static int Peng = 1 &lt;&lt; 1; /** * 明杠 */ public static int MingGang = 1 &lt;&lt; 2; /** * 暗杠 */ public static int AnGang = 1 &lt;&lt; 3; /** * 巴杠 */ public static int BaGang = 1 &lt;&lt; 4; /** * 得到用户所拥有的行为 * @return 玩家所拥有的行为集合 */ public static int getUserActivity()&#123; int userActivity = 0; // 玩家拥有的行为,可能为多个 boolean canBaGang = true; if (canBaGang) userActivity += MaJiangActivity.BaGang; boolean canAnGang = true; if (canAnGang) userActivity += MaJiangActivity.AnGang; return userActivity; &#125; // 程序入口 public static void main(String[] args) &#123; int userActivity = getUserActivity(); if(Activity.checkHasActivityType(userActivity,MaJiangActivity.AnGang))&#123; // 检查用户是否具有暗杠行为 System.out.println(&quot;具有暗杠行为...&quot;); &#125; if(!Activity.checkHasActivityType(userActivity,MaJiangActivity.Pass))&#123; // 检查用户是否不具有过的行为 System.out.println(&quot;不具有过行为...&quot;); &#125; &#125;&#125;","categories":[],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"java","slug":"java","permalink":"https://blog.smilexin.cn/tags/java/"}]},{"title":"JDK8 新特性之lambda表达式","slug":"JDK8_新特性之lambda表达式","date":"2017-07-12T16:00:00.000Z","updated":"2021-04-30T02:44:33.310Z","comments":true,"path":"2017/07/13/JDK8_新特性之lambda表达式.html","link":"","permalink":"https://blog.smilexin.cn/2017/07/13/JDK8_新特性之lambda表达式.html","excerpt":"","text":"lambda表达式lambda表达式其实就是按一定语法，省略书写固定的代码，达到简化代码的效果。 使用lambda表达式要使用lambda表达式需要注明jdk8编译 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; lambda应用案例集合排序 普通的写法 12ArrayList&lt;Integer&gt; list = new ArrayList();Collections.sort(list); // 默认的是升序,升序排序 使用lambda的写法： 123ArrayList&lt;Integer&gt; list = new ArrayList();list.sort((o1, o2) -&gt; o2 - o1); // 降序list.sort(null); // 默认升序 对List集合中的User按照age的大小进行排序输出 普通的写法 123456789101112131415161718192021222324private static List&lt;User&gt; list=new ArrayList&lt;User&gt;(); public static void main(String[] args) &#123; list.add(new User(34)); list.add(new User(14)); list.add(new User(24)); System.out.println(&quot;排序前：&quot;+list.toString()); //对list集合的数据进行按照年龄排序 Collections.sort(list, new Comparator&lt;User&gt;() &#123; @Override public int compare(User o1, User o2) &#123; // TODO Auto-generated method stub return Integer.compare(o1.age, o2.age); &#125; &#125;); System.out.println(&quot;排序后：&quot;+list.toString()); &#125; ------------------------ 输出结果： 排序前：[34, 14, 24] 排序后：[14, 24, 34] 使用lambda的写法： 123456789101112131415private static List&lt;User&gt; list=new ArrayList&lt;User&gt;(); public static void main(String[] args) &#123; ...... System.out.println(&quot;排序前：&quot;+list.toString()); //对list集合的数据进行按照年龄排序(现在一行就可以代替上面的排序代码) Collections.sort(list, (o1,o2)-&gt;Integer.compare(o1.age, o2.age)); System.out.println(&quot;排序后：&quot;+list.toString()); &#125; ------------------------ 输出结果： 排序前：[34, 14, 24] 排序后：[14, 24, 34] 新开一个子线程，并在子线程中输出“helloWord” 普通的写法： 12345678public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;HelloWord&quot;); &#125; &#125;).start();&#125; 使用lambda的写法： 1234public static void main(String[] args) &#123; //使用这个：()-&gt;Syso(&quot;HelloWord&quot;)表达式代替内部类，其实Syso(&quot;HelloWord&quot;)这个位置可以使用一个方法来代替 new Thread( ()-&gt;System.out.println(&quot;HelloWord&quot;) ).start();&#125; 案例分析lambda表达式：其实就是省略书写固定的代码 下面的代码那些是固定的呢？那些是可以省略书写的呢？1234567//对list集合的数据进行按照年龄排序Collections.sort(list, new Comparator&lt;User&gt;() &#123; @Override public int compare(User o1, User o2) &#123; return Integer.compare(o1.age, o2.age); &#125;&#125;); 可以省略书写的是： 1. new Comparator() 这个是固定的，因为参数必须接受Comparator 2. compare这个方法名也是可以省略 3. compare这个方法的返回值和权限都可以省略 省略固定的代码后变成： 123456//对list集合的数据进行按照年龄排序Collections.sort(list, (User o1, User o2)-&gt;&#123; return Integer.compare(o1.age, o2.age); &#125;); 还有什么可以省略得呢？其实（User o1, User o2）的User也可以省略，因为list集合里存的都是User,JVM是可以猜测的出参数额类型。 省略固定的代码后变成：123456//对list集合的数据进行按照年龄排序Collections.sort(list, ( o1, o2)-&gt;&#123; return Integer.compare(o1.age, o2.age); &#125;); 还有什么可以省略得呢？其实return也可以省略，JVM是可以猜测的出返回类型。 修改变成：12//lambda表达式是：(o1, o2)-&gt;(Integer.compare(o1.age, o2.age))。代替复杂内部类Collections.sort(list, (o1, o2) -&gt; (Integer.compare(o1.age, o2.age)) ); 既然要传list,那我可否直接用list排序,当然可以的,代码优化为: 1list.sort((o1, o2) -&gt; (Integer.compare(o1.getAge(), o2.getAge()))); lambda表达式的基本语法lambda表达式的基本语法：参数列表 -&gt; 表达式 参数列表： 1.如果没有参数，直接用（）来表示。//如上需求2的（）-&gt;System.out.println(&quot;HelloWord&quot;) 2.如果只有一个参数，并且参数写了类型，参数外面一定要加（）。 3.如果只有一个参数，并且参数不写类型，那么这个参数外面可以不用加（。 4.如果有两个或者多个参数，不管是否写参数类型，都要加（）。//如上需求1 5.如果参数要加修饰符或者标签，参数一定要加上完整的类型。 表达式： 1.如果表达式只有一行，那么可以直接写（不需要{}）； 2.如果表达式只有多行，需要用{}变成代码块； 3.如果表达式是代码块，并且方法需要返回值，那么在代码块中就必须返回一个返回值； 4.如果只有单行的情况，并且方法需要返回值，不能有return，编译器会自动帮我们推导return;","categories":[],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://blog.smilexin.cn/tags/JDK/"},{"name":"java","slug":"java","permalink":"https://blog.smilexin.cn/tags/java/"}]},{"title":"Dubbo demo项目 (五) 启动Dubbo服务","slug":"Dubbo_demo项目（五)","date":"2017-07-03T16:00:00.000Z","updated":"2021-04-30T02:44:33.306Z","comments":true,"path":"2017/07/04/Dubbo_demo项目（五).html","link":"","permalink":"https://blog.smilexin.cn/2017/07/04/Dubbo_demo项目（五).html","excerpt":"","text":"尝试启动现在已经基本上搭建完成了 Dubbo 业务中心,但是如果想要正常的使用 Dubbo 还需要对整体的代码进行调试 定义一个 Dubbo 服务的启动程序类：ProviderStartup 1234567891011121314151617package cn.hejx.service.impl.demo;import com.alibaba.dubbo.container.Main;/** * Created by 追风少年 * service 启动入口 * @email doubihah@foxmail.com * @create 2017-07-03 10:07 **/public class ProviderStartup &#123; public static void main(String[] args) &#123; Main.main(args); // 启动dubbo服务 &#125;&#125; 能够这样启动的主要的原因在于项目之中已经按照 Dubbo 的默认要求编写了 META-INF “Main.main(args)” 在读取的时候会自动的找到指定目录,进行配置文件的加载 排除错误123456789101112131415161718192021222324252627282930313233343536log4j:WARN No appenders could be found for logger (com.alibaba.dubbo.common.logger.LoggerFactory).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.org.springframework.beans.factory.BeanDefinitionStoreException: Unexpected exception parsing XML document from file [E:\\IdeaProjects\\dubbodemo\\service\\target\\classes\\META-INF\\spring\\spring-common.xml]; nested exception is java.lang.IllegalStateException: Context namespace element &apos;component-scan&apos; and its parser class [org.springframework.context.annotation.ComponentScanBeanDefinitionParser] are only available on JDK 1.5 and higher at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:420) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:342) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:310) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:143) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:178) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:149) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:212) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:113) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:80) at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:123) at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:422) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:352) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:93) at com.alibaba.dubbo.container.spring.SpringContainer.start(SpringContainer.java:50) at com.alibaba.dubbo.container.Main.main(Main.java:80) at cn.hejx.service.impl.demo.ProviderStartup.main(ProviderStartup.java:14) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Caused by: java.lang.IllegalStateException: Context namespace element &apos;component-scan&apos; and its parser class [org.springframework.context.annotation.ComponentScanBeanDefinitionParser] are only available on JDK 1.5 and higher at org.springframework.context.config.ContextNamespaceHandler$1.parse(ContextNamespaceHandler.java:65) at org.springframework.beans.factory.xml.NamespaceHandlerSupport.parse(NamespaceHandlerSupport.java:69) at org.springframework.beans.factory.xml.BeanDefinitionParserDelegate.parseCustomElement(BeanDefinitionParserDelegate.java:1297) at org.springframework.beans.factory.xml.BeanDefinitionParserDelegate.parseCustomElement(BeanDefinitionParserDelegate.java:1287) at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:135) at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:92) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:507) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398) ... 21 more 问题处理1[org.springframework.context.annotation.ComponentScanBeanDefinitionParser] are only available on JDK 1.5 and higher 控制台显示ComponentScanBeanDefinitionParser应该运行在 jdk1.5 或者更高级别,现在我们对整个项目的依赖包进行排查 由于我使用的是 IntelliJ IDEA 进行开发 该工具有个Maven Projects窗口，一般在右侧能够找到，如果没有可以从菜单栏打开：View&gt;Tool Windows&gt;Maven Projects 选择要分析的maven module(idea的module相当于eclipse的project),右击show dependencies,会出来该module的全部依赖关系图，非常清晰细致 在图里选中一个artifact,则所有依赖该artifact的地方都会一起连带出来突出显示，如果有不同版本的也会标记出来。这样该artifact在该工程里是如何被直接或间接引入的进来也就明朗了 如果有冲突的版本，可以右击该版本的节点然后Exclude，对应的pom.xml就已经成功修改了。(IntelliJ IDEA对于文件的修改都是实时保存的，无须Ctrl+S) 问题原因：由于 Dubbo 的依赖程序库本身有自己依赖的 spring 的 jar 包,所以需要对重复的包做一个排除操作 1234567891011&lt;dependency&gt; &lt;!-- 导入Dubbo开发包 --&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 项目中已经配置了日志组件,但是这个日志并没有正常的显示 123456log4j:WARN No appenders could be found for logger (com.alibaba.dubbo.common.logger.LoggerFactory).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.[2017-07-03 10:57:23] Dubbo service server started!Process finished with exit code 1 经检查发现在 Zookeeper 里面进行下载的时候也会出现log4j,slf4j组件,需要继续追加排除 123456789101112131415&lt;dependency&gt; &lt;!-- 导入Zookeeper开发包 --&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 调试完成,成功启动1234567891011121314151617181920212223242526272829303132333435363738394041424344452017-07-03 14:06:56 | INFO | main | cn.hejx.service.impl.demo.ProviderStartup | info ..............2017-07-03 14:06:56 | ERROR | main | cn.hejx.service.impl.demo.ProviderStartup | error msg2017-07-03 14:06:56 | INFO | main | com.alibaba.dubbo.common.logger.LoggerFactory | using logger: com.alibaba.dubbo.common.logger.slf4j.Slf4jLoggerAdapter2017-07-03 14:06:56 | INFO | main | com.alibaba.dubbo.container.Main | [DUBBO] Use container type([spring]) to run dubbo serivce., dubbo version: 2.5.3, current host: 127.0.0.1七月 03, 2017 2:06:56 下午 org.springframework.context.support.ClassPathXmlApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@1bce4f0a: startup date [Mon Jul 03 14:06:56 CST 2017]; root of context hierarchy七月 03, 2017 2:06:57 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from file [E:\\IdeaProjects\\dubbodemo\\service\\target\\classes\\META-INF\\spring\\spring-common.xml]七月 03, 2017 2:06:57 下午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from file [E:\\IdeaProjects\\dubbodemo\\service\\target\\classes\\META-INF\\spring\\spring-dubbo.xml]七月 03, 2017 2:06:57 下午 org.springframework.context.support.PropertySourcesPlaceholderConfigurer loadProperties信息: Loading properties file from file [E:\\IdeaProjects\\dubbodemo\\service\\target\\classes\\config\\dubbo.properties]2017-07-03 14:06:58 | INFO | main | com.alibaba.dubbo.config.AbstractConfig | [DUBBO] The service ready on spring started. service: cn.hejx.remoteapi.IMessage, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:58 | INFO | main | com.alibaba.dubbo.config.AbstractConfig | [DUBBO] Export dubbo service cn.hejx.remoteapi.IMessage to local registry, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:58 | INFO | main | com.alibaba.dubbo.config.AbstractConfig | [DUBBO] Export dubbo service cn.hejx.remoteapi.IMessage to url dubbo://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:58 | INFO | main | com.alibaba.dubbo.config.AbstractConfig | [DUBBO] Register dubbo service cn.hejx.remoteapi.IMessage url dubbo://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev to registry registry://192.168.2.233:2181/com.alibaba.dubbo.registry.RegistryService?application=hejx-service&amp;dubbo=2.5.3&amp;pid=8928&amp;registry=zookeeper&amp;timestamp=1499062018617, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.remoting.transport.AbstractServer | [DUBBO] Start NettyServer bind /0.0.0.0:19372, export /192.168.2.100:19372, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.registry.zookeeper.ZookeeperRegistry | [DUBBO] Load registry store file C:\\Users\\Administrator\\.dubbo\\dubbo-registry-192.168.2.233.cache, data: &#123;cn.hejx.remoteapi.IMessage:dev=empty://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;category=configurators&amp;check=false&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=7128&amp;revision=dev&amp;side=provider&amp;timestamp=1499062000651&amp;version=dev&#125;, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | ZkClient-EventThread-16-192.168.2.233:2181 | org.I0Itec.zkclient.ZkEventThread | Starting ZkClient event thread.2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:host.name=PC-20170423KMDT2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.version=1.8.0_1312017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.vendor=Oracle Corporation2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.home=C:\\Program Files\\Java\\jdk1.8.0_131\\jre2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.class.path=C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\charsets.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\deploy.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\access-bridge-64.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\cldrdata.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\dnsns.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\jaccess.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\jfxrt.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\localedata.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\nashorn.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\sunec.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\sunjce_provider.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\sunmscapi.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\sunpkcs11.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\ext\\zipfs.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\javaws.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\jce.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\jfr.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\jfxswt.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\jsse.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\management-agent.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\plugin.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\resources.jar;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\lib\\rt.jar;E:\\IdeaProjects\\dubbodemo\\service\\target\\classes;E:\\IdeaProjects\\dubbodemo\\remoteapi\\target\\classes;C:\\Users\\Administrator\\.m2\\repository\\com\\alibaba\\dubbo\\2.5.3\\dubbo-2.5.3.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\jboss\\netty\\netty\\3.2.5.Final\\netty-3.2.5.Final.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\apache\\zookeeper\\zookeeper\\3.4.9\\zookeeper-3.4.9.jar;C:\\Users\\Administrator\\.m2\\repository\\jline\\jline\\0.9.94\\jline-0.9.94.jar;C:\\Users\\Administrator\\.m2\\repository\\io\\netty\\netty\\3.10.5.Final\\netty-3.10.5.Final.jar;C:\\Users\\Administrator\\.m2\\repository\\com\\101tec\\zkclient\\0.10\\zkclient-0.10.jar;C:\\Users\\Administrator\\.m2\\repository\\ch\\qos\\logback\\logback-core\\1.2.3\\logback-core-1.2.3.jar;C:\\Users\\Administrator\\.m2\\repository\\ch\\qos\\logback\\logback-classic\\1.2.3\\logback-classic-1.2.3.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\slf4j\\slf4j-api\\1.7.25\\slf4j-api-1.7.25.jar;C:\\Users\\Administrator\\.m2\\repository\\commons-beanutils\\commons-beanutils\\1.9.3\\commons-beanutils-1.9.3.jar;C:\\Users\\Administrator\\.m2\\repository\\commons-logging\\commons-logging\\1.2\\commons-logging-1.2.jar;C:\\Users\\Administrator\\.m2\\repository\\commons-collections\\commons-collections\\3.2.2\\commons-collections-3.2.2.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\apache\\commons\\commons-lang3\\3.5\\commons-lang3-3.5.jar;C:\\Users\\Administrator\\.m2\\repository\\io\\netty\\netty-all\\4.1.9.Final\\netty-all-4.1.9.Final.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\javassist\\javassist\\3.21.0-GA\\javassist-3.21.0-GA.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-core\\4.3.5.RELEASE\\spring-core-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-context\\4.3.5.RELEASE\\spring-context-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-expression\\4.3.5.RELEASE\\spring-expression-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-context-support\\4.3.5.RELEASE\\spring-context-support-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-beans\\4.3.5.RELEASE\\spring-beans-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-aop\\4.3.5.RELEASE\\spring-aop-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\springframework\\spring-aspects\\4.3.5.RELEASE\\spring-aspects-4.3.5.RELEASE.jar;C:\\Users\\Administrator\\.m2\\repository\\org\\aspectj\\aspectjweaver\\1.8.9\\aspectjweaver-1.8.9.jar;D:\\Program Files (x86)\\JetBrains\\IntelliJ IDEA 2016.3.4\\lib\\idea_rt.jar2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.library.path=C:\\Program Files\\Java\\jdk1.8.0_131\\bin;C:\\Windows\\Sun\\Java\\bin;C:\\Windows\\system32;C:\\Windows;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\Java\\jdk1.8.0_131\\bin;C:\\Program Files\\Java\\jdk1.8.0_131\\jre\\bin;C:\\Program Files\\MySQL\\MySQL Utilities 1.6\\;C:\\Program Files\\TortoiseSVN\\bin;D:\\apache-maven-3.3.9\\bin;D:\\Program Files (x86)\\Git\\bin;C:\\Program Files\\MySQL\\MySQL Server 5.7\\bin;;.2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.io.tmpdir=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:java.compiler=&lt;NA&gt;2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:os.name=Windows 72017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:os.arch=amd642017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:os.version=6.12017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:user.name=Administrator2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:user.home=C:\\Users\\Administrator2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Client environment:user.dir=E:\\IdeaProjects\\dubbodemo2017-07-03 14:06:59 | INFO | main | org.apache.zookeeper.ZooKeeper | Initiating client connection, connectString=192.168.2.233:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4bc222e2017-07-03 14:06:59 | INFO | main | org.I0Itec.zkclient.ZkClient | Waiting for keeper state SyncConnected2017-07-03 14:06:59 | INFO | main-SendThread(192.168.2.233:2181) | org.apache.zookeeper.ClientCnxn | Opening socket connection to server 192.168.2.233/192.168.2.233:2181. Will not attempt to authenticate using SASL (unknown error)2017-07-03 14:06:59 | INFO | main-SendThread(192.168.2.233:2181) | org.apache.zookeeper.ClientCnxn | Socket connection established to 192.168.2.233/192.168.2.233:2181, initiating session2017-07-03 14:06:59 | INFO | main-SendThread(192.168.2.233:2181) | org.apache.zookeeper.ClientCnxn | Session establishment complete on server 192.168.2.233/192.168.2.233:2181, sessionid = 0x15d065f7a61001e, negotiated timeout = 300002017-07-03 14:06:59 | INFO | main-EventThread | org.I0Itec.zkclient.ZkClient | zookeeper state changed (SyncConnected)2017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.registry.zookeeper.ZookeeperRegistry | [DUBBO] Register: dubbo://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.registry.zookeeper.ZookeeperRegistry | [DUBBO] Subscribe: provider://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;category=configurators&amp;check=false&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev, dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.registry.zookeeper.ZookeeperRegistry | [DUBBO] Notify urls for subscribe url provider://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;category=configurators&amp;check=false&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev, urls: [empty://192.168.2.100:19372/cn.hejx.remoteapi.IMessage?anyhost=true&amp;application=hejx-service&amp;category=configurators&amp;check=false&amp;default.timeout=3000&amp;dubbo=2.5.3&amp;interface=cn.hejx.remoteapi.IMessage&amp;methods=echo&amp;pid=8928&amp;revision=dev&amp;side=provider&amp;timestamp=1499062018653&amp;version=dev], dubbo version: 2.5.3, current host: 127.0.0.12017-07-03 14:06:59 | INFO | main | com.alibaba.dubbo.container.Main | [DUBBO] Dubbo SpringContainer started!, dubbo version: 2.5.3, current host: 127.0.0.1[2017-07-03 14:06:59] Dubbo service server started! 查看zookeeper信息123456zkCli.sh -server 192.168.2.233[zk: 192.168.2.233(CONNECTED) 3] ls /[dubbo, zookeeper][zk: 192.168.2.233(CONNECTED) 4] ls /dubbo[cn.hejx.remoteapi.IMessage][zk: 192.168.2.233(CONNECTED) 5] 当业务中心注册成功以后会自动的在 zookeeper 里面保存有相应的 dubbo 的远程服务接口信息 这里附上修改后的service/pom.xml配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;service&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;profiles.dir&gt;src/main/profiles&lt;/profiles.dir&gt; &lt;maven.jar.plugin.version&gt;3.0.2&lt;/maven.jar.plugin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 导入项目之中要使用的公共接口项目 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;artifactId&gt;remoteapi&lt;/artifactId&gt; &lt;version&gt;$&#123;remoteapi.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 导入Dubbo开发包 --&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 导入Zookeeper开发包 --&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;$&#123;zkclient.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 导入所有要使用到的日志组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入 commons 组件包 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;$&#123;commons.beanutils.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-lang3.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;$&#123;netty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;$&#123;javassist.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入Spring相关配置包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 配置 profile 文件 --&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/dev&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;beta&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/beta&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/product&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;build&gt; &lt;finalName&gt;service&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;profile.dir&#125;&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.jar.plugin.version&#125;&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Dubbo demo项目 (三) 搭建业务中心项目","slug":"Dubbo_demo项目（三)","date":"2017-07-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.306Z","comments":true,"path":"2017/07/03/Dubbo_demo项目（三).html","link":"","permalink":"https://blog.smilexin.cn/2017/07/03/Dubbo_demo项目（三).html","excerpt":"","text":"业务中心 业务中心是整个 Dubbo 的核心所在 业务中心的搭建需要配置许多的开发包 搭建业务中心的开发环境 首先建立一个 service 的项目，作为业务中心的存在：cn.hejx.service 修改 parent/pom.xml 配置文件导入所需要 Dubbo 的开发类库 修改 parent/pom.xml 配置文件主要是新增开发包的属性配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;!-- 此配置文件作为父项pom.xml --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;remoteapi&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;jdk.version&gt;1.8&lt;/jdk.version&gt; &lt;!-- 定义要使用的jdk的开发版本 --&gt; &lt;!-- maven是个项目管理工具，如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话， 它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题， 以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本， 那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现， 在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。 --&gt; &lt;maven.compiler.plugin.version&gt;3.6.0&lt;/maven.compiler.plugin.version&gt; &lt;!-- 源代码打包插件 --&gt; &lt;maven.source.plugin.version&gt;3.0.1&lt;/maven.source.plugin.version&gt; &lt;!-- 定义所有使用的开发包的版本 --&gt; &lt;dubbo.version&gt;2.5.3&lt;/dubbo.version&gt; &lt;!-- 定义要使用的dubbo开发版本 --&gt; &lt;!-- 定义要使用的zookeeper开发版本,注意这个版本必须与服务器上的zookeeper版本一致 --&gt; &lt;zookeeper.version&gt;3.4.9&lt;/zookeeper.version&gt; &lt;!-- ZkClient 在整个项目里面是Dubbo要使用的开发包，他描述的是Zookeeper客户端的操作处理 --&gt; &lt;zkclient.version&gt;0.10&lt;/zkclient.version&gt; &lt;spring.version&gt;4.3.5.RELEASE&lt;/spring.version&gt; &lt;!-- 定义要使用的Spring版本 --&gt; &lt;logback.version&gt;1.2.3&lt;/logback.version&gt; &lt;!-- 日志处理包 --&gt; &lt;slf4j.version&gt;1.7.25&lt;/slf4j.version&gt; &lt;!-- 定义日志的支持包 --&gt; &lt;!--&lt;aspectj.version&gt;1.8.10&lt;/aspectj.version&gt; &amp;lt;!&amp;ndash; Aspectj 面向切面开发包 &amp;ndash;&amp;gt;--&gt; &lt;commons.beanutils.version&gt;1.9.3&lt;/commons.beanutils.version&gt; &lt;!-- commons.beanutils开发包 --&gt; &lt;commons-lang3.version&gt;3.5&lt;/commons-lang3.version&gt; &lt;!-- commons-lang3开发包 --&gt; &lt;netty.version&gt;4.1.9.Final&lt;/netty.version&gt; &lt;!-- netty --&gt; &lt;javassist.version&gt;3.21.0-GA&lt;/javassist.version&gt; &lt;!-- Javassist动态编译的开发包 --&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;!-- 定义要使用的junit版本 --&gt; &lt;remoteapi.version&gt;1.0-SNAPSHOT&lt;/remoteapi.version&gt; &lt;/properties&gt; &lt;build&gt;&lt;!-- 定义编译时的配置项 --&gt; &lt;finalName&gt;parent&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.source.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;!-- 排除所有的jar文件 --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.compiler.plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;jdk.version&#125;&lt;/source&gt; &lt;!-- 定义源代码的开发版本 --&gt; &lt;target&gt;$&#123;jdk.version&#125;&lt;/target&gt; &lt;!-- 定义生成class文件的编译版本 --&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 修改 service/pom.xml 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;service&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;maven.jar.plugin.version&gt;3.0.2&lt;/maven.jar.plugin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 导入项目之中要使用的公共接口项目 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;artifactId&gt;remoteapi&lt;/artifactId&gt; &lt;version&gt;$&#123;remoteapi.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 导入Dubbo开发包 --&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 导入Zookeeper开发包 --&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;$&#123;zkclient.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入所有要使用到的日志组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入 commons 组件包 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;$&#123;commons.beanutils.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-lang3.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;$&#123;netty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;$&#123;javassist.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 导入Spring相关配置包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;service&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.jar.plugin.version&#125;&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 小结此时引入了所有开发类库需要的相关程序包，但是这些开发包由于彼此之间会存在有一些其他版本的依赖库的问题，所以在随后进行业务启动的时候还需要去排查冲突的开发包","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Dubbo demo项目 (四) 定义业务中心配置文件","slug":"Dubbo_demo项目（四)","date":"2017-07-02T16:00:00.000Z","updated":"2021-04-30T02:44:33.307Z","comments":true,"path":"2017/07/03/Dubbo_demo项目（四).html","link":"","permalink":"https://blog.smilexin.cn/2017/07/03/Dubbo_demo项目（四).html","excerpt":"","text":"业务实现类实现remoteapi中的IMessage接口 定义 Message 接口实现类1234567891011121314151617181920package cn.hejx.service.impl;import cn.hejx.IMessage;import org.springframework.stereotype.Component;/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2017-06-30 16:07 **/@Componentpublic class MessageImpl implements IMessage&#123; @Override public String echo(String msg) &#123; return &quot;ECHO:&quot; + msg; &#125;&#125; 此时 MessageImpl 程序类定义的 Bean 的名称为 messageImpl ,首字母小写 定义业务中心配置文件 在一个真实的项目之中必须要去考虑各种可能出现的不同的项目环境，所以一般会建立一个profiles目录，在这个目录下我们建立若干个子目录，例如：dev、beta、product “src/main/profiles/dev” ：描述开发环境下的相关属性 “src/main/profiles/beta” ：描述测试环境下的相关属性 “src/main/profiles/product” ：描述生产环境下的相关属性 由于本次项目使用了 logback 日志组件,所以还需要有一个 logback.xml 的配置文件存在,这个文件可以直接保存在 “src/main/profiles/{dev,beta,product}” 目录下 在 “src/main/profiles/{dev,beta,product}/config” 目录,里面保存所有的 *.properties 文件 定义一个 dubbo.properties 文件,主要的功能是进行 dubbo 相关的配置,而在实际开发之中还需要定义一个 database.properties 文件,进行数据库的连接项的信息配置 建立一个 “src/main/resources” 目录，在这个目录之中一定要有一个 META-INF 的目录，里面可以保存具体的配置文件，例如：如果现在需要定义的是所有的 Spring 配置文件，那么可以将其目录设置为“src/main/resources/META-INF/spring” 默认情况下 Dubbo 在进行配置文件加载的时候使用的就是 META-INF 作为加载配置文件的标记 将之前建立的 resources 目录和 profiles/xx 目录设置为资源根目录 修改 service/pom.xml 配置文件,重点在于构建 profile 编译的相关处理操作 1.增加一个环境属性,描述 profile 的路径 1234&lt;properties&gt; &lt;profiles.dir&gt;src/main/profiles&lt;/profiles.dir&gt; &lt;maven.jar.plugin.version&gt;3.0.2&lt;/maven.jar.plugin.version&gt;&lt;/properties&gt; 2.在 pom.xml 里面追加 profiles 和 resources 定义 12345678910111213141516171819202122232425262728293031323334353637383940&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/dev&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;beta&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/beta&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;profile.dir&gt;$&#123;profiles.dir&#125;/product&lt;/profile.dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt;&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;profile.dir&#125;&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; 3.在 “src/main/resources/META-INF/spring” 目录下创建 spring-common.xml 配置文件 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 配置 Annotation 扫描包 --&gt; &lt;context:component-scan base-package=&quot;cn.hejx.service&quot; /&gt; &lt;!-- 定义所有要导入的属性文件的路径 --&gt; &lt;context:property-placeholder location=&quot;classpath:config/*.properties&quot; /&gt;&lt;/beans&gt; 4.编辑 dubbo.properties 配置文件,追加相关的信息 12345678910# 定义当前业务中心操作业务的名称dubbo.application.name=hejx-service# 定义dubbo的注册中心的地址项,本次利用ZooKeeper进行的dubbo数据保存dubbo.registry.address=zookeeper://192.168.2.233:2181# 定义dubbo在哪个端口上要进行服务的发布,10000以上随便写dubbo.protocol.port=19372# 要进行的是远程调用,那么就一定会有一个超时时间的问题dubbo.provider.timeout=3000# 定义远程服务的操作版本dubbo.interface.version=dev 5.在 “src/main/resources/META-INF/spring” 目录下创建 spring-dubbo.xml 配置文件 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!-- 定义当前应用的名称,主要是用于注册中心的信息保存,这个名称可以任意填写 --&gt; &lt;dubbo:application name=&quot;$&#123;dubbo.application.name&#125;&quot; /&gt; &lt;!-- 定义dubbo注册中心的地址 --&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;$&#123;dubbo.registry.address&#125;&quot; /&gt; &lt;!-- 定义dubbo所在的服务,执行时暴露给客户端的端口 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;$&#123;dubbo.protocol.port&#125;&quot; /&gt; &lt;!-- 定义远程服务提供者操作的超时时间 --&gt; &lt;dubbo:provider timeout=&quot;$&#123;dubbo.provider.timeout&#125;&quot; /&gt; &lt;!-- 定义dubbo的远程服务的接口,这个接口定义的时候需要考虑到一个版本问题 --&gt; &lt;dubbo:service interface=&quot;cn.hejx.remoteapi.IMessage&quot; ref=&quot;messageImpl&quot; version=&quot;$&#123;dubbo.interface.version&#125;&quot; /&gt;&lt;/beans&gt; 6.logback.xml 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;!-- 配置IP地址 --&gt; &lt;!--&lt;conversionRule conversionWord=&quot;ip&quot; converterClass=&quot;com.xyk.util.log4j.IpConvert&quot; /&gt;--&gt; &lt;!-- Console 输出格式 --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;%date&#123;yyyy-MM-dd HH:mm:ss&#125; %boldGreen | %highlight(%-5level) | %boldYellow(%thread) | %boldGreen(%logger) | %msg%n&quot;/&gt; &lt;!-- 文件输出格式 --&gt; &lt;property name=&quot;FILE_LOG_PATTERN&quot; value=&quot;===%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %logger Line:%-3L - %msg%n&quot;/&gt; &lt;!-- Console 输出设置 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt; $&#123;CONSOLE_LOG_PATTERN&#125; &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 说明： 1、日志级别及文件 日志记录采用分级记录，级别与日志文件名相对应，不同级别的日志信息记录到不同的日志文件中 例如：error级别记录到log_error_xxx.log或log_error.log（该文件为当前记录的日志文件），而log_error_xxx.log为归档日志， 日志文件按日期记录，同一天内，若日志文件大小等于或大于2M，则按0、1、2...顺序分别命名 例如log-level-2013-12-21.0.log 其它级别的日志也是如此。 2、文件路径 若开发、测试用，在Eclipse中运行项目，则到Eclipse的安装路径查找logs文件夹，以相对路径../logs。 若部署到Tomcat下，则在Tomcat下的logs文件中 3、Appender FILEERROR对应error级别，文件名以log-error-xxx.log形式命名 FILEWARN对应warn级别，文件名以log-warn-xxx.log形式命名 FILEINFO对应info级别，文件名以log-info-xxx.log形式命名 FILEDEBUG对应debug级别，文件名以log-debug-xxx.log形式命名 stdout将日志信息输出到控制上，为方便开发测试使用 --&gt; &lt;contextName&gt;dubboDemo&lt;/contextName&gt; &lt;property name=&quot;LOG_PATH&quot; value=&quot;log/&quot; /&gt; &lt;!--设置系统日志目录--&gt; &lt;property name=&quot;APPDIR&quot; value=&quot;service&quot; /&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_error.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。 而2013-12-21的日志文件在由fileNamePattern指定。%d&#123;yyyy-MM-dd&#125;指定日期格式，%i指定索引 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/error/log-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始， 命名日志文件，例如log-error-2013-12-21.0.log --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录error级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;error&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEWARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_warn.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。 而2013-12-21的日志文件在由fileNamePattern指定。%d&#123;yyyy-MM-dd&#125;指定日期格式，%i指定索引 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/warn/log-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始， 命名日志文件，例如log-error-2013-12-21.0.log --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录warn级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 日志记录器，日期滚动记录 --&gt; &lt;appender name=&quot;FILEINFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/log_info.log&lt;/file&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 归档的日志文件的路径，例如今天是2013-12-21日志，当前写的日志文件路径为file节点指定，可以将此文件与file指定文件路径设置为不同路径，从而将当前日志文件或归档日志文件置不同的目录。 而2013-12-21的日志文件在由fileNamePattern指定。%d&#123;yyyy-MM-dd&#125;指定日期格式，%i指定索引 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;APPDIR&#125;/info/log-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 除按日志记录之外，还配置了日志文件不能超过2M，若超过2M，日志文件会以索引0开始， 命名日志文件，例如log-error-2013-12-21.0.log --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;2MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 追加方式记录日志 --&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 日志文件的格式 --&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 此日志文件只记录info级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot; /&gt; &lt;logger name=&quot;org.hibernate&quot; level=&quot;WARN&quot; /&gt; &lt;!-- 生产环境下，将此级别配置为适合的级别，以免日志文件太多或影响程序性能 --&gt; &lt;!--这里改level 生产环境改成ERROR 开发环境为INFO--&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;FILEERROR&quot; /&gt; &lt;appender-ref ref=&quot;FILEWARN&quot; /&gt; &lt;appender-ref ref=&quot;FILEINFO&quot; /&gt; &lt;!-- 生产环境将请stdout,testfile去掉 --&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; 项目结构图这个图片有错误:profiles文件夹应该是在src/main文件夹下 小结此时一个 Dubbo 业务中心就已经成功的实现了,之后就是调试和运行测试的的过程了","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Dubbo demo项目 (二) 定义远程服务接口","slug":"Dubbo_demo项目（二)","date":"2017-06-29T16:00:00.000Z","updated":"2021-04-30T02:44:33.306Z","comments":true,"path":"2017/06/30/Dubbo_demo项目（二).html","link":"","permalink":"https://blog.smilexin.cn/2017/06/30/Dubbo_demo项目（二).html","excerpt":"","text":"定义远程服务接口远程服务接口实际上指的就是业务接口，但是对于整个项目里面由于需要考虑到开发版本的问题，所以针对于我们的业务接口也需要继承 parent 项目中的相关约定 remoteapi为了方便进行管理，暂时将远程的业务接口项目定义为 remoteapi 建立一个Maven的快速启动项目，项目的整体包名：cn.hejx.remoteapi 修改 pom.xml 配置文件，让其去继承 parent/pom.xml 配置文件 随后就需要进行远程接口的搭建，这次要搭建的远程接口的核心意义在于进行一个echo程序的实现 pom.xml123456789101112131415&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;!-- 定义要实现的父项目的名称 --&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;remoteapi&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;remoteapi&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt;&lt;/project&gt; IMessage接口123456789101112131415161718package cn.hejx;/** * Created by 追风少年 * * @email doubihah@foxmail.com * @create 2017-06-30 14:46 **/public interface IMessage &#123; /** * 实现信息的回应处理,回应的信息是在原始信息前追加一些相应的提示返回 * @param msg 接收的消息 * @return 处理后的 Echo 数据 */ public String echo(String msg);&#125; 提醒以后在业务层的实现项目里面以及客户端去调用远程业务项目里面必须去引用 remoteapi 的项目","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Dubbo demo项目 (一) 定义父项规则","slug":"Dubbo_demo项目（一）","date":"2017-06-29T16:00:00.000Z","updated":"2021-04-30T02:44:33.305Z","comments":true,"path":"2017/06/30/Dubbo_demo项目（一）.html","link":"","permalink":"https://blog.smilexin.cn/2017/06/30/Dubbo_demo项目（一）.html","excerpt":"","text":"定义父项规则在本次的开发之中，如果想要实现一个Dubbo项目的编写，需要有三个项目：远程接口、业务实现、客户端，为了保证整个项目的整体风格一致，以及所有开发包的版本的统一管理，需要定义一个父项目，在这个项目里面主要的目的是定义一些基础的插件，以及版本的属性信息，同时其他的项目里面都要求继承这个项目。 所有项目的搭建使用的是Maven的方式管理 创建一个parent项目，这个项目作为整个的公共的项目约束（使用maven创建项目,使用quickstart默认风格） 修改项目的pom.xml配置文件 配置项目打包形式12&lt;!-- 该项目应该作为一个父项目的pom.xml的配置文件,所以必须将 packaging 设置为pom --&gt;&lt;packaging&gt;pom&lt;/packaging&gt; 配置jdk版本maven是个项目管理工具，如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话，它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题，以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本，那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现，在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件 123&lt;jdk.version&gt;1.8&lt;/jdk.version&gt; &lt;!-- 定义要使用的jdk的开发版本 --&gt;&lt;!-- 定义程序编译的开发版本，这样整体的项目会从JDK1.5变为JDK1.8 --&gt;&lt;maven.compiler.plugin.version&gt;3.6.0&lt;/maven.compiler.plugin.version&gt; 定义源代码生成的插件版本信息12&lt;!-- 定义源代码生成的插件版本信息 --&gt;&lt;maven.source.plugin.version&gt;3.0.1&lt;/maven.source.plugin.version&gt; 定义编译时的配置项12345678910111213141516171819202122232425262728&lt;build&gt;&lt;!-- 定义编译时的配置项 --&gt;&lt;finalName&gt;parent&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.source.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;!-- 排除所有的jar文件 --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.compiler.plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;jdk.version&#125;&lt;/source&gt; &lt;!-- 定义源代码的开发版本 --&gt; &lt;target&gt;$&#123;jdk.version&#125;&lt;/target&gt; &lt;!-- 定义生成class文件的编译版本 --&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 最后附上完整的pom.xml文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;!-- 此配置文件作为父项pom.xml --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.hejx&lt;/groupId&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;jdk.version&gt;1.8&lt;/jdk.version&gt; &lt;!-- 定义要使用的jdk的开发版本 --&gt; &lt;!-- maven是个项目管理工具，如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话， 它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题， 以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本， 那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现， 在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。 --&gt; &lt;maven.compiler.plugin.version&gt;3.6.0&lt;/maven.compiler.plugin.version&gt; &lt;!-- 源代码打包插件 --&gt; &lt;maven.source.plugin.version&gt;3.0.1&lt;/maven.source.plugin.version&gt; &lt;/properties&gt; &lt;build&gt;&lt;!-- 定义编译时的配置项 --&gt; &lt;finalName&gt;parent&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.source.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;!-- 排除所有的jar文件 --&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.compiler.plugin.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;jdk.version&#125;&lt;/source&gt; &lt;!-- 定义源代码的开发版本 --&gt; &lt;target&gt;$&#123;jdk.version&#125;&lt;/target&gt; &lt;!-- 定义生成class文件的编译版本 --&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;","categories":[],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.smilexin.cn/tags/Dubbo/"}]},{"title":"Mysql 常用笔记","slug":"Mysql_常用笔记","date":"2017-02-05T16:00:00.000Z","updated":"2021-04-30T02:44:33.312Z","comments":true,"path":"2017/02/06/Mysql_常用笔记.html","link":"","permalink":"https://blog.smilexin.cn/2017/02/06/Mysql_常用笔记.html","excerpt":"","text":"新增字段1ALTER TABLE tableName ADD newColumn varchar(8) DEFAULT &apos;&apos; COMMENT &apos;新添加的字段&apos;; 修改字段1ALTER TABLE tb_recharge MODIFY COLUMN pay_platform int(11) NOT NULL COMMENT &apos;支付平台&apos;; 删除字段12-- 删除事件表中的事件描述字段ALTER TABLE `tb_event` DROP COLUMN event_desc; 将A表的数据拷贝到B表每个字段需要数据类型相同,这里的例子是将以前用户表存储的role_id拷贝到用户角色关系表 12INSERT INTO tb_user_role(user_id,role_id) SELECT pk_id,role_id FROM tb_user WHERE role_id IS NOT NULL AND role_id &lt;&gt; &apos;&apos; 循环插入数据（id自增）123456789101112BEGIN DECLARE i INT DEFAULT 1;WHILE i&lt;6000DO INSERT INTO `login_info`(name,role_uid,acc_id,sid,sex,login_ip,login_time,money,gold,roomcard,sum_online,create_time) VALUES (&apos;hy&apos;, &apos;100087&apos;, &apos;test.hy&apos;, &apos;01&apos;, &apos;1&apos;, &apos;192.168.2.50&apos;, &apos;2017-08-21 19:22:10&apos;, &apos;0&apos;, &apos;0&apos;, &apos;0&apos;, &apos;220&apos;, &apos;2017-08-16 11:33:04&apos;);SET i=i+1; END WHILE ; commit; END Mysql将数据分组后取出时间最近的数据这一种查询较为耗时，不推荐使用，6000条正常数据左右就耗时2秒多，伤不起 1234select id,name,role_uid,acc_id,sid,sex,login_ip,login_time,money,gold,roomcard,sum_online from login_info as bwhere not exists(select 1 from login_info where role_uid = b.role_uid and b.login_time&lt;login_time ) ORDER BY login_time DESC limit 0,10 下面这种推荐使用因为mysql的group是返回每组结果集中的第一行，所以如果需要返回每组最新的数据，只要在 GROUP BY 前将顺序调整好，把你希望的数据排在最前面，那么 GROUP BY 时就能顺利取到这个数据。故解决方法就是先进行你想要的排序，然后在此排序后的结果集的基础上，进行 GROUP BY 操作。123sql: select id,name,role_uid,acc_id,sid,sex,login_ip,login_time,money,gold,roomcard,sum_online from (select * from login_info ORDER BY login_time DESC ) t GROUP BY t.role_uid ORDER BY login_time DESC limit 0,10count_sql: SELECT COUNT(DISTINCT role_uid) FROM login_info Mysql 使用游标处理历史问题数据1234567891011121314151617181920212223242526272829303132333435CREATE PROCEDURE proc_userRole()BEGINDECLARE roleId BIGINT; -- 角色idDECLARE userId BIGINT; -- 用户idDECLARE today DATETIME DEFAULT NOW();-- 遍历数据结束标志DECLARE done INT DEFAULT FALSE;DECLARE userCur CURSOR FOR SELECT t.pk_id,t.role_id FROM tb_user AS t;-- 将结束标志绑定到游标DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;OPEN userCur; -- 打开游标 myLoop: LOOP FETCH userCur INTO userId,roleId; IF done THEN LEAVE myLoop; -- 结束循环 END IF; IF roleId=12 THEN -- 分解以前的双角色 INSERT INTO tb_user_role(`user_id`,`role_id`,`data_create_time`,`data_create_user`) VALUES(userId,5,today,&apos;角色名1&apos;); INSERT INTO tb_user_role(`user_id`,`role_id`,`data_create_time`,`data_create_user`) VALUES(userId,10,today,&apos;角色名2&apos;); ELSEIF roleId=13 THEN -- 分解以前的双角色2 INSERT INTO tb_user_role(`user_id`,`role_id`,`data_create_time`,`data_create_user`) VALUES(userId,9,today,&apos;角色2&apos;); INSERT INTO tb_user_role(`user_id`,`role_id`,`data_create_time`,`data_create_user`) VALUES(userId,10,today,&apos;橘色&apos;); ELSE INSERT INTO tb_user_role(`user_id`,`role_id`,`data_create_time`,`data_create_user`) VALUES(userId,roleId,today,&apos;角色1&apos;); END IF; END LOOP;CLOSE userCur;END;call proc_userRole();","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://blog.smilexin.cn/tags/Mysql/"}]}]}